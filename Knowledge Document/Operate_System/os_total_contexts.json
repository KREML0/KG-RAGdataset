[
  "### 计算机系统概述知识点",
  "操作系统的概念 在信息化时代, 软件是计算机系统的灵魂, 而作为软件核心的操作系统, 已与现代计算机系统密不可分、融为一体。 计算机系统自下而上可以大致分为4部分: 硬件、操作系统、应用程序和用户(这里的划分与计算机组成原理中的分层不同)。 操作系统管理各种计算机硬件, 为应用程序提供基础, 并且充当计算机硬件与用户之间的中介。硬件如中央处理器、内存、输入/输出设备等, 提供基本的计算资源。 应用程序如字处理程序、电子制表软件、编译器、网络浏览器等, 规定按何种方式使用这些资源来解决用户的计算问题。 操作系统控制和协调各用户的应用程序对硬件的分配与使用。在计算机系统的运行过程中, 操作系统提供了正确使用这些资源的方法。 综上所述, 操作系统(Operating System, OS)是指控制和管理整个计算机系统的硬件与软件资源, 合理地组织、调度计算机的工作与资源的分配, 进而为用户和其他软件提供方便接口与环境的程序集合。 操作系统是计算机系统中最基本的系统软件。",
  "操作系统的功能和目标 为给多道程序提供良好的运行环境, 操作系统应具有以下几方面的功能: 处理机管理、存储器管理、设备管理和文件管理。 为方便用户使用操作系统, 还要向用户提供接口。 同时, 操作系统可用来扩充机器, 以提供更方便的服务、更高的资源利用率。 下面用一个直观的例子来理解这种情况。 例如, 用户是雇主, 操作系统是工人(用来操作机器), 计算机是机器(由处理机、存储器、设备、文件几个部件构成), 工人有熟练的技能, 能够控制和协调各个部件的工作, 这就是操作系统对资源的管理; 同时, 工人必须接收雇主的命令, 这就是“接口”; 有了工人, 机器就能发挥更大的作用, 因此工人就成了“扩充机器”。 1. 操作系统作为计算机系统资源的管理者 (1)处理机管理 在多道程序环境下, 处理机的分配和运行都以进程(或线程)为基本单位, 因此对处理机的管理可归结为对进程的管理。 并发是指在计算机内同时运行多个进程, 因此进程何时创建、何时撤销、如何管理、如何避免冲突、合理共享就是进程管理最主要的任务。 进程管理的主要功能包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。 (2)存储器管理 存储器管理是为了给多道程序的运行提供良好的环境, 方便用户使用及提高内存的利用率, 主要包括内存分配与回收、地址映射、内存保护与共享和内存扩充等功能。 (3)文件管理 计算机中的信息都是以文件的形式存在的, 操作系统中负责文件管理的部分称为文件系统。 文件管理包括文件存储空间的管理、目录管理及文件读/写管理和保护等。 (4)设备管理 设备管理的主要任务是完成用户的I/O请求, 方便用户使用各种设备, 提高设备的利用率, 主要包括缓冲管理、设备分配、设备处理和虚拟设备等功能。 这些工作都由“工人”负责, “雇主”无须关注。 2. 操作系统作为用户与计算机硬件系统之间的接口 为让用户方便、快捷、可靠地操纵计算机硬件并运行自己的程序, 操作系统还提供用户接口。 操作系统提供的接口主要分为两类: 一类是命令接口, 用户利用这些操作命令来组织和控制作业的执行; 另一类是程序接口, 编程人员可用来请求操作系统服务。 (1)命令接口 使用命令接口进行作业控制的主要方式有两种, 即联机控制方式和脱机控制方式。 按作业控制方式的不同, 可将命令接口分为联机命令接口和脱机命令接口。 联机命令接口也称交互式命令接口, 适用于分时或实时系统的接口。 联机命令由一组键盘操作命令组成。 用户通过控制台或终端输入操作命令, 向系统提出各种服务要求。 用户每输入一条命令, 控制权就转给操作系统的命令解释程序, 然后由命令解释程序解释并执行输入的命令, 进而完成指定的功能。 之后, 控制权转回控制台或终端, 此时用户又可输入下一条命令。 联机命令接口可以这样理解: “雇主”说一句话, “工人”做一件事, 并做出反馈, 这就强调了交互性。 脱机命令接口也称批处理命令接口, 适用于批处理系统。 脱机命令由一组作业控制命令组成。 脱机用户不能直接干预作业的运行, 而应事先用相应的作业控制命令编写一份作业操作说明书, 连同作业一起提交给系统。 当系统调度到该作业时, 由系统中的命令解释程序逐条解释执行作业说明书上的命令, 进而间接地控制作业的运行。 脱机命令接口可以这样理解: “雇主”将要“工人”做的事情写在清单上, “工人”按照清单逐条完成这些事情, 这就是批处理。 (2)程序接口 程序接口由一组系统调用(也称广义指令)组成。 用户通过在程序中使用这些系统调用来请求操作系统为其提供服务, 如使用各种外部设备、申请分配和回收内存及其他各种要求。 当前最流行的是图形用户界面(GUI), 即图形接口。 GUI最终是通过调用程序接口实现的, 用户通过鼠标和键盘在图形界面上单击或使用快捷键, 就能方便地使用操作系统。 严格来说, 图形接口不是操作系统的一部分, 但图形接口所调用的系统调用命令是操作系统的一部分。 3. 操作系统实现了对计算机资源的扩充 没有任何软件支持的计算机称为裸机, 它仅构成计算机系统的物质基础, 而实际呈现在用户面前的计算机系统是经过若干层软件改造的计算机。 裸机在最内层, 外面是操作系统。 操作系统所提供的资源管理功能和方便用户的各种服务功能将裸机改造成功能更强、使用更方便的机器; 因此, 我们通常将覆盖了软件的机器称为扩充机器或虚拟机。 “工人”操作机器, 机器就有更大的作用, 于是“工人”便成了“扩充机器”。 注意, 本课程关注的是操作系统如何控制和协调处理机、存储器、设备和文件, 而不关注接口和扩充机器, 对于后两者, 读者只需要有个印象, 能够理解即可。",
  "操作系统的特征 操作系统是一种系统软件, 但与其他系统软件和应用软件有很大的不同, 它有自己的特殊性即基本特征。 操作系统的基本特征包括并发、共享、虚拟和异步。 这些概念对理解和掌握操作系统的核心至关重要, 将一直贯穿于各个章节中。 1. 并发(Concurrence) 并发是指两个或多个事件在同一时间间隔内发生。 在多道程序环境下, 在内存中同时装有若干道程序, 以便当运行某道程序时, 利用其因I/O操作而暂停执行时的CPU空档时间, 再调度另一道程序运行, 从而实现多道程序交替运行, 使CPU保持忙碌状态。 并行性是指系统具有同时进行运算或操作的特性, 在同一时刻能完成两种或两种以上的工作。 在支持多道程序的单处理机环境下, 一段时间内, 宏观上有多道程序在同时执行, 而在每个时刻, 实际仅能有一道程序执行, 因此微观上这些程序仍是分时交替执行的。 可见, 操作系统的并发性是通过分时得以实现的。 而CPU与I/O设备、I/O设备和I/O设备则能实现真正的并行。 若要实现进程的并行, 则需要有相关硬件的支持, 如多流水线或多处理机环境。 注意同一时间间隔(并发)和同一时刻(并行)的区别, 下面以生活中的例子来理解这种区别。 例如, 若你在9:00-9:10仅吃面包, 在9:10-9:20仅写字, 在9:20-9:30仅吃面包, 在9:30-10:00仅写字, 则在9:00-10:00吃面包和写字这两种行为就是并发执行的; 又如, 若你在9:00-10:00右手写字, 左手同时拿着面包吃, 则这两个动作就是并行执行的。 在操作系统中, 引入进程的目的是使程序能并发执行。 2. 共享(Sharing) 资源共享即共享, 是指系统中的资源可供内存中多个并发执行的进程共同使用。 资源共享主要可分为互斥共享和同时访问两种方式。 (1)互斥共享方式 系统中的某些资源, 如打印机、磁带机, 虽然可供多个进程使用, 但为使得所打印或记录的结果不致造成混淆, 应规定在一段时间内只允许一个进程访问该资源。 为此, 当进程A访问某个资源时, 必须先提出请求, 若此时该资源空闲, 则系统便将之分配给A使用, 此后有其他进程也要访问该资源时(只要未用完)就必须等待。 仅当A访问完并释放该资源后, 才允许另一个进程对该资源进行访问。 我们将这种资源共享方式称为互斥共享, 而将在一段时间内只允许一个进程访问的资源称为临界资源。 计算机系统中的大多数物理设备及某些软件中所用的栈、变量和表格, 都属于临界资源, 它们都要求被互斥地共享。 (2)同时访问方式 系统中还有另一类资源, 这类资源允许一段时间内由多个进程“同时”访问。 这里所说的“同时”通常是宏观上的, 而在微观上, 这些进程可能是交替地对该资源进行访问, 即“分时共享”的。 可供多个进程“同时”访问的典型资源是磁盘设备, 一些用重入代码编写的文件也可被“同时”共享, 即允许若干用户同时访问该文件。 注意, 互斥共享要求一种资源在一段时间内(哪怕是一段很短的时间)只能满足一个请求, 否则就会出现严重的问题(你能想象打印机第一行打印文档A的内容、第二行打印文档B的内容的效果吗?), 而同时访问共享通常要求一个请求分几个时间片段间隔地完成, 其效果与连续完成的效果相同。 并发和共享是操作系统两个最基本的特征, 两者之间互为存在的条件: ①资源共享是以程序的并发为条件的, 若系统不允许程序并发执行, 则自然不存在资源共享问题; ②若系统不能对资源共享实施有效的管理, 则必将影响到程序的并发执行, 甚至根本无法并发执行。 3. 虚拟(Virtual) 虚拟是指将一个物理上的实体变为若干逻辑上的对应物。 物理实体(前者)是实的, 即实际存在的; 而后者是虚的, 是用户感觉上的事物。 用于实现虚拟的技术称为虚拟技术。 操作系统的虚拟技术可归纳为: 时分复用技术, 如虚拟处理器; 空分复用技术, 如虚拟存储器。 通过多道程序设计技术, 让多道程序并发执行, 来分时使用一个处理器。 此时, 虽然只有一个处理器, 但它能同时为多个用户服务, 使每个终端用户都感觉有一个CPU在专门为它服务。 利用多道程序设计技术将一个物理上的CPU虚拟为多个逻辑上的CPU, 称为虚拟处理器。 采用虚拟存储器技术将一台机器的物理存储器变为虚拟存储器, 以便从逻辑上扩充存储器的容量。 当然, 这时用户所感觉到的内存容量是虚的。 我们将用户感觉到(但实际不存在)的存储器称为虚拟存储器。 还可采用虚拟设备技术将一台物理I/O设备虚拟为多台逻辑上的I/O设备, 并允许每个用户占用一台逻辑上的I/O设备, 使原来仅允许在一段时间内由一个用户访问的设备(临界资源)变为在一段时间内允许多个用户同时访问的共享设备。 4. 异步(Asynchronism) 多道程序环境允许多个程序并发执行, 但由于资源有限, 进程的执行并不是一贯到底的, 而是走走停停的, 它以不可预知的速度向前推进, 这就是进程的异步性。 异步性使得操作系统运行在一种随机的环境下, 可能导致进程产生与时间有关的错误(就像对全局变量的访问顺序不当会导致程序出错一样)。 然而, 只要运行环境相同, 操作系统就须保证多次运行进程后都能获得相同的结果。",
  "手工操作阶段(此阶段无操作系统) 用户在计算机上算题的所有工作都要人工干预, 如程序的装入、运行、结果的输出等。 随着计算机硬件的发展, 人机矛盾(速度和资源利用)越来越大, 必须寻求新的解决办法。 手工操作阶段有两个突出的缺点: ①用户独占全机, 虽然不会出现因资源已被其他用户占用的现象, 但资源利用率低。 ②CPU等待手工操作, CPU的利用不充分。 唯一的解决办法就是用高速的机器代替相对较慢的手工操作来对作业进行控制。",
  "批处理阶段(操作系统开始出现) 为了解决人机矛盾及CPU和I/O设备之间速度不匹配的矛盾, 出现了批处理系统。 按发展历程又分为单道批处理系统、多道批处理系统(多道程序设计技术出现以后)。 1. 单道批处理系统 为实现对作业的连续处理, 需要先将一批作业以脱机方式输入磁带, 并在系统中配上监督程序(Monitor), 在其控制下, 使这批作业能一个接一个地连续处理。 虽然系统对作业的处理是成批进行的, 但内存中始终保持一道作业。 单道批处理系统的主要特征如下: 1) 自动性。在顺利的情况下, 磁带上的一批作业能自动地逐个运行, 而无须人工干预。 2) 顺序性。磁带上的各道作业顺序地进入内存, 先调入内存的作业先完成。 3) 单道性。内存中仅有一道程序运行, 即监督程序每次从磁带上只调入一道程序进入内存运行, 当该程序完成或发生异常情况时, 才换入其后继程序进入内存运行。 此时面临的问题是: 每次主机内存中仅存放一道作业, 每当它在运行期间(注意这里是“运行时”而不是“完成后”)发出输入/输出请求后, 高速的CPU便处于等待低速的I/O完成的状态。 为了进一步提高资源的利用率和系统的吞吐量, 引入了多道程序技术。 2. 多道批处理系统 用户所提交的作业都先存放在外存上并排成一个队列, 作业调度程序按一定的算法从后备队列中选择若干作业调入内存, 它们在管理程序的控制下相互穿插地运行, 共享系统中的各种硬/软件资源。 当某道程序因请求I/O 操作而暂停运行时, CPU便立即转去运行另一道程序, 这是通过中断机制实现的。 它让系统的各个组成部分都尽量的“忙”, 切换任务所花费的时间很少, 因而可实现系统各部件之间的并行工作, 使其在单位时间内的效率翻倍。 多道程序设计的特点是多道、宏观上并行、微观上串行。 1) 多道。计算机内存中同时存放多道相互独立的程序。 2) 宏观上并行。同时进入系统的多道程序都处于运行过程中, 但都未运行完毕。 3) 微观上串行。内存中的多道程序轮流占有CPU, 交替执行。 多道程序设计技术的实现需要解决下列问题: 1) 如何分配处理器。 2) 多道程序的内存分配问题。 3) I/O 设备如何分配。 4) 如何组织和存放大量的程序和数据, 以方便用户使用并保证其安全性与一致性。 在批处理系统中采用多道程序设计技术就形成了多道批处理操作系统。 该系统将用户提交的作业成批地送入计算机内存, 然后由作业调度程序自动地选择作业运行。 优点: 资源利用率高, 多道程序共享计算机资源, 从而使各种资源得到充分利用; 系统吞吐量大, CPU和其他资源保持“忙碌”状态。 缺点: 用户响应的时间较长; 不提供人机交互能力, 用户既不能了解自己的程序的运行情况, 又不能控制计算机。",
  "分时操作系统 所谓分时技术, 是指将处理器的运行时间分成很短的时间片, 按时间片轮流将处理器分配给各联机作业使用。 若某个作业在分配给它的时间片内不能完成其计算, 则该作业暂时停止运行, 将处理器让给其他作业使用, 等待下一轮再继续运行。 计算机速度很快, 作业运行轮转得也很快, 因此给每个用户的感觉就像是自己独占一台计算机。 分时操作系统是指多个用户通过终端同时共享一台主机, 这些终端连接在主机上, 用户可以同时与主机进行交互操作而互不干扰。 因此, 实现分时系统的关键问题是如何使用户能与自己的作业进行交互, 即当用户在自己的终端上键入命令时, 系统应能及时接收并及时处理该命令, 再将结果返回用户。 分时系统也是支持多道程序设计的系统, 但它不同于多道批处理系统。 多道批处理是实现作业自动控制而无须人工干预的系统, 而分时系统是实现人机交互的系统, 这使得分时系统具有与批处理系统不同的特征。 分时系统的主要特征如下: 1) 同时性。同时性也称多路性, 指允许多个终端用户同时使用一台计算机。 2) 交互性。用户通过终端采用人机对话的方式直接控制程序运行, 与同程序进行交互。 3) 独立性。系统中多个用户可以彼此独立地进行操作, 互不干扰, 单个用户感觉不到别人也在使用这台计算机, 好像只有自己单独使用这台计算机一样。 4) 及时性。用户请求能在很短时间内获得响应。 虽然分时操作系统较好地解决了人机交互问题, 但在一些应用场合, 需要系统能对外部的信息在规定的时间(比时间片的时间还短)内做出处理(比如飞机订票系统或导弹制导系统), 因此, 实时操作系统应运而生。",
  "实时操作系统 为了能在某个时间限制内完成某些紧急任务而不需要时间片排队, 诞生了实时操作系统。 这里的时间限制可以分为两种情况: 若某个动作必须绝对地在规定的时刻(或规定的时间范围)发生, 则称为硬实时系统, 如飞行器的飞行自动控制系统, 这类系统必须提供绝对保证, 让某个特定的动作在规定的时间内完成。 若能够接受偶尔违反时间规定且不会引起任何永久性的损害, 则称为软实时系统, 如飞机订票系统、银行管理系统。 在实时操作系统的控制下, 计算机系统接收到外部信号后及时进行处理, 并在严格的时限内处理完接收的事件。 实时操作系统的主要特点是及时性和可靠性。",
  "网络操作系统和分布式计算机系统 网络操作系统是伴随着计算机网络的发展而诞生的, 它把网络中的各台计算机有机地结合起来, 实现各台计算机之间的通信和数据传送等功能, 实现网络中各种资源的共享。 分布式计算机系统是由多台计算机组成并满足下列条件的系统: 系统中任意两台计算机通过通信方式交换信息; 每台计算机都具有同等的地位, 即没有主机也没有从机: 每台计算机上的资源为所有用户共享; 系统中的任意台计算机都可以构成一个子系统, 并且还能重构; 任何工作都可以分布在几台计算机上, 由它们并行工作、协同完成。 用于管理分布式计算机系统的操作系统称为分布式计算机系统。 该系统的主要特点是: 分布性和并行性。 分布式操作系统与网络操作系统的本质不同是, 分布式操作系统中的若干计算机相互协同完成同一任务。",
  "个人计算机操作系统 个人计算机操作系统是目前使用最广泛的操作系统, 它广泛应用于文字处理、电子表格、游戏中, 常见的有Windows、Linux和MacOS等。 此外, 还有嵌入式操作系统、服务器操作系统、智能手机操作系统等。",
  "处理器运行模式 在计算机系统中, 通常CPU执行两种不同性质的程序: 一种是操作系统内核程序; 另一种是用户自编程序(系统外层的应用程序, 简称应用程序)。 对操作系统而言, 这两种程序的作用不同, 前者是后者的管理者, 因此“管理程序”(内核程序)要执行一些特权指令, 而“被管理程序”(用户自编程序)出于安全考虑不能执行这些特权指令。 1) 特权指令, 是指不允许用户直接使用的指令, 如I/O指令、关中断指令、内存清零指令, 存取用于内存保护的寄存器、修改程序状态字寄存器等的指令。 2) 非特权指令, 是指允许用户直接使用的指令, 它不能直接访问系统中的软硬件资源, 仅限于访问用户的地址空间, 这也是为了防止用户程序对系统造成破坏。 在具体实现上, 将CPU的运行模式划分为用户态(目态)和内核态(也称管态、核心态)。 可以理解为CPU内部有一个小开关, 当小开关为0时, CPU处于内核态, 此时CPU可以执行特权指令, 切换到用户态的指令也是特权指令。 当小开关为1时, CPU处于用户态, 此时CPU只能执行非特权指令。 应用程序运行在用户态, 操作系统内核程序运行在内核态。 应用程序向操作系统请求服务时通过使用访管指令, 访管指令是在用户态执行的, 因此是非特权指令。 在软件工程思想和结构化程序设计方法影响下诞生的现代操作系统, 几乎都是分层式的结构。 操作系统的各项功能分别被设置在不同的层次上。 一些与硬件关联较紧密的模块, 如时钟管理、中断处理、设备驱动等处于最低层。 其次是运行频率较高的程序, 如进程管理、存储器管理和设备管理等。 这两部分内容构成了操作系统的内核。 这部分内容的指令运行在内核态。 内核是计算机上配置的底层软件, 它管理着系统的各种资源, 可视为连接应用程序和硬件的一座桥梁, 大多数操作系统的内核包括4方面的内容。 1. 时钟管理 在计算机的各种部件中, 时钟是关键设备。 时钟的第一功能是计时, 操作系统需要通过时钟管理, 向用户提供标准的系统时间。 另外, 通过时钟中断的管理, 可以实现进程的切换。 例如, 在分时操作系统中采用时间片轮转调度, 在实时系统中按截止时间控制运行, 在批处理系统中通过时钟管理来衡量一个作业的运行程度等。 因此, 系统管理的方方面面无不依赖于时钟。 2. 中断机制 引入中断技术的初衷是提高多道程序运行时的CPU利用率, 使CPU可以在I/O操作期间执行其他指令。 后来逐步得到发展, 形成了多种类型, 成为操作系统各项操作的基础。 例如, 键盘或鼠标信息的输入、进程的管理和调度、系统功能的调用、设备驱动、文件访问等, 无不依赖于中断机制。 可以说, 现代操作系统是靠中断驱动的软件。 中断机制中, 只有一小部分功能属于内核, 它们负责保护和恢复中断现场的信息, 转移控制权到相关的处理程序。 这样可以减少中断的处理时间, 提高系统的并行处理能力。 3. 原语 按层次结构设计的操作系统, 底层必然是一些可被调用的公用小程序, 它们各自完成一个规定的操作, 通常将具有这些特点的程序称为原语(Atomic Operation)。 它们的特点如下: 1) 处于操作系统的底层, 是最接近硬件的部分。 2) 这些程序的运行具有原子性, 其操作只能一气呵成(出于系统安全性和便于管理考虑)。 3) 这些程序的运行时间都较短, 而且调用频繁。 定义原语的直接方法是关中断, 让其所有动作不可分割地完成后再打开中断。 系统中的设备驱动、CPU切换、进程通信等功能中的部分操作都可定义为原语, 使它们成为内核的组成部分。 4. 系统控制的数据结构及处理 系统中用来登记状态信息的数据结构很多, 如作业控制块、进程控制块(PCB)、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。 为了实现有效的管理, 系统需要一些基本的操作, 常见的操作有以下3种: 1) 进程管理。进程状态管理、进程调度和分派、创建与撤销进程控制块等。 2) 存储器管理。存储器的空间分配和回收、内存信息保护程序、代码对换程序等。 3) 设备管理。缓冲区管理、设备分配和回收等。 可见, 内核态指令实际上包括系统调用类指令和一些针对时钟、中断和原语的操作指令。",
  "中断和异常的概念 在操作系统中引入内核态和用户态这两种工作状态后, 就需要考虑这两种状态之间如何切换。 操作系统内核工作在内核态, 而用户程序工作在用户态。 系统不允许用户程序实现内核态的功能, 而它们又必须使用这些功能。 因此, 需要在内核态建立一些“门”, 以便实现从用户态进入内核态。 在实际操作系统中, CPU运行用户程序时唯一能进入这些“门”的途径就是通过中断或异常。 发生中断或异常时, 运行用户态的CPU会立即进入内核态, 这是通过硬件实现的(例如, 用一个特殊寄存器的一位来表示CPU所处的工作状态, 0表示内核态, 1表示用户态。若要进入内核态, 则只需将该位置0即可)。 中断是操作系统中非常重要的一个概念, 对一个运行在计算机上的实用操作系统而言, 缺少了中断机制, 将是不可想象的。 原因是, 操作系统的发展过程大体上就是一个想方设法不断提高资源利用率的过程, 而提高资源利用率就需要在程序并未使用某种资源时, 将它对那种资源的占有权释放, 而这一行为就需要通过中断实现。 1. 中断和异常的定义 中断(Interruption)也称外中断, 是指来自CPU 执行指令外部的事件, 通常用于信息输入/输出(见第5章), 如设备发出的I/O结束中断, 表示设备输入/输出处理已经完成。 时钟中断, 表示一个固定的时间片已到, 让处理机处理计时、启动定时运行的任务等。 异常(Exception)也称内中断, 是指来自CPU执行指令内部的事件, 如程序的非法操作码、地址越界、运算溢出、虚存系统的缺页及专门的陷入指令等引起的事件。 异常不能被屏蔽, 一旦出现, 就应立即处理。 2. 中断和异常的分类 外中断可分为可屏蔽中断和不可屏蔽中断。 可屏蔽中断是指通过INTR线发出的中断请求, 通过改变屏蔽字可以实现多重中断, 从而使得中断处理更加灵活。 不可屏蔽中断是指通过 NMI线发出的中断请求, 通常是紧急的硬件故障, 如电源掉电等。 此外, 异常也是不能被屏蔽的。 异常可分为故障、自陷和终止。 故障(Fault)通常是由指令执行引起的异常, 如非法操作码、缺页故障、除数为0、运算溢出等。 自陷(Trap, 也称陷入)是一种事先安排的“异常”事件, 用于在用户态下调用操作系统内核程序, 如条件陷阱指令、系统调用指令等。 终止(Abort)是指出现了使得CPU无法继续执行的硬件故障, 如控制器出错、存储器校验错等。 故障异常和自陷异常属于软件中断(程序性异常), 终止异常和外部中断属于硬件中断。 3. 中断和异常的处理过程 中断和异常处理过程的大致描述如下: 当CPU在执行用户程序的第 i 条指令时检测到一个异常事件, 或在执行第 i 条指令后发现一个中断请求信号, 则CPU打断当前的用户程序, 然后转到相应的中断或异常处理程序去执行。 若中断或异常处理程序能够解决相应的问题, 则在中断或异常处理程序的最后, CPU通过执行中断或异常返回指令, 回到被打断的用户程序的第 i 条指令或第 i+1条指令继续执行; 若中断或异常处理程序发现是不可恢复的致命错误, 则终止用户程序。 通常情况下, 对中断和异常的具体处理过程由操作系统(和驱动程序)完成。 注意区分中断处理和子程序调用: ①中断处理程序与被中断的当前程序是相互独立的, 它们之间没有确定的关系; 子程序与主程序是同一程序的两部分, 它们属于主从关系。 ②通常中断的产生都是随机的; 而子程序调用是通过调用指令(CALL)引起的, 是由程序设计者事先安排的。 ③调用子程序的过程完全属于软件处理过程; 而中断处理的过程还需要有专门的硬件电路才能实现。 ④中断处理程序的入口地址可由硬件向量法产生向量地址, 再由向量地址找到入口地址: 子程序的入口地址是由CALL 指令中的地址码给出的。 ⑤调用中断处理程序和子程序都需要保护程序计数器(PC)的内容, 前者由中断隐指令完成, 后者由CALL 指令完成(执行指令时, 处理器先将当前的PC值压入栈, 再将PC设置为被调用子程序的入口地址)。 ⑥响应中断时, 需对同时检测到的多个中断请求进行裁决, 而调用子程序时没有这种操作。",
  "系统调用 系统调用是操作系统提供给应用程序(程序员)使用的接口, 可视为一种供应用程序调用的特殊的公共子程序。 系统中的各种共享资源都由操作系统统一掌管, 因此凡是与共享资源有关的操作(如存储分配、I/O传输及文件管理等), 都必须通过系统调用方式向操作系统提出服务请求, 由操作系统代为完成, 并将处理结果返回给应用程序。 这样, 就可以保证系统的稳定性和安全性, 防止用户进行非法操作。 通常, 一个操作系统提供的系统调用命令有几十条乃至上百条之多, 每个系统调用都有唯一的系统调用号。 这些系统调用按功能大致可分为如下几类。 设备管理。完成设备的请求或释放, 以及设备启动等功能。 文件管理。完成文件的读、写、创建及删除等功能。 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。 进程通信。完成进程之间的消息传递或信号传递等功能。 内存管理。完成内存的分配、回收以及获取作业占用内存区大小和起始地址等功能。 显然, 系统调用相关功能涉及系统资源管理、进程管理之类的操作, 对整个系统的影响非常大, 因此系统调用的处理需要由操作系统内核程序负责完成, 要运行在内核态。 下面分析系统调用的处理过程: 第一步, 用户程序首先将系统调用号和所需的参数压入堆栈; 接着, 调用实际的调用指令, 然后执行一个陷入指令, 将CPU状态从用户态转为内核态, 再后由硬件和操作系统内核程序保护被中断进程的现场, 将程序计数器(PC)、程序状态字(PSW)及通用寄存器内容等压入堆栈。 第二步, 分析系统调用类型, 转入相应的系统调用处理子程序。 在系统中配置了一张系统调用入口表, 表中的每个表项都对应一个系统调用, 根据系统调用号可以找到该系统调用处理子程序的入口地址。 第三步, 在系统调用处理子程序执行结束后, 恢复被中断的或设置新进程的CPU现场, 然后返回被中断进程或新进程, 继续往下执行。 可以这么理解, 用户程序执行“陷入指令”, 相当于将CPU的使用权主动交给操作系统内核程序(CPU状态会从用户态进入内核态), 之后操作系统内核程序再对系统调用请求做出相应处理。 处理完成后, 操作系统内核程序又会将CPU的使用权还给用户程序(CPU状态会从内核态回到用户态)。 这么设计的目的是: 用户程序不能直接执行对系统影响非常大的操作, 必须通过系统调用的方式请求操作系统代为执行, 以便保证系统的稳定性和安全性。 这样, 操作系统的运行环境可以理解为: 用户通过操作系统运行上层程序(如系统提供的命令解释程序或用户自编程序), 而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持, 当需要管理程序服务时, 系统通过硬件中断机制进入内核态, 运行管理程序; 也可能是程序运行出现异常情况, 被动地需要管理程序的服务, 此时则通过异常处理进入内核态。 管理程序运行结束时, 退出中断或异常处理程序, 返回到用户程序的断点处继续执行。 下面列举一些由用户态转向内核态的例子: 1) 用户程序要求操作系统的服务, 即系统调用。 2) 发生一次中断。 3) 用户程序中产生了一个错误状态。 4) 用户程序中企图执行一条特权指令。 从内核态转向用户态由一条指令实现, 这条指令也是特权命令, 一般是中断返回指令。",
  "分层法 分层法是将操作系统分为若干层, 底层(层0)为硬件, 顶层(层N)为用户接口, 每层只能调用紧邻它的低层的功能和服务(单向依赖)。 分层法的优点: ①便于系统的调试和验证, 简化了系统的设计和实现。 第1层可先调试而无须考虑系统的其他部分, 因为它只使用了基本硬件。 第1层调试完且验证正确之后, 就可以调试第2层, 如此向上。 若在调试某层时发现错误, 则错误应在这一层上, 这是因为它的低层都调试好了。 ②易扩充和易维护。 在系统中增加、修改或替换一层中的模块或整层时, 只要不改变相应层间的接口, 就不会影响其他层。 分层法的问题: ①合理定义各层比较困难。 因为依赖关系固定后, 往往就显得不够灵活。 ②效率较差。 操作系统每执行一个功能, 通常要自上而下地穿越多层, 各层之间都有相应的层间通信机制, 这无疑增加了额外的开销, 导致系统效率降低。",
  "模块化 模块化是将操作系统按功能划分为若干具有一定独立性的模块。 每个模块具有某方面的管理功能, 并规定好各模块间的接口, 使各模块之间能够通过接口进行通信。 还可以进一步将各模块细分为若干具有一定功能的子模块, 同样也规定好各子模块之间的接口。 这种设计方法被称为模块-接口法。 在划分模块时, 若将模块划分得太小, 则虽然能降低模块本身的复杂性, 但会使得模块之间的联系过多, 造成系统比较混乱; 若模块划分得过大, 则又会增加模块内部的复杂性, 显然应在两者间进行权衡。 此外, 在划分模块时, 要充分考虑模块的独立性问题, 因为模块独立性越高, 各模块间的交互就越少, 系统的结构也就越清晰。 衡量模块的独立性主要有两个标准: 内聚性, 模块内部各部分间联系的紧密程度。内聚性越高, 模块独立性越好。 耦合度, 模块间相互联系和相互影响的程度。耦合度越低, 模块独立性越好。 模块化的优点: ①提高了操作系统设计的正确性、可理解性和可维护性: ②增强了操作系统的可适应性; ③加速了操作系统的开发过程。 模块化的缺点: ①模块间的接口规定很难满足对接口的实际需求。 ②各模块设计者齐头并进, 每个决定无法建立在上一个已验证的正确决定的基础上, 因此无法找到一个可靠的决定顺序。",
  "宏内核 从操作系统的内核架构来划分, 可分为宏内核和微内核。 宏内核, 也称单内核或大内核, 是指将系统的主要功能模块都作为一个紧密联系的整体运行在内核态, 从而为用户程序提供高性能的系统服务。 因为各管理模块之间共享信息, 能有效利用相互之间的有效特性, 所以具有无可比拟的性能优势。 随着体系结构和应用需求的不断发展, 需要操作系统提供的服务越来越复杂, 操作系统的设计规模急剧增长, 操作系统也面临着“软件危机”困境。 就像一个人, 越胖活动起来就越困难。 所以就出现了微内核技术, 就是将一些非核心的功能移到用户空间, 这种设计带来的好处是方便扩展系统, 所有新服务都可以在用户空间增加, 内核基本不用去做改动。 从操作系统的发展来看, 宏内核获得了绝对的胜利, 目前主流的操作系统, 如Windows、Android、iOS、macOS、Linux等, 都是基于宏内核的构架。 但也应注意到, 微内核和宏内核一直是同步发展的, 目前主流的操作系统早已不是当年纯粹的宏内核构架了, 而是广泛吸取微内核构架的优点而后揉合而成的混合内核。 当今宏内核构架遇到了越来越多的困难和挑战, 而微内核的优势似乎越来越明显, 尤其是谷歌的Fuchsia 和华为的鸿蒙OS, 都瞄准了微内核构架。",
  "微内核 (1) 微内核的基本概念 微内核构架, 是指将内核中最基本的功能保留在内核, 而将那些不需要在内核态执行的功能移到用户态执行, 从而降低内核的设计复杂性。 那些移出内核的操作系统代码根据分层的原则被划分成若干服务程序, 它们的执行相互独立, 交互则都借助于微内核进行通信。 微内核结构将操作系统划分为两大部分: 微内核和多个服务器。 微内核是指精心设计的、能实现操作系统最基本核心功能的小型内核, 通常包含: ①与硬件处理紧密相关的部分; ②一些较基本的功能; ③客户和服务器之间的通信。 这些部分只是为构建通用操作系统提供一个重要基础, 这样就可以确保将内核做得很小。 操作系统中的绝大部分功能都放在微内核外的一组服务器(进程)中实现, 如用于提供对进程(线程)进行管理的进程(线程)服务器、提供虚拟存储器管理功能的虚拟存储器服务器等, 它们都是作为进程来实现的, 运行在用户态, 客户与服务器之间是借助微内核提供的消息传递机制来实现交互的。 在微内核结构中, 为了实现高可靠性, 只有微内核运行在内核态, 其余模块都运行在用户态, 一个模块中的错误只会使这个模块崩溃, 而不会使整个系统崩溃。 例如, 文件服务代码运行时出了问题, 宏内核因为文件服务是运行在内核态的, 系统直接就崩溃了。 而微内核的文件服务是运行在用户态的, 只要将文件服务功能强行停止, 然后重启, 就可以继续使用, 系统不会崩溃。 (2) 微内核的基本功能 微内核结构通常利用“机制与策略分离”的原理来构造OS结构, 将机制部分以及与硬件紧密相关的部分放入微内核。 微内核通常具有如下功能: ①进程(线程)管理。进程(线程)之间的通信功能是微内核OS最基本的功能, 此外还有进程的切换、进程的调度, 以及多处理机之间的同步等功能, 都应放入微内核。 举个例子, 为实现进程调度功能, 需要在进程管理中设置一个或多个进程优先级队列, 这部分属于调度功能的机制部分, 应将它放入微内核。 而对用户进程如何分类, 以及优先级的确认方式, 则属于策略问题, 可将它们放入微内核外的进程管理服务器中。 ②低级存储器管理。在微内核中, 只配置最基本的低级存储器管理机制, 如用于实现将逻辑地址变换为物理地址等的页表机制和地址变换机制, 这一部分是依赖于硬件的, 因此放入微内核。 而实现虚拟存储器管理的策略, 则包含应采取何种页面置换算法、采用何种内存分配与回收的策略, 应将这部分放在微内核外的存储器管理服务器中。 ③中断和陷入处理。微内核OS将与硬件紧密相关的一小部分放入微内核, 此时微内核的主要功能是捕获所发生的中断和陷入事件, 并进行中断响应处理, 在识别中断或陷入的事件后, 再发送给相关的服务器来处理, 所以中断和陷入处理也应放入微内核。 微内核操作系统将进程管理、存储器管理以及I/O管理这些功能一分为二, 属于机制的很小一部分放入微内核, 而绝大部分放入微内核外的各种服务器实现, 大多数服务器都要比微内核大。 因此, 在采用客户/服务器模式时, 能将微内核做得很小。 (3) 微内核的特点 微内核结构的主要优点如下所示。 ①扩展性和灵活性。许多功能从内核中分离出来, 当要修改某些功能或增加新功能时, 只需在相应的服务器中修改或新增功能, 或再增加一个专用的服务器, 而无须改动内核代码。 ②可靠性和安全性。前面已举例说明。 ③可移植性。与CPU和I/O硬件有关的代码均放在内核中, 而其他各种服务器均与硬件平台无关, 因而将操作系统移植到另一个平台上所需做的修改是比较小的。 ④分布式计算。客户和服务器之间、服务器和服务器之间的通信采用消息传递机制, 这就使得微内核系统能很好地支持分布式系统和网络系统。 微内核结构的主要问题是性能问题, 因为需要频繁地在内核态和用户态之间进行切换, 操作系统的执行开销偏大。 为了改善运行效率, 可以将那些频繁使用的系统服务移回内核, 从而保证系统性能, 但这又会使微内核的容量明显地增大。 虽然宏内核在桌面操作系统中取得了绝对的胜利, 但是微内核在实时、工业、航空及军事应用中特别流行, 这些领域都是关键任务, 需要有高度的可靠性。",
  "外核 不同于虚拟机克隆真实机器, 另一种策略是对资源进行划分, 为每个用户分配整个资源的一个子集。 例如, 某虚拟机可能得到磁盘的0~1023盘块, 而另一虚拟机得到磁盘的1024~2047盘块等。 在底层, 一种称为外核(exokernel)的程序在内核态中运行。 它的任务是为虚拟机分配资源, 并检查这些资源使用的安全性, 以确保没有机器会使用他人的资源。 每个用户的虚拟机可以运行自己的操作系统, 但限制只能使用已经申请并且获得分配的那部分资源。 外核机制的优点是减少了资源的“映射层”。 在其他设计中, 每个虚拟机系统都认为它拥有完整的磁盘(或其他资源), 这样虚拟机监控程序就必须维护一张表格以重映像磁盘地址, 有了外核, 这个重映射处理就不需要了。 外核只需要记录已分配给各个虚拟机的有关资源即可。 这种方法还有一个优点, 它将多道程序(在外核内)与用户操作系统代码(在用户空间内)加以分离, 而且相应的负载并不重, 因为外核所做的只是保持多个虚拟机彼此不发生冲突。",
  "操作系统引导 操作系统(如Windows、Linux等)是一种程序, 程序以数据的形式存放在硬盘中, 而硬盘通常分为多个区, 一台计算机中又可能有多个或多种外部存储设备。 操作系统引导是指计算机利用CPU运行特定程序, 通过程序识别硬盘, 识别硬盘分区, 识别硬盘分区上的操作系统, 最后通过程序启动操作系统, 一环扣一环地完成上述过程。 常见操作系统的引导过程如下: ①激活 CPU。激活的CPU读取ROM 中的 boot程序, 将指令寄存器置为BIOS(基本输入/输出系统)的第一条指令, 即开始执行BIOS的指令。 ②硬件自检。BIOS 程序在内存最开始的空间构建中断向量表, 接下来的POST(通电自检)过程要用到中断功能。 然后进行通电自检, 检查硬件是否出现故障。 如有故障, 主板会发出不同含义的蜂鸣, 启动中止; 如无故障, 屏幕会显示CPU、内存、硬盘等信息。 ③加载带有操作系统的硬盘。通电自检后, BIOS开始读取 Boot Sequence(通过CMOS里保存的启动顺序, 或者通过与用户交互的方式), 将控制权交给启动顺序排在第一位的存储设备, 然后CPU将该存储设备引导扇区的内容加载到内存中。 ④加载主引导记录(MBR)。硬盘以特定的标识符区分引导硬盘和非引导硬盘。 若发现一个存储设备不是可引导盘, 就检查下一个存储设备。 如无其他启动设备, 就会死机。 主引导记录 MBR的作用是告诉CPU去硬盘的哪个主分区去找操作系统。 ⑤扫描硬盘分区表, 并加载硬盘活动分区。MBR包含硬盘分区表, 硬盘分区表以特定的标识符区分活动分区和非活动分区。 主引导记录扫描硬盘分区表, 进而识别含有操作系统的硬盘分区(活动分区)。 找到硬盘活动分区后, 开始加载硬盘活动分区, 将控制权交给活动分区。 ⑥加载分区引导记录(PBR)。读取活动分区的第一个扇区, 这个扇区称为分区引导记录(PBR), 其作用是寻找并激活分区根目录下用于引导操作系统的程序(启动管理器)。 ⑦加载启动管理器。分区引导记录搜索活动分区中的启动管理器, 加载启动管理器。 ⑧加载操作系统。将操作系统的初始化程序加载到内存中执行。",
  "虚拟机的基本概念 虚拟机是指利用虚拟化技术, 将一台物理机器虚拟化为多台虚拟机器, 通过隐藏特定计算平台的实际物理特性, 为用户提供抽象的、统一的、模拟的计算环境。 有两类虚拟化方法。 1. 第一类虚拟机管理程序 从技术上讲, 第一类虚拟机管理程序就像一个操作系统, 因为它是唯一一个运行在最高特权级的程序。 它在裸机上运行并且具备多道程序功能。 虚拟机管理程序向上层提供若干虚拟机, 这些虚拟机是裸机硬件的精确复制品。 因为每台虚拟机都与裸机相同, 所以在不同的虚拟机上可以运行任何不同的操作系统。 虚拟机作为用户态的一个进程运行, 不允许执行敏感指令。 然而, 虚拟机上的操作系统认为自己运行在内核态(实际上不是), 称为虚拟内核态。 虚拟机中的用户进程认为自己运行在用户态(实际上确实是)。 当虚拟机操作系统执行了一条CPU处于内核态才允许执行的指令时, 会陷入虚拟机管理程序。 在支持虚拟化的CPU上, 虚拟机管理程序检查这条指令是由虚拟机中的操作系统执行的还是由用户程序执行的。 若是前者, 则虚拟机管理程序将安排这条指令功能的正确执行。 否则, 虚拟机管理程序将模拟真实硬件面对用户态执行敏感指令时的行为。 在过去不支持虚拟化的CPU上, 真实硬件不会直接执行虚拟机中的敏感指令, 这些敏感指令被转为对虚拟机管理程序的调用, 由虚拟机管理程序模拟这些指令的功能。 2. 第二类虚拟机管理程序 第二类虚拟机管理程序是一个依赖于Windows、Linux等操作系统分配和调度资源的程序, 很像一个普通的进程。 第二类虚拟机管理程序仍然伪装成具有CPU和各种设备的完整计算机。 VMware Workstation 是首个x86平台上的第二类虚拟机管理程序。 运行在两类虚拟机管理程序上的操作系统都称为客户操作系统。 对于第二类虚拟机管理程序, 运行在底层硬件上的操作系统称为宿主操作系统。 首次启动时, 第二类虚拟机管理程序像一台刚启动的计算机那样运转, 期望找到的驱动器可以是虚拟设备。 然后将操作系统安装到虚拟磁盘上(其实只是宿主操作系统中的一个文件)。 客户操作系统安装完成后, 就能启动并运行。 虚拟化在 Web主机领域很流行。 没有虚拟化, 服务商只能提供共享托管(不能控制服务器的软件)和独占托管(成本较高)。 当服务商提供租用虚拟机时, 一台物理服务器就可以运行多个虚拟机, 每个虚拟机看起来都是一台完整的服务器, 客户可以在虚拟机上安装自己想用的操作系统和软件, 但是只需支付较低的费用, 这就是市面上常见的“云”主机。 有的教材将第一类虚拟化技术称为裸金属架构, 将第二类虚拟化技术称为寄居架构。",
  "并行性与并发性的区别和联系 并行性和并发性是既相似又有区别的两个概念。 并行性是指两个或多个事件在同一时刻发生, 并发性是指两个或多个事件在同一时间间隔内发生。 在多道程序环境下, 并发性是指在一段时间内, 宏观上有多个程序同时运行, 但在单处理器系统中每个时刻却仅能有一道程序执行, 因此微观上这些程序只能分时地交替执行。 若在计算机系统中有多个处理器, 则这些可以并发执行的程序便被分配到多个处理器上, 实现并行执行, 即利用每个处理器来处理一个可并发执行的程序。",
  "特权指令与非特权指令 特权指令是指有特殊权限的指令, 由于这类指令的权限最大, 使用不当将导致整个系统崩溃, 如清内存、置时钟、分配系统资源、修改虚存的段表或页表、修改用户的访问权限等。 若所有程序都能使用这些指令, 则系统一天死机n次就不足为奇。 为保证系统安全, 这类指令不能直接提供给用户使用, 因此特权指令必须在内核态执行。 实际上, CPU在内核态下可以执行指令系统的全集。 形象地说, 特权指令是那些儿童不宜的东西, 而非特权指令是老少皆宜的东西。 为了防止用户程序中使用特权指令, 用户态下只能使用非特权指令, 内核态下可以使用全部指令。 在用户态下使用特权指令时, 将产生中断以阻止用户使用特权指令。 所以将用户程序放在用户态下运行, 而操作系统中必须使用特权指令的那部分程序在内核态下运行, 从而保证了系统的安全性和可靠性。 从用户态转换为内核态的唯一途径是中断或异常。",
  "访管指令与访管中断 访管指令(trap 指令)是一条在用户态下执行的指令。 在用户程序中, 因要求操作系统提供服务而有意识地使用访管指令, 从而产生一个中断事件(自愿中断), 将操作系统转换为内核态, 称为访管中断。 访管中断由访管指令产生, 程序员使用访管指令向操作系统请求服务。 为什么要在程序中引入访管指令呢? 这是因为用户程序只能在用户态下运行。 若用户程序想要完成在用户态下无法完成的工作, 该怎么办? 解决这个问题要靠访管指令。 访管指令本身不是特权指令, 其基本功能是让程序拥有“自愿进管”的手段, 从而引起访管中断。",
  "定义微内核结构OS的四个方面 1) 足够小的内核。 2) 基于客户/服务器模式。 3) 应用“机制与策略分离”原理。机制是指实现某一功能的具体执行机构。 策略则是在机制的基础上借助于某些参数和算法来实现该功能的优化, 或达到不同的功能目标。 在传统的OS中, 将机制放在OS内核的较低层中, 将策略放在内核的较高层中。 而在微内核 OS中, 通常将机制放在OS的微内核中。 正因如此, 才可以将内核做得很小。 4) 采用面向对象技术。基于面向对象技术中的“抽象”和“隐蔽”原则能控制系统的复杂性, 进一步利用“对象”“封装”和“继承”等概念还能确保操作系统的正确性、可靠性、易扩展性等。 正因如此, 面向对象技术被广泛应用于现代操作系统的设计之中。",
  "内存管理的基本原理和要求 内存管理(Memory Management)是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件技术一直在飞速发展, 内存容量也在不断增大, 但仍然不可能将所有用户进程和系统所需要的全部程序与数据放入主存, 因此操作系统必须对内存空间进行合理的划分和有效的动态分配。操作系统对内存的划分和动态分配, 就是内存管理的概念。 有效的内存管理在多道程序设计中非常重要, 它不仅可以方便用户使用存储器、提高内存利用率, 还可以通过虚拟技术从逻辑上扩充存储器。内存管理的主要功能有: 内存空间的分配与回收。由操作系统负责内存空间的分配和管理, 记录内存的空闲空间、内存的分配情况, 并回收已结束进程所占用的内存空间。 地址转换。程序的逻辑地址与内存中的物理地址不可能一致, 因此存储管理必须提供地址变换功能, 将逻辑地址转换成相应的物理地址。 内存空间的扩充。利用虚拟存储技术从逻辑上扩充内存。 内存共享。指允许多个进程访问内存的同一部分。例如, 多个合作进程可能需要访问同一块数据, 因此必须支持对内存共享区域进行受控访问。 存储保护。保证各个进程在各自的存储空间内运行, 互不干扰。 在进行具体的内存管理之前, 需要了解进程运行的基本原理和要求。",
  "逻辑地址与物理地址 编译后, 每个目标模块都从0号单元开始编址, 这称为该目标模块的相对地址(或逻辑地址)。当链接程序将各个模块链接成一个完整的可执行目标程序时, 链接程序顺序依次按各个模块的相对地址构成统一的从0号单元开始编址的逻辑地址空间(或虚拟地址空间)。进程在运行时, 看到和使用的地址都是逻辑地址。用户程序和程序员只需知道逻辑地址, 而内存管理的具体机制则是完全透明的。不同进程可以有相同的逻辑地址, 因为这些相同的逻辑地址可以映射到主存的不同位置。 物理地址空间是指内存中物理单元的集合, 它是地址转换的最终地址, 进程在运行时执行指令和访问数据, 最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时, 必须通过地址转换将逻辑地址转换成物理地址, 这个过程称为地址重定位。 操作系统通过内存管理部件(MMU)将进程使用的逻辑地址转换为物理地址。进程使用虚拟内存空间中的地址, 操作系统在相关硬件的协助下, 将它“转换”成真正的物理地址。逻辑地址通过页表映射到物理内存, 页表由操作系统维护并被处理器引用。",
  "程序的链接与装入 创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序, 通常需要以下几个步骤: 编译。由编译程序将用户源代码编译成若干目标模块。 链接。由链接程序将编译后形成的一组目标模块, 以及它们所需的库函数链接在一起, 形成一个完整的装入模块。 装入。由装入程序将装入模块装入内存运行。 将一个装入模块装入内存时, 有以下三种装入方式。 (1) 绝对装入 绝对装入方式只适用于单道程序环境。在编译时, 若知道程序将放到内存的哪个位置, 则编译程序将产生绝对地址的目标代码。装入程序按照装入模块的地址, 将程序和数据装入内存。程序中的逻辑地址与实际内存地址完全相同, 因此不需对程序和数据的地址进行修改。 (2) 可重定位装入 可重定位装入也称静态重定位。经过编译、链接后的装入模块的始址(起始地址)通常都是从0开始的, 程序中使用的指令和数据的地址都是相对于始址而言的逻辑地址。可根据内存的当前情况, 将装入模块装入内存的适当位置。在装入时对目标程序中的相对地址的修改过程称为重定位, 地址转换通常是在进程装入时一次完成的。 当一个作业装入内存时, 必须给它分配要求的全部内存空间, 若没有足够的内存, 则无法装入。作业一旦进入内存, 整个运行期间就不能在内存中移动, 也不能再申请内存空间。 (3) 动态运行时装入 动态运行时装入也称动态重定位。程序若要在内存中发生移动, 则要采用动态的装入方式。装入程序将装入模块装入内存后, 并不会立即将装入模块中的相对地址转换为绝对地址, 而是将这种地址转换推迟到程序真正要执行时才进行。因此, 装入内存后的所有地址均为相对地址。这种方式需要一个重定位寄存器(存放装入模块的起始位置)的支持。 动态重定位的优点:可以将程序分配到不连续的存储区;在程序运行前只需装入它的部分代码即可投入运行, 然后在程序运行期间, 根据需要动态申请分配内存;便于程序段的共享。 对目标模块进行链接时, 根据链接的时间不同, 分为以下三种链接方式。 (1) 静态链接 在程序运行之前, 先将各目标模块及它们所需的库函数链接成一个完整的装入模块, 以后不再拆开。 (2) 装入时动态链接 将用户源程序编译后所得到的一组目标模块, 在装入内存时, 采用边装入边链接的方式。其优点是便于修改和更新, 便于实现对目标模块的共享。 (3) 运行时动态链接 在程序执行中需要某目标模块时, 才对它进行链接。凡在程序执行中未用到的目标模块, 都不会被调入内存和链接到装入模块上。其优点是能加快程序的装入过程, 还可节省内存空间。",
  "进程的内存映像 不同于存放在硬盘上的可执行程序文件, 当一个程序调入内存运行时, 就构成了进程的内存映像。一个进程的内存映像一般有几个要素: 代码段:即程序的二进制代码, 代码段是只读的, 可以被多个进程共享。 数据段:即程序运行时加工处理的对象, 包括全局变量和静态变量。 进程控制块(PCB):存放在系统区。操作系统通过PCB来控制和管理进程。 堆:用来存放动态分配的变量。通过调用malloc函数动态地向高地址分配空间。 栈:用来实现函数调用。从用户空间的最大地址往低地址方向增长。 代码段和数据段在程序调入内存时就指定了大小, 而堆和栈不一样。当调用像 malloc 和 free这样的C标准库函数时, 堆可以在运行时动态地扩展和收缩。用户栈在程序运行期间也可以动态地扩展和收缩。",
  "内存保护 确保每个进程都有一个单独的内存空间。内存分配前, 需要保护操作系统不受用户进程的影响, 同时保护用户进程不受其他用户进程的影响。内存保护可采取两种方法: 在CPU中设置一对上、下限寄存器, 存放用户进程在主存中的下限和上限地址, 每当CPU要访问一个地址时, 分别和两个寄存器的值相比, 判断有无越界。 采用重定位寄存器(也称基地址寄存器)和界地址寄存器(也称限长寄存器)进行越界检查。重定位寄存器中存放的是进程的起始物理地址, 界地址寄存器中存放的是进程的最大逻辑地址。内存管理部件将逻辑地址与界地址寄存器进行比较, 若未发生地址越界, 则加上重定位寄存器的值后映射成物理地址, 再送交内存单元。 加载重定位寄存器和界地址寄存器时必须使用特权指令, 只有操作系统内核才可以加载这两个存储器。",
  "内存共享 并不是所有的进程内存空间都适合共享, 只有那些只读的区域才可以共享。可重入代码也称纯代码, 是一种允许多个进程同时访问但不允许被任何进程修改的代码。但在实际执行时, 也可以为每个进程配以局部数据区, 将在执行中可能改变的部分复制到该数据区, 这样, 程序在执行时只需对该私有数据区中的内存进行修改, 并不去改变共享的代码。 在分页系统中, 为实现代码共享, 应在每个进程的页表中都建立页表项, 它们都指向共享代码区的物理页号。对于分段系统, 不管该段有多大, 都只需为该段设置一个段表项, 指向共享代码段始址。",
  "内存分配与回收 存储管理方式随着操作系统的发展而发展。在操作系统由单道向多道发展时, 存储管理方式便由单一连续分配发展为固定分区分配。为了能更好地适应不同大小的程序要求, 又从固定分区分配发展到动态分区分配。为了更好地提高内存的利用率, 进而从连续分配方式发展到离散分配方式——页式存储管理。引入分段存储管理的目的, 主要是满足用户在编程和使用方面的要求。",
  "连续分配管理方式 连续分配方式是指为一个用户程序分配一个连续的内存空间。连续分配方式主要包括单一连续分配、固定分区分配和动态分区分配。",
  "单一连续分配 在单一连续分配方式中, 内存被分为系统区和用户区, 系统区仅供操作系统使用, 通常在低地址部分; 用户区内存中仅有一道用户程序, 即用户程序独占整个用户区。 这种方式的优点是简单、无外部碎片; 不需要进行内存保护。缺点是只能用于单用户、单任务的操作系统中; 有内部碎片; 内存的利用率极低。",
  "固定分区分配 固定分区分配是最简单的一种多道程序存储管理方式, 它将用户内存空间划分为若干固定大小的分区, 每个分区只装入一道作业。 在划分分区时有两种不同的方法。 分区大小相等。 分区大小不等。 为了便于分配和回收, 建立一张分区使用表。 这种方式存在两个问题: ①程序太大而放不进任何一个分区; ②当程序小于固定分区大小时, 也要占用一个完整的内存分区, 这样分区内部就存在空间浪费, 这种现象称为内部碎片。固定分区方式无外部碎片。",
  "动态分区分配 (1) 动态分区分配的基本原理 动态分区分配也称可变分区分配, 是指在进程装入内存时, 根据进程的实际需要, 动态地为之分配内存, 并使分区的大小正好适合进程的需要。 随着时间的推移, 内存中会产生越来越多的小内存块, 内存的利用率也随之下降。这些小内存块被称为外部碎片。外部碎片可通过紧凑技术来克服, 即操作系统不时地对进程进行移动和整理。 在动态分区分配中, 设置一张空闲分区链(表)。分配内存时, 检索空闲分区链, 找到所需的分区。回收内存时, 系统根据回收分区的始址, 从空闲分区链中找到相应的插入点, 此时可能出现四种情况: ①与前一空闲分区相邻, 则合并; ②与后一空闲分区相邻, 则合并; ③同时与前、后两个分区相邻, 则三者合并; ④没有相邻的空闲分区, 则为回收区新建一个表项。 (2) 基于顺序搜索的分配算法 首次适应(First Fit)算法。空闲分区按地址递增的次序排列。每次分配内存时, 顺序查找到第一个能满足大小的空闲分区, 分配给作业。 邻近适应(Next Fit)算法。也称循环首次适应算法, 分配内存时从上次查找结束的位置开始继续查找。 最佳适应(Best Fit)算法。空闲分区按容量递增的次序排列。每次分配内存时, 顺序查找到第一个能满足大小的空闲分区, 即最小的空闲分区, 分配给作业。 最坏适应(Worst Fit)算法。空闲分区按容量递减的次序排列。每次分配内存时, 查找到最大的空闲分区, 从中分割一部分空间给作业。 综合来看, 首次适应算法的开销小, 性能最好。 (3) 基于索引搜索的分配算法 快速适应算法。空闲分区的分类根据进程常用的空间大小进行划分。为每类(大小相同)空闲分区, 单独设立一个空闲分区链。 伙伴系统。规定所有分区的大小均为2的k次幂(k为正整数)。 哈希算法。根据空闲分区链表的分布规律, 建立哈希函数, 构建一张以空闲分区大小为关键字的哈希表, 每个表项记录一个对应空闲分区链的头指针。",
  "基本分页存储管理 将内存空间分为若干固定大小的分区, 称为页框、页帧或物理块。进程的逻辑地址空间也分为与块大小相等的若干区域, 称为页或页面。操作系统以页框为单位为各个进程分配内存空间。 分页管理不产生外部碎片。但会产生内部碎片(页内碎片)。 分页存储的几个基本概念 (1) 页面和页面大小 进程的逻辑地址空间中的每个页面有一个编号, 称为页号, 从0开始:内存空间中的每个页框也有一个编号, 称为页框号(或物理块号), 也从0开始。 为方便地址转换, 页面大小应是2的整数次幂。 (2) 地址结构 分页存储管理的逻辑地址结构包含两部分:前一部分为页号P, 后一部分为页内偏移量W。 (3) 页表 为了便于找到进程的每个页面在内存中存放的位置, 系统为每个进程建立一张页面映射表, 简称页表。进程的每个页面对应一个页表项, 每个页表项由页号和块号组成, 它记录了页面在内存中对应的物理块号。页表的作用是实现从页号到物理块号的地址映射。 基本地址变换机构 地址变换机构的任务是将逻辑地址转换为内存中的物理地址。地址变换是借助于页表实现的。 在系统中设置一个页表寄存器(PTR), 存放页表在内存的始址F和页表长度 M。设页面大小为L, 逻辑地址A到物理地址E的变换过程如下: ① 根据逻辑地址计算出页号 P=A/L、页内偏移量 W=A%L。 ② 判断页号是否越界, 若页号P≥页表长度M, 则产生越界中断, 否则继续执行。 ③ 在页表中查询页号对应的页表项, 确定页面存放的物理块号b。 ④ 计算物理地址 E=b*L+W, 用物理地址去访存。 具有快表的地址变换机构 在地址变换机构中增设一个具有并行查找能力的高速缓冲存储器——快表(TLB), 也称相联存储器, 用来存放当前访问的若干页表项, 以加速地址变换的过程。与此对应, 主存中的页表常称为慢表。 在具有快表的分页机制中, 地址的变换过程如下: ① CPU给出逻辑地址后, 由硬件进行地址转换, 将页号与快表中的所有页号进行比较。 ② 若找到匹配的页号, 说明要访问的页表项在快表中有副本, 则直接从中取出该页对应的物理块号, 与页内偏移量拼接形成物理地址。 ③ 若未找到匹配的页号, 则需要访问内存中的页表, 读出页表项后, 就能得到该页的物理块号, 再与页内偏移量拼接形成物理地址。找到页表项后, 应同时将其存入快表, 以便后面的再次访问。 两级页表 为解决页表占用过多连续内存空间的问题, 可采用离散分配方式, 为离散分配的页表再建立一张页表, 称为外层页表(或页目录)。 当采用两级分页时, 逻辑地址空间被划分为一级页号(页目录号)、二级页号和页内偏移量。 在页表的每个表项中, 存放的是进程的某页对应的物理块号。在外层页表的每个表项中, 存放的是某个页表分页的始址。 为了方便实现地址变换, 需要在系统中增设一个外层页表寄存器(也称页目录基址寄存器), 用于存放页目录始址。将逻辑地址中的页目录号作为页目录的索引, 从中找到对应页表的始址; 再用二级页号作为页表分页的索引, 从中找到对应的页表项; 将页表项中的物理块号和页内偏移拼接形成物理地址。共进行了三次访存。 对于更大的逻辑地址空间, 必须采用多级页表, 再对外层页表分页。",
  "基本分段存储管理 分页管理方式是从计算机的角度考虑设计的, 分段管理方式的提出则考虑了用户和程序员, 以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。 分段 分段系统将用户进程的逻辑地址空间划分为大小不等的段。每段从0开始编址, 并分配一段连续的地址空间(段内要求连续, 段间不要求连续, 进程的地址空间是二维的)。 分段存储管理的逻辑地址结构由段号S与段内偏移量W两部分组成。 在分段系统中, 段号和段内偏移量必须由用户显式提供。 段表 每个进程都有一张逻辑空间与内存空间映射的段表, 进程的每个段对应一个段表项, 段表项记录了该段在内存中的始址和段的长度。 地址变换机构 在系统中设置了一个段表寄存器, 用于存放段表始址F和段表长度M。从逻辑地址到物理地址E之间的地址变换过程如下: ① 从逻辑地址A中取出前几位为段号S, 后几位为段内偏移量W。 ② 判断段号是否越界, 若段号S≥段表长度M, 则产生越界中断, 否则继续执行。 ③ 在段表中查询段号对应的段表项。取出段表项中该段的段长C, 若W≥C, 则产生越界中断, 否则继续执行。 ④ 取出段表项中该段的始址b, 计算物理地址 E=b+W, 用物理地址E去访存。 分页和分段的对比 页是信息的物理单位, 分页的主要目的是提高内存利用率, 对用户是不可见的。段是信息的逻辑单位, 分段的主要目的是更好地满足用户需求, 对用户是可见的。 页的大小固定且由系统决定。段的长度不固定, 具体取决于用户所编写的程序。 分页管理的地址空间是一维的。分段管理的地址空间是二维的。 段的共享与保护 在分段系统中, 为实现段共享, 在系统中配置一张共享段表, 所有共享的段都在共享段表中占一个表项。 可重入代码或纯代码是一种允许多个进程同时访问的代码。 与分页管理类似, 分段管理的保护方法主要有两种: 一种是存取控制保护, 另一种是地址越界保护。",
  "段页式存储管理 将分页存储管理和分段存储管理这两种方法结合起来, 便形成了段页式存储管理方式。 在段页式系统中, 进程的地址空间首先被分成若干逻辑段, 每段都有自己的段号, 然后将各段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样, 将其分成若干和页面大小相同的物理块, 对内存的分配以物理块为单位。 在段页式系统中, 进程的逻辑地址分为三部分:段号、页号和页内偏移量。 为了实现地址变换, 系统为每个进程建立一张段表, 每个段对应一个段表项, 每个段有一张页表。系统中还应有一个段表寄存器。 在进行地址变换时, 首先通过段表查到页表始址, 然后通过页表找到物理块号, 最后形成物理地址。进行一次访问实际需要三次访问主存。段页式管理的地址空间是二维的。",
  "虚拟内存的基本概念 传统存储管理方式的特征 它们都具有以下两个共同的特征: 一次性。作业必须一次性全部装入内存后, 才能开始运行。 驻留性。作业被装入内存后, 就一直驻留在内存中, 其任何部分都不会被换出, 直至作业运行结束。 局部性原理 时间局部性。程序中的某条指令一旦执行, 不久后该指令可能再次执行; 某数据被访问过, 不久后该数据可能再次被访问。 空间局部性。一旦程序访问了某个存储单元, 在不久后, 其附近的存储单元也将被访问。 虚拟内存技术实际上建立了“内存-外存”的两级存储器结构, 利用局部性原理实现高速缓存。 虚拟存储器的定义和特征 基于局部性原理, 在程序装入时, 仅需将程序当前运行要用到的少数页面(或段)装入内存, 而将其余部分暂留在外存, 便可启动程序执行。在程序执行过程中, 当所访问的信息不在内存时, 由操作系统负责将所需信息从外存调入内存, 然后继续执行程序, 这个过程就是请求调页(或请求调段)功能。当内存空间不够时, 由操作系统负责将内存中暂时用不到的信息换出到外存, 从而腾出空间存放将要调入内存的信息, 这个过程就是页面置换(或段置換)功能。这样, 系统好像为用户提供了一个比实际内存容量大得多的存储器, 称为虚拟存储器。 虚拟存储器有以下三个主要特征: 多次性。无须在作业运行时一次性全部装入内存, 而是允许被分成多次调入内存。 对换性。在作业运行时无须一直常驻内存, 而是允许在作业运行过程中, 将那些暂不使用的程序和数据从内存调至外存的对换区(换出), 待以后需要时再将它们从外存调至内存(换进)。 虚拟性。从逻辑上扩充了内存的容量, 使用户看到的内存容量, 远大于实际容量。 虚拟内存技术的实现 虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式: 请求分页存储管理。 请求分段存储管理。 请求段页式存储管理。 一般需要的硬件支持有以下几个方面: 一定容量的内存和外存。 页表机制(或段表机制), 作为主要的数据结构。 中断机构, 当用户程序要访问的部分尚未调入内存时, 则产生中断。 地址变换机构, 逻辑地址到物理地址的变换。",
  "请求分页管理方式 请求分页系统建立在基本分页系统的基础之上, 为支持虚拟存储器功能而增加了请求调页和页面置换功能。 页表机制 在请求页表项中增加了4个字段。 状态位P。标记该页是否已调入内存。 访问字段A。记录本页在一段时间内被访问的次数, 或记录本页最近已有多长时间未被访问。 修改位M。标记该页在调入内存后是否被修改过。 外存地址。记录该页在外存的存放地址。 缺页中断机构 在请求分页系统中, 每当要访问的页面不在内存时, 便产生一个缺页中断, 请求操作系统的缺页中断处理程序处理。此时缺页的进程阻塞, 放入阻塞队列, 调页完成后再将其唤醒, 放回就绪队列。若内存中有空闲页框, 则为进程分配一个页框, 将所缺页面从外存装入该页框, 并修改页表中相应的表项。若内存中没有空闲页框, 则由页面置换算法选择一个页面淘汰, 若该页在内存期间被修改过, 则还要将其写回外存。 与一般的中断相比, 它有以下两个明显的区别: 在指令执行期间而非一条指令执行完后产生和处理中断, 属于内部异常。 一条指令在执行期间, 可能产生多次缺页中断。 地址变换机构 在基本分页系统地址变换机构的基础上, 为实现虚拟内存, 增加了产生和处理缺页中断, 及从内存中换出一页的功能。 请求分页系统的地址变换过程如下: ① 先检索快表, 若命中, 则从相应表项中取出该页的物理块号, 并修改页表项中的访问位。 ② 若快表未命中, 则要到页表中查找, 若找到, 则从相应表项中取出物理块号, 并将该页表项写入快表。 ③ 若在页表中未找到, 则需要进行缺页中断处理, 请求系统将该页从外存换入内存, 页面被调入内存后, 由操作系统负责更新页表和快表, 并获得物理块号。 ④ 利用得到的物理块号和页内地址拼接形成物理地址, 用该地址去访存。",
  "页框分配 驻留集大小 对于分页式的虚拟内存, 操作系统必须决定给特定的进程分配几个页框。给一个进程分配的页框的集合就是这个进程的驻留集。 驻留集越小, 驻留在内存中的进程就越多, 可以提高多道程序的并发度, 但分配给每个进程的页框太少, 会导致缺页率较高。 驻留集越大, 当分配给进程的页框超过某个数量时, 再为进程增加页框对缺页率的改善是不明显的, 反而只能是浪费内存空间。 内存分配策略 在请求分页系统中, 可采取两种内存分配策略, 即固定和可变分配策略。在进行置换时, 也可采取两种策略, 即全局和局部置换。于是可组合出下面三种适用的策略。 (1) 固定分配局部置换 为每个进程分配固定数量的物理块, 在进程运行期间都不改变。若进程在运行中发生缺页, 则只能从分配给该进程在内存的页面中选出一页换出。 (2) 可变分配全局置换 先为每个进程分配一定数量的物理块, 在进程运行期间可根据情况适当地增加或减少。若进程在运行中发生缺页, 则系统从空闲物理块队列中取出一块分配给该进程。 (3) 可变分配局部置换 为每个进程分配一定数量的物理块, 当某进程发生缺页时, 只允许从该进程在内存的页面中选出一页换出。若进程在运行中频繁地发生缺页中断, 则系统再为该进程分配若干物理块;反之, 若进程在运行中的缺页率特别低, 则可适当减少分配给该进程的物理块。 物理块调入算法 采用固定分配策略时, 可采用下述几种算法。 平均分配算法, 将系统中所有可供分配的物理块平均分配给各个进程。 按比例分配算法, 根据进程的大小按比例分配物理块。 优先权分配算法, 为重要和紧迫的进程分配较多的物理块。 调入页面的时机 预调页策略。可以预测不久之后可能被访问的页面, 将它们预先调入内存。 请求调页策略。进程在运行中需要访问的页面不在内存, 便提出请求, 由系统将其所需页面调入内存。 从何处调入页面 请求分页系统中的外存分为两部分: 用于存放文件的文件区和用于存放对换页面的对换区。对换区的磁盘I/O速度比文件区的更快。 系统拥有足够的对换区空间。可以全部从对换区调入所需页面, 以提高调页速度。 系统缺少足够的对换区空间。凡是不会被修改的文件都直接从文件区调入; 对于那些可能被修改的部分, 在将它们换出时必须放在对换区。 UNIX方式。与进程有关的文件都放在文件区, 因此未运行过的页面都应从文件区调入。曾经运行过但又被换出的页面, 应从对换区调入。",
  "页面置换算法 进程运行时, 若其访问的页面不在内存而需将其调入, 但内存已无空闲空间时, 就需要从内存中调出一页, 换出到外存。选择调出哪个页面的算法就称为页面置换算法。 最佳(OPT)置换算法 最佳置换算法选择淘汰的页面是以后永不使用的页面, 或是在最长时间内不再被访问的页面, 以便保证获得最低的缺页率。该算法无法实现。 先进先出(FIFO)页面置换算法 FIFO 算法选择淘汰的页面是最早进入内存的页面。该算法实现简单, 但与进程实际运行的规律不相适应, 性能较差。 FIFO 算法还会产生当为进程分配的物理块增多, 缺页次数不减反增的异常现象, 称为 Belady异常。 最近最久未使用(LRU)置换算法 LRU 算法选择淘汰的页面是最近最长时间未使用的页面, 它认为过去一段时间内未访问过的页面, 在最近的将来可能也不会被访问。 LRU 算法性能较好, 但实现起来需要寄存器和栈的硬件支持, 开销较大。 时钟(CLOCK) 置换算法 (1) 简单的CLOCK 置换算法 为每个页面设置一个访问位, 当某页首次被装入或被访问时, 其访问位被置为1。算法将内存中的页面链接成一个循环队列, 并有一个替换指针与之相关联。在选择淘汰一页时, 只需检查页面的访问位:若为0, 就选择该页换出:若为1, 则将它置为0, 暂不换出, 给予该页第二次驻留内存的机会, 再依次顺序检查下一个页面。 (2) 改进型 CLOCK 置换算法 在改进型 CLOCK算法中, 除考虑页面使用情况外, 还增加了置换代价——修改位。在选择页面换出时, 优先考虑既未使用过又未修改过的页面。由访问位A和修改位M可以组合成下面四种类型的页面: 1类(A=0, M=0): 最近未被访问, 且未被修改, 是最佳的淘汰页。 2类(A=0, M=1): 最近未被访问, 但已被修改, 是次佳的淘汰页。 3类(A=1, M=0): 最近已被访问, 但未被修改, 可能再被访问。 4类(A=1, M=1): 最近已被访问, 且已被修改, 可能再被访问。 算法执行时, 按1->2->3->4的顺序分轮扫描, 寻找并淘汰相应类别的页面。",
  "抖动和工作集 抖动 在页面置换过程中, 刚刚换出的页面马上又要换入内存, 刚刚换入的页面马上又要换出内存, 这种频繁的页面调度行为称为抖动或颠簸。 系统发生抖动的根本原因是, 分配给每个进程的物理块太少, 不能满足进程正常运行的基本要求。 工作集 工作集是指在某段时间间隔内, 进程要访问的页面集合。工作集反映了进程在接下来的一段时间内很有可能频繁访问的页面集合, 因此驻留集大小不能小于工作集大小, 否则进程在运行过程中会频繁缺页。",
  "页框回收 页面缓冲算法 页面缓冲算法在原页面置换算法的基础上增设已修改页面链表, 保存已修改且需要被换出的页面, 等被换出的页面数量达到一定值时, 再一起换出到磁盘, 以减少页面换出的开销。 为了显著降低页面换入/换出的频率, 在内存中设置了如下两个链表: 空闲页面链表。当有一个未被修改的页面要换出时, 实际上并不将它换出到磁盘, 而将它所在的页框挂在空闲链表的链尾。 修改页面链表。当进程需要将一个已修改的页面换出时, 系统并不立即将它换出到磁盘, 而将它所在的页框挂在修改页面链表的末尾。 页框回收 当系统可分配的内存不足时, 就必须回收一些页框。属于内核的大部分页框都是不能回收的, 而由进程使用的页框大部分是可以回收的。 在Linux内核中, 设置了一个负责页面换出的守护进程kswapd, 它定期检查内存的使用情况, 当空闲页框数量少于特定的阈值时, 便发起页框回收操作。",
  "内存映射文件 内存映射文件(Memory-Mapped Files)是操作系统向应用程序提供的一个系统调用, 它与虚拟内存有些相似, 在磁盘文件与进程的虚拟地址空间之间建立映射关系。 进程通过该系统调用, 将一个文件映射到其虚拟地址空间的某个区域, 之后就能用访问内存的方式来读/写文件。磁盘文件的读/写由操作系统负责完成, 对进程而言是透明的。在映射进程的页面时, 不会实际读入文件的内容, 而只在访问页面时才被每次一页地读入。当进程退出或关闭文件映射时, 所有被改动的页面才被写回磁盘文件。 内存映射文件带来的好处主要是: ①使程序员的编程更简单; ②方便多个进程共享同一个磁盘文件。",
  "虚拟存储器性能影响因素 缺页率是影响虚拟存储器性能的主要因素, 而缺页率又受到页面大小、分配给进程的物理块数、页面置换算法以及程序的编制方法的影响。 根据局部性原理, 页面较大则缺页率较低, 页面较小则缺页率较高。 分配给进程的物理块数越多, 缺页率就越低。 好的页面置换算法可使进程在运行过程中具有较低的缺页率。 写回磁盘的频率。在系统中建立一个已修改换出页面的链表, 可显著减少磁盘I/O的次数。 编写程序的局部化程度越高, 执行时的缺页率就越低。",
  "进程的概念和特征 进程的概念 在多道程序环境下, 允许多个程序并发执行, 此时它们将失去封闭性, 并具有间断性及不可再现性的特征。为此引入了进程(Process)的概念, 以便更好地描述和控制程序的并发执行, 实现操作系统的并发性和共享性(最基本的两个特性)。 为了使参与并发执行的每个程序(含数据)都能独立地运行, 必须为之配置一个专门的数据结构, 称为进程控制块(Process Control Block,PCB)。系统利用PCB来描述进程的基本情况和运行状态, 进而控制和管理进程。相应地, 由程序段、相关数据段和PCB 三部分构成了进程实体(也称进程映像)。所谓创建进程, 就是创建进程的PCB; 而撤销进程, 就是撤销进程的PCB。 从不同的角度, 进程可以有不同的定义, 比较典型的定义有: 进程是一个正在执行程序的实例。 进程是一个程序及其数据从磁盘加载到内存后, 在CPU上的执行过程。 进程是一个具有独立功能的程序在一个数据集合上运行的过程。 引入进程实体的概念后, 我们可将传统操作系统中的进程定义为:“进程是进程实体的运行过程, 是系统进行资源分配和调度的一个独立单位。” 读者要准确理解这里说的系统资源。它指CPU、存储器和其他设备服务于某个进程的“时间”, 例如将CPU资源理解为CPU的时间片才是准确的。因为进程是这些资源分配和调度的独立单位, 即“时间片”分配的独立单位, 这就决定了进程一定是一个动态的、过程性的概念。 进程的特征 进程是由多道程序的并发执行而引出的, 它和程序是两个截然不同的概念。程序是静态的, 进程是动态的, 进程的基本特征是对比单个程序的顺序执行提出的。 动态性。进程是程序的一次执行, 它有着创建、活动、暂停、终止等过程, 具有一定的生命周期, 是动态地产生、变化和消亡的。动态性是进程最基本的特征。 并发性。指多个进程同存于内存中, 能在一段时间内同时运行。引入进程的目的就是使进程能和其他进程并发执行。并发性是进程的重要特征, 也是操作系统的重要特征。 独立性。指进程是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序, 都不能作为一个独立的单位参与运行。 异步性。由于进程的相互制约, 使得进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性, 为此在操作系统中必须配置相应的进程同步机制。",
  "进程的组成 进程是一个独立的运行单位, 也是操作系统进行资源分配和调度的基本单位。它由以下三部分组成, 其中最核心的是进程控制块(PCB)。 进程控制块 进程创建时, 操作系统为它新建一个PCB, 该结构之后常驻内存, 任意时刻都可以存取, 并在进程结束时删除。PCB是进程实体的一部分, 是进程存在的唯一标志。 进程执行时, 系统通过其PCB 了解进程的现行状态信息, 以便操作系统对其进行控制和管理; 进程结束时, 系统收回其PCB, 该进程随之消亡。 当操作系统希望调度某个进程运行时, 要从该进程的PCB中查出其现行状态及优先级; 在调度到某个进程后, 要根据其PCB中所保存的CPU状态信息, 设置该进程恢复运行的现场, 并根据其PCB中的程序和数据的内存始址, 找到其程序和数据; 进程在运行过程中, 当需要和与之合作的进程实现同步、通信或访问文件时, 也需要访问PCB; 当进程由于某种原因此暂停运行时, 又需将其断点的CPU环境保存在PCB中。可见, 在进程的整个生命期中, 系统总是通过PCB对进程进行控制的, 亦即系统唯有通过进程的PCB才能感知到该进程的存在。 PCB 主要包括进程描述信息、进程控制和管理信息、资源分配清单和CPU相关信息等。各部分的主要说明如下: 进程描述信息。进程标识符:标志各个进程, 每个进程都有一个唯一的标识号。用户标识符:进程所归属的用户, 用户标识符主要为共享和保护服务。 进程控制和管理信息。进程当前状态:描述进程的状态信息, 作为CPU分配调度的依据。进程优先级:描述进程抢占CPU的优先级, 优先级高的进程可优先获得CPU。 资源分配清单, 用于说明有关内存地址空间或虚拟地址空间的状况, 所打开文件的列表和所使用的输入/输出设备信息。 处理机相关信息, 也称CPU上下文, 主要指CPU中各寄存器的值。当进程处于执行态时, CPU的许多信息都在寄存器中。当进程被切换时, CPU状态信息都必须保存在相应的PCB中, 以便在该进程重新执行时, 能从断点继续执行。 在一个系统中, 通常存在着许多进程的PCB, 有的处于就绪态, 有的处于阻塞态, 而且阻塞的原因各不相同。为了方便进程的调度和管理, 需要将各个进程的PCB用适当的方法组织起来。目前, 常用的组织方式有链接方式和索引方式两种。链接方式将同一状态的PCB链接成一个队列, 不同状态对应不同的队列, 也可将处于阻塞态的进程的PCB, 根据其阻塞原因的不同, 排成多个阻塞队列。索引方式将同一状态的进程组织在一个索引表中, 索引表的表项指向相应的PCB, 不同状态对应不同的索引表, 如就绪索引表和阻塞索引表等。 程序段 程序段就是能被进程调度程序调度到CPU 执行的程序代码段。注意, 程序可被多个进程共享, 即多个进程可以运行同一个程序。 数据段 一个进程的数据段, 可以是进程对应的程序加工处理的原始数据, 也可以是程序执行时产生的中间或最终结果。",
  "进程的状态与转换 进程在其生命周期内, 由于系统中各个进程之间的相互制约及系统的运行环境的变化, 使得进程的状态也在不断地发生变化。通常进程有以下5种状态, 前3种是进程的基本状态。 运行态。进程正在CPU上运行。在单CPU中, 每个时刻只有一个进程处于运行态。 就绪态。进程获得了除CPU外的一切所需资源, 一旦得到CPU, 便可立即运行。系统中处于就绪态的进程可能有多个, 通常将它们排成一个队列, 称为就绪队列。 阻塞态, 也称等待态。进程正在等待某一事件而暂停运行, 如等待某个资源可用(不包括CPU)或等待1/0完成。即使CPU空闲, 该进程也不能运行。系统通常将处于阻塞态的进程也排成一个队列, 甚至根据阻塞原因的不同, 设置多个阻塞队列。 创建态。进程正在被创建, 尚未转到就绪态。创建进程需要多个步骤:首先申请一个空白PCB, 并向PCB中填写用于控制和管理进程的信息;然后为该进程分配运行时所必须的资源;最后将该进程转入就绪态并插入就绪队列。但是, 若进程所需的资源尚不能得到满足, 如内存不足, 则创建工作尚未完成, 进程此时所处的状态称为创建态。 终止态。进程正从系统中消失, 可能是进程正常结束或其他原因退出运行。进程需要结束运行时, 系统首先将该进程置为终止态, 然后进一步处理资源释放和回收等工作。 区分就绪态和阻塞态:就绪态是指进程仅缺少CPU, 只要获得CPU就立即运行;而阻塞态是指进程需要其他资源(除了CPU)或等待某一事件。 3种基本状态之间的转换如下: 就绪态→运行态:处于就绪态的进程被调度后, 获得CPU资源(分派CPU的时间片), 于是进程由就绪态转换为运行态。 运行态→就绪态:处于运行态的进程在时间片用完后, 不得不让出CPU, 从而进程由运行态转换为就绪态。此外, 在可剥夺的操作系统中, 当有更高优先级的进程就绪时, 调度程序将正在执行的进程转换为就绪态, 让更高优先级的进程执行。 运行态→阻塞态:进程请求某一资源(如外设)的使用和分配或等待某一事件的发生(如I/O 操作的完成)时, 它就从运行态转换为阻塞态。进程以系统调用的形式请求操作系统提供服务, 这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。 阻塞态→就绪态:进程等待的事件到来时, 如I/O操作完成或中断结束时, 中断处理程序必须将相应进程的状态由阻塞态转换为就绪态。 需要注意的是, 一个进程从运行态变为阻塞态是主动的行为, 而从阻塞态变为就绪态是被动的行为, 需要其他相关进程的协助。",
  "进程控制 进程控制的主要功能是对系统中的所有进程实施有效的管理, 它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中, 一般将进程控制用的程序段称为原语, 原语的特点是执行期间不允许中断, 它是一个不可分割的基本单位。 进程的创建 允许一个进程创建另一个进程, 此时创建者称为父进程, 被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程终止时, 应将其从父进程那里获得的资源还给父进程。 在操作系统中, 终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下(创建原语): 为新进程分配一个唯一的进程标识号, 并申请一个空白PCB(PCB是有限的)。若PCB申请失败, 则创建失败。 为进程分配其运行所需的资源, 如内存、文件、I/O设备和CPU时间等(在PCB中体现)。这些资源或从操作系统获得, 或仅从其父进程获得。若资源不足(如内存), 则并不是创建失败, 而是处于创建态, 等待内存资源。 初始化PCB, 主要包括初始化标志信息、初始化CPU状态信息和初始化CPU控制信息,以及设置进程的优先级等。 若进程就绪队列能够接纳新进程, 则将新进程插入就绪队列, 等待被调度运行。 进程的终止 引起进程终止的事件主要有:①正常结束, 表示进程的任务已完成并准备退出运行。②异常结束, 表示进程在运行时, 发生了某种异常事件, 使程序无法继续运行, 如存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、I/O故障等。③外界干预, 指进程应外界的请求而终止运行, 如操作员或操作系统干预、父进程请求和父进程终止。 操作系统终止进程的过程如下(终止原语): 根据被终止进程的标识符, 检索出该进程的PCB, 从中读出该进程的状态。 若被终止进程处于运行状态, 立即终止该进程的执行, 将CPU资源分配给其他进程。 若该进程还有子孙进程, 则通常需将其所有子孙进程终止(有些系统无此要求)。 将该进程所拥有的全部资源, 或归还给其父进程, 或归还给操作系统。 将该PCB从所在队列(链表)中删除。 有些系统不允许子进程在父进程终止的情况下存在, 对于这类系统, 若一个进程终止, 则它的所有子进程也终止, 这种现象称为级联终止。然而, 不是所有操作系统都是这么设计的。 进程的阻塞和唤醒 正在执行的进程, 由于期待的某些事件未发生, 如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新任务可做等, 进程便通过调用阻塞原语(Block), 使自己由运行态变为阻塞态。可见, 阻塞是进程自身的一种主动行为, 也因此只有处于运行态的进程(获得CPU), 才可能将其转为阻塞态。阻塞原语的执行过程如下: 找到将要被阻塞进程的标识号(PID)对应的PCB。 若该进程为运行态, 则保护其现场, 将其状态转为阻塞态, 停止运行。 将该PCB插入相应事件的等待队列, 将CPU资源调度给其他就绪进程。 当被阻塞进程所期待的事件出现时, 如它所期待的I/O操作已完成或其所期待的数据已到达, 由有关进程(比如, 释放该1/0设备的进程, 或提供数据的进程)调用唤醒原语(Wakeup), 将等待该事件的进程唤醒。唤醒原语的执行过程如下: 在该事件的等待队列中找到相应进程的PCB。 将其从等待队列中移出, 并置其状态为就绪态。 将该PCB插入就绪队列, 等待调度程序调度。 应当注意, Block 原语和 Wakeup 原语是一对作用刚好相反的原语, 必须成对使用。若在某个进程中调用了 Block原语, 则必须在与之合作的或其他相关的进程中安排一条相应的 Wakeup原语, 以便唤醒阻塞进程;否则, 阻塞进程将因不能被唤醒而永久地处于阻塞态。",
  "进程的通信 进程通信是指进程之间的信息交换。PV操作(见2.3节)是低级通信方式, 高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类。 共享存储 在通信的进程之间存在一块可直接访问的共享空间, 通过对这片共享空间进行读/写操作实现进程之间的信息交换。在对共享空间进行读/写操作时, 需要使用同步互斥工具(如P操作、V操作)对共享空间的读/写进行控制。共享存储又分为两种:低级方式的共享是基于数据结构的共享:高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具, 而数据交换则由用户自己安排读/写指令完成。 注意, 进程空间一般都是独立的, 进程运行期间一般不能访问其他进程的空间, 想让两个进程共享空间, 必须通过特殊的系统调用实现, 而进程内的线程是自然共享进程空间的。 消息传递 若通信的进程之间不存在可直接访问的共享空间, 则必须利用操作系统提供的消息传递方法实现进程通信。在消息传递系统中, 进程间的数据交换以格式化的消息(Message)为单位。进程通过操作系统提供的发送消息和接收消息两个原语进行数据交换。这种方式隐藏了通信实现细节, 使通信过程对用户透明, 简化了通信程序的设计, 是当前应用最广泛的进程间通信机制。在微内核操作系统中, 微内核与服务器之间的通信就采用了消息传递机制。该机制能很好地支持多CPU系统、分布式系统和计算机网络, 因此也成为这些领域最主要的通信工具。 直接通信方式。发送进程直接将消息发送给接收进程, 并将它挂在接收进程的消息缓冲队列上, 接收进程从消息缓冲队列中取得消息。 间接通信方式。发送进程将消息发送到某个中间实体, 接收进程从中间实体取得消息。这种中间实体一般称为信箱。该通信方式广泛应用于计算机网络中。 管道通信 管道是一个特殊的共享文件, 也称pipe文件, 数据在管道中是先进先出的。管道通信允许两个进程按生产者-消费者方式进行通信。为了协调双方的通信, 管道机制必须提供三方面的协调能力:①互斥, 指当一个进程对管道进行读/写操作时, 其他进程必须等待。②同步, 指写进程向管道写入一定数量的数据后, 写进程阻塞, 直到读进程取走数据后再将它唤醒; 读进程将管道中的数据取空后, 读进程阻塞, 直到写进程将数据写入管道后才将其唤醒。③确定对方的存在。 在Linux中, 管道是一种使用非常频繁的通信机制。从本质上说, 管道也是一种文件, 但它又和一般的文件有所不同, 管道可以克服使用文件进行通信的两个问题, 具体表现如下: 限制管道的大小。管道文件是一个固定大小的缓冲区, 在Linux中该缓冲区的大小为4KB, 这使得它的大小不像普通文件那样不加检验地增长。 读进程也可能工作得比写进程快。当管道内的数据已被读取时, 管道变空。当这种情况发生时, 一个随后的read()调用将被阻塞, 等待某些数据的写入。 管道只能由创建进程所访问, 当父进程创建一个管道后, 管道是一种特殊文件, 子进程会继承父进程的打开文件, 因此子进程也继承父进程的管道, 并可用它来与父进程进行通信。 从管道读数据是一次性操作, 数据一旦被读取, 就释放空间以便写更多数据。普通管道只允许单向通信, 若要实现两个进程双向通信, 则需要定义两个管道。 信号 信号(Signal)是一种用于通知进程发生了某个事件的机制。不同的系统事件对应不同的信号类型, 每类信号对应一个序号。 在进程的PCB中, 用至少位向量记录该进程的待处理信号。若给某个进程发送一个信号, 则把该类信号对应的位修改为1。一旦该信号被处理, 就把对应的位修改为0。此外, 还用另一个位向量记录被阻塞(被屏蔽)的信号。当某个位为1时, 表示该位对应的信号类型将被进程忽略, 无须响应。 信号的发送方式主要有两种: 内核给某个进程发送信号。当内核检测到某个特定的系统事件时, 就给进程发送信号。 一个进程给另一个进程发送信号。进程可以调用kill函数, 要求内核发送一个信号给目的进程。 当操作系统把一个进程从内核态切换到用户态时会检查该进程是否有未被阻塞的待处理信号, 若有, 则强制进程接收信号并立即处理。信号的处理方式有两种: 执行默认的信号处理程序。操作系统为每类信号预设了默认的信号处理程序。 执行进程定义的信号处理程序。进程可为某类信号自定义信号处理程序。 信号处理程序运行结束后, 通常会返回进程的下一条指令继续执行。",
  "线程和多线程模型 线程的基本概念 引入进程的目的是更好地使多道程序并发执行, 提高资源利用率和系统吞吐量; 而引入线程(Threads)的目的则是减小程序在并发执行时所付出的时空开销, 提高操作系统的并发性能。 线程最直接的理解就是轻量级进程, 它是一个基本的CPU执行单元, 也是程序执行流的最小单元, 由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体, 是被系统独立调度和分派的基本单位, 线程自己不拥有系统资源, 只拥有一点儿在运行中必不可少的资源, 但它可与同属一个进程的其他线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程, 同一进程中的多个线程之间可以并发执行。由于线程之间相互制约, 致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。 引入线程后, 进程的内涵发生了改变, 进程只作为除 CPU外的系统资源的分配单元, 而线程则作为CPU的分配单元。由于一个进程内部有多个线程, 若线程的切换发生在同一个进程内部, 则只需要很少的时空开销。 线程与进程的比较 调度。在传统的操作系统中, 拥有资源和独立调度的基本单位都是进程, 每次调度都要进行上下文切换, 开销较大。在引入线程的操作系统中, 线程是独立调度的基本单位, 而线程切换的代价远低于进程。在同一进程中, 线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时, 会引起进程切换。 并发性。在引入线程的操作系统中, 不仅进程之间可以并发执行, 一个进程中的多个线程之间也可并发执行, 甚至不同进程中的线程也能并发执行, 从而使操作系统具有更好的并发性, 提高了系统资源的利用率和系统的吞吐量。 拥有资源。进程是系统中拥有资源的基本单位, 而线程不拥有系统资源(仅有一点必不可少、能保证独立运行的资源), 但线程可以访问其隶属进程的系统资源, 这主要表现在属于同一进程的所有线程都具有相同的地址空间。 独立性。每个进程都拥有独立的地址空间和资源, 除了共享全局变量, 不允许其他进程访问。某个进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的, 它们共享进程的地址空间和资源。 系统开销。在创建或撤销进程时, 系统都要为之分配或回收进程控制块(PCB)及其他资源, 如内存空间、I/O设备等。操作系统为此所付出的开销, 明显大于创建或撤销线程时的开销。类似地, 在进程切换时涉及进程上下文的切换, 而线程切换时只需保存和设置少量寄存器内容, 开销很小。 支持多处理器系统。对于传统单线程进程, 不管有多少个CPU, 进程只能运行在一个CPU上。对于多线程进程, 可将进程中的多个线程分配到多个CPU上执行。 线程的属性 线程是一个轻型实体, 它不拥有系统资源, 但每个线程都应有一个唯一的标识符和一个线程控制块, 线程控制块记录线程执行的寄存器和栈等现场状态。 不同的线程可以执行相同的程序, 即同一个服务程序被不同的用户调用时, 操作系统将它们创建成不同的线程。 同一进程中的各个线程共享该进程所拥有的资源。 线程是CPU的独立调度单位, 多个线程是可以并发执行的。在单CPU的计算机系统中, 各线程可交替地占用CPU; 在多CPU的计算机系统中, 各线程可同时占用不同的CPU, 若各个CPU同时为一个进程内的各线程服务, 则可缩短进程的处理时间。 一个线程被创建后, 便开始了它的生命周期, 直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。 线程的状态与转换 与进程一样, 各线程之间也存在共享资源和相互合作的制约关系, 致使线程在运行时也具有间断性。相应地, 线程在运行时也具有下面三种基本状态。 执行态:线程已获得CPU而正在运行。 就绪态:线程已具备各种执行条件, 只需再获得CPU便可立即执行。 阻塞态:线程在执行中因某事件受阻而处于暂停状态。 线程这三种基本状态之间的转换和进程基本状态之间的转换是一样的。 线程的组织与控制 (1) 线程控制块 与进程类似, 系统也为每个线程配置一个线程控制块TCB, 用于记录控制和管理线程的信息。线程控制块通常包括:①线程标识符;②一组寄存器, 包括程序计数器、状态寄存器和通用寄存器;③线程运行状态, 用于描述线程正处于何种状态;④优先级;⑤线程专有存储区, 线程切换时用于保存现场等;⑥堆栈指针, 用于过程调用时保存局部变量及返回地址等。 同一进程中的所有线程都能访问进程的地址空间和全局变量。但是, 每个线程都拥有自己的堆栈, 且互不共享。 (2) 线程的创建 线程也是具有生命期的, 它由创建而产生, 由调度而执行, 由终止而消亡。 用户程序启动时, 通常仅有一个称为初始化线程的线程正在执行, 其主要功能是用于创建新线程。在创建新线程时, 需要利用一个线程创建函数, 并提供相应的参数, 如指向线程主程序的入口指针、堆栈的大小、线程优先级等。线程创建函数执行完后, 将返回一个线程标识符。 (3) 线程的终止 当一个线程完成自己的任务后, 或线程在运行中出现异常而要被强制终止时, 由终止线程调用相应的函数执行终止操作。但是有些线程(主要是系统线程)一旦被建立, 便一直运行而不会被终止。通常, 线程被终止后并不立即释放它所占有的资源, 只有当进程中的其他线程执行了分离函数后, 被终止线程才与资源分离, 此时的资源才能被其他线程利用。 线程的实现方式 线程的实现可以分为两类: 用户级线程(User-Level Thread, ULT)和内核级线程(Kernel-Level Thread, KLT)。内核级线程也称内核支持的线程。 (1) 用户级线程(ULT) 在用户级线程中, 有关线程管理(创建、撤销和切换等)的所有工作都由应用程序在用户空间内(用户态)完成, 无须操作系统干预, 内核意识不到线程的存在。 这种实现方式的优点如下:①线程切换不需要转换到内核空间, 节省了模式切换的开销。②调度算法可以是进程专用的, 不同的进程可根据自身的需要, 对自己的线程选择不同的调度算法。③用户级线程的实现与操作系统平台无关, 对线程管理的代码是属于用户程序的一部分。 这种实现方式的缺点如下:①系统调用的阻塞问题, 当线程执行一个系统调用时, 不仅该线程被阻塞, 进程内的所有线程也都被阻塞。②不能发挥多CPU的优势, 内核每次分配给一个进程的仅有一个CPU, 因此进程中仅有一个线程能执行。 (2) 内核级线程(KLT) 在操作系统中, 无论是系统进程还是用户进程, 都是在操作系统内核的支持下运行的, 与内核紧密相关。内核级线程同样也是在内核的支持下运行的, 线程管理的所有工作也是在内核空间内(内核态)实现的。操作系统也为每个内核级线程设置一个线程控制块TCB, 内核根据该控制块感知某线程的存在, 并对其加以控制。 这种实现方式的优点如下:①能发挥多CPU的优势, 内核能同时调度同一进程中的多个线程并行执行。②若进程中的一个线程被阻塞, 则内核可以调度该进程中的其他线程占用CPU, 也可运行其他进程中的线程。③内核支持线程具有很小的数据结构和堆栈, 线程切换比较快、开销小。④内核本身也可采用多线程技术, 可以提高系统的执行速度和效率。 这种实现方式的缺点如下:同一进程中的线程切换, 需要从用户态转到内核态进行, 系统开销较大。 (3) 组合方式 有些系统使用组合方式的多线程实现。在组合实现方式中, 内核支持多个内核级线程的建立、调度和管理, 同时允许用户程序建立、调度和管理用户级线程。一些内核级线程对应多个用户级线程, 这是用户级线程通过时分多路复用内核级线程实现的。同一进程中的多个线程可以同时在多CPU上并行执行, 且在阻塞一个线程时不需要将整个进程阻塞, 所以组合方式能结合 KLT和ULT的优点, 并且克服各自的不足。 多线程模型 在同时支持用户级线程和内核级线程的系统中, 用户级线程和内核级线程连接方式的不同, 形成了下面三种不同的多线程模型。 多对一模型。将多个用户级线程映射到一个内核级线程。每个进程只被分配一个内核级线程, 线程的调度和管理在用户空间完成。 优点:线程管理是在用户空间进行的, 无须切换到内核态, 因此效率比较高。 缺点:若一个线程在访问内核时发生阻塞, 则整个进程都会被阻塞; 在任何时刻, 只有一个线程能够访问内核, 多个线程不能同时在多个CPU上运行。 一对一模型。将每个用户级线程映射到一个内核级线程。每个进程有与用户级线程数量相同的内核级线程, 线程切换由内核完成, 需要切换到内核态。 优点:当一个线程被阻塞后, 允许调度另一个线程运行, 所以并发能力较强。 缺点:每创建一个用户线程, 相应地就需要创建一个内核线程, 开销较大。 多对多模型。将n个用户级线程映射到m个内核级线程上, 要求n≥m。 特点:既克服了多对一模型并发度不高的缺点, 又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。此外, 还拥有上述两种模型各自的优点。",
  "调度的概念 调度的基本概念 在多道程序系统中, 进程的数量往往多于CPU的个数, 因此进程争用CPU的情况在所难免。 CPU 调度是对CPU进行分配, 即从就绪队列中按照一定的算法(公平、高效的原则)选择一个进程并将CPU分配给它运行, 以实现进程并发地执行。 CPU 调度是多道程序操作系统的基础, 是操作系统设计的核心问题。 调度的层次 一个作业从提交开始直到完成, 往往要经历以下三级调度。 (1) 高级调度(作业调度) 按照某种规则从外存上处于后备队列的作业中挑选一个(或多个), 给它(们)分配内存、I/O 设备等必要的资源, 并建立相应的进程, 以使它(们)获得竞争CPU的权利。简言之, 作业调度就是内存与辅存之间的调度。每个作业只调入一次、调出一次。 多道批处理系统中大多配有作业调度, 而其他系统中通常不需要配置作业调度。 (2) 中级调度(内存调度) 引入中级调度的目的是提高内存利用率和系统吞吐量。为此, 将那些暂时不能运行的进程调至外存等待, 此时进程的状态称为挂起态。当它们已具备运行条件且内存又稍有空闲时, 由中级调度来决定将外存上的那些已具备运行条件的挂起进程再重新调入内存, 并修改其状态为就绪态, 挂在就绪队列上等待。中级调度实际上是存储器管理中的对换功能。 (3) 低级调度(进程调度) 按照某种算法从就绪队列中选取一个进程, 将CPU 分配给它。进程调度是最基本的一种调度, 在各种操作系统中都必须配置这级调度。进程调度的频率很高, 一般几十毫秒一次。 三级调度的联系 作业调度从外存的后备队列中选择一批作业进入内存, 为它们建立进程, 这些进程被送入就绪队列, 进程调度从就绪队列中选出一个进程, 并将其状态改为运行态, 将CPU分配给它。中级调度是为了提高内存的利用率, 系统将那些暂时不能运行的进程挂起来。 作业调度为进程活动做准备, 进程调度使进程正常活动起来。 中级调度将暂时不能运行的进程挂起, 中级调度处于作业调度和进程调度之间。 作业调度次数少, 中级调度次数略多, 进程调度频率最高。 进程调度是最基本的, 不可或缺。",
  "调度的实现 调度程序(调度器) 用于调度和分派CPU的组件称为调度程序, 它通常由三部分组成。 排队器。将系统中的所有就绪进程按照一定的策略排成一个或多个队列, 以便于调度程序选择。 分派器。依据调度程序所选的进程, 将其从就绪队列中取出, 将CPU分配给新进程。 上下文切换器。在对CPU进行切换时, 会发生两对上下文的切换操作:第一对, 将当前进程的上下文保存到其PCB中, 再装入分派程序的上下文, 以便分派程序运行;第二对, 移出分派程序的上下文, 将新选进程的CPU现场信息装入CPU的各个相应寄存器。 在上下文切换时, 需要执行大量load 和 store指令, 以保存寄存器的内容, 因此会花费较多时间。 调度的时机、切换与过程 现代操作系统中, 应该进行进程调度与切换的情况如下: 创建新进程后, 父进程和子进程都处于就绪态, 因此需要决定是运行父进程还是运行子进程。 进程正常结束或异常终止后, 必须从就绪队列中选择某个进程运行。 当进程因I/O请求、信号量操作或其他原因此被阻塞时, 必须调度其他进程运行。 当1/0设备准备就绪后, 发出I/O 中断, 原先等待I/O的进程从阻塞态变为就绪态, 此时需要决定是让新的就绪进程投入运行, 还是让中断发生时运行的进程继续执行。 不能进行进程的调度与切换的情况如下: 在处理中断的过程中。 需要完全屏蔽中断的原子操作过程中。 若在上述过程中发生了引起调度的条件, 则不能马上进行调度和切换, 应置系统的请求调度标志, 直到上述过程结束后才进行相应的调度与切换。 进程调度的方式 通常有以下两种进程调度方式: 非抢占调度方式, 也称非剥夺方式。是指当一个进程正在CPU上执行时, 即使有某个更为重要或紧迫的进程进入就绪队列, 仍然让正在执行的进程继续执行, 直到该进程运行完成或发生某种事件而进入阻塞态时, 才将CPU分配给其他进程。 非抢占调度方式的优点是实现简单、系统开销小, 适用于早期的批处理系统, 但它不能用于分时系统和大多数的实时系统。 抢占调度方式, 也称剥夺方式。是指当一个进程正在CPU上执行时, 若有某个更为重要或紧迫的进程需要使用CPU, 则允许调度程序根据某种原则去暂停正在执行的进程, 将CPU 分配给这个更为重要或紧迫的进程。 抢占调度方式对提高系统吞吐率和响应效率都有明显的好处。但“抢占”不是一种任意性行为, 必须遵循一定的原则, 主要有优先权、短进程优先和时间片原则等。 闲逛进程 当进程切换时, 若系统中没有就绪进程, 则会调度闲逛进程(Idle Process)运行, 它的PID为0。若没有其他进程就绪, 则该进程就一直运行, 并在指令周期后测试中断。闲逛进程的优先级最低, 没有就绪进程时才会运行闲逛进程, 只要有进程就绪, 就会立即让出CPU。 闲逛进程不需要CPU之外的资源, 它不会被阻塞。 两种线程的调度 用户级线程调度。因为内核并不知道线程的存在, 所以内核还是和以前一样, 选择一个进程, 并给予时间控制。由进程中的调度程序决定哪个线程运行。 内核级线程调度。内核选择一个特定线程运行, 通常不用考虑该线程属于哪个进程。对被选择的线程赋予一个时间片, 若超过了时间片, 则会强制挂起该线程。 用户级线程的线程切换在同一进程中进行, 仅需少量的机器指令; 内核级线程的线程切换需要完整的上下文切换、修改内存映像、使高速缓存失效, 这就导致了若干数量级的延迟。",
  "调度的目标 为了比较CPU调度算法的性能, 人们提出了很多评价标准, 下面介绍其中主要的几种: CPU利用率。CPU是计算机系统中最重要和昂贵的资源之一, 所以应尽可能使CPU保持“忙”状态, 使这一资源利用率最高。 系统吞吐量。表示单位时间内CPU完成作业的数量。长作业需要消耗较长的CPU时间, 因此会降低系统的吞吐量。而对于短作业, 需要消耗的CPU时间较短, 因此能提高系统的吞吐量。 周转时间。指从作业提交到作业完成所经历的时间, 是作业等待、在就绪队列中排队、在CPU上运行及I/O操作所花费时间的总和。 周转时间 = 作业完成时间 - 作业提交时间 带权周转时间 = 作业周转时间 / 作业实际运行时间 等待时间。指进程处于等待CPU的时间之和, 等待时间越长, 用户满意度越低。CPU调度算法实际上并不影响作业执行或I/O操作的时间, 只影响作业在就绪队列中等待所花的时间。 响应时间。指从用户提交请求到系统首次产生响应所用的时间。在交互式系统中, 一般采用响应时间作为衡量调度算法的重要准则之一。",
  "进程切换 对通常的进程而言, 其创建、撤销及要求由系统设备完成的I/O操作, 都是利用系统调用而进入内核, 再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的, 因此可以说, 任何进程都是在操作系统内核的支持下运行的, 是与内核紧密相关的。 (1) 上下文切换 切换 CPU到另一个进程需要保存当前进程状态并恢复另一个进程的状态, 这个任务称为上下文切换。进程上下文采用进程PCB表示, 包括CPU寄存器的值、进程状态和内存管理信息等。上下文切换的流程如下: 挂起一个进程, 将CPU上下文保存到PCB, 包括程序计数器和其他寄存器。 将进程的PCB移入相应的队列, 如就绪、在某事件阻塞等队列。 选择另一个进程执行, 并更新其PCB。 恢复新进程的CPU上下文。 跳转到新进程PCB中的程序计数器所指向的位置执行。 (2) 上下文切换的消耗 上下文切换通常是计算密集型的, 即它需要相当可观的CPU时间, 所以上下文切换对系统来说意味着消耗大量的CPU时间。 (3) 上下文切换与模式切换 模式切换与上下文切换是不同的, 模式切换时, CPU逻辑上可能还在执行同一进程。用户态和内核态之间的切换称为模式切换, 而不是上下文切换, 因为没有改变当前的进程。上下文切换只能发生在内核态, 它是多任务操作系统中的一个必需的特性。 调度和切换的区别:调度是指决定资源分配给哪个进程的行为, 是一种决策行为;切换是指实际分配的行为, 是执行行为。一般来说, 先有资源的调度, 然后才有进程的切换。",
  "CPU 调度算法 先来先服务(FCFS)调度算法 FCFS 调度算法是一种最简单的调度算法, 它既可用于作业调度, 又可用于进程调度。 在作业调度中, FCFS调度算法每次从后备作业队列中选择最先进入该队列的一个或几个作业, 将它们调入内存, 分配必要的资源, 创建进程并放入就绪队列。 在进程调度中, FCFS调度算法每次从就绪队列中选择最先进入该队列的进程, 将CPU分配给它, 使之投入运行, 直到运行完成或因某种原因此阻塞时才释放CPU。 FCFS 调度算法属于不可剥夺算法。若一个长作业先到达系统, 就会使后面的许多短作业等待很长时间。 FCFS 调度算法的特点是算法简单, 但效率低;对长作业比较有利, 但对短作业不利;有利于CPU繁忙型作业, 而不利于1/0繁忙型作业。 短作业优先(SJF)调度算法 短作业(进程)优先调度算法是指对短作业(进程)优先调度的算法。短作业优先(SJF)调度算法从后备队列中选择一个或几个估计运行时间最短的作业;短进程优先(SPF)调度算法从就绪队列中选择一个估计运行时间最短的进程。 SJF 算法也存在不容忽视的缺点: 该算法对长作业不利。若有一长作业进入系统的后备队列, 由于调度程序总是优先调度那些(即使是后进来的)短作业, 将导致长作业长期不被调度, 产生饥饿现象。 该算法完全未考虑作业的紧迫程度, 因此不能保证紧迫性作业会被及时处理。 由于作业的长短是根据用户所提供的估计执行时间而定的, 而用户又可能有意或无意地缩短其作业的估计运行时间, 致使该算法不一定能真正做到短作业优先调度。 SPF 算法也可以是抢占式的。当一个新进程到达就绪队列时, 若其估计执行时间比当前进程的剩余时间小, 则立即暂停当前进程, 将CPU分配给新进程。因此, 抢占式SPF调度算法也称最短剩余时间优先调度算法。 高响应比优先调度算法 高响应比优先调度算法主要用于作业调度, 是对FCFS 调度算法和SJF 调度算法的一种综合平衡, 同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时, 先计算后备作业队列中每个作业的响应比, 从中选出响应比最高的作业投入运行。 响应比 = (等待时间+要求服务时间) / 要求服务时间。 优先级调度算法 优先级调度算法既可用于作业调度, 又可用于进程调度。 根据新的更高优先级进程能否抢占正在执行的进程, 可将该调度算法分为如下两种: 非抢占式优先级调度算法。当一个进程正在CPU上运行时, 即使有某个优先级更高的进程进入就绪队列, 仍让正在运行的进程继续运行。 抢占式优先级调度算法。当一个进程正在CPU上运行时, 若有某个优先级更高的进程进入就绪队列, 则立即暂停正在运行的进程, 将CPU分配给优先级更高的进程。 根据进程创建后其优先级是否可以改变, 可将进程优先级分为以下两种: 静态优先级。优先级是在创建进程时确定的, 且在进程的整个运行期间保持不变。 动态优先级。创建进程时先赋予进程一个优先级, 但优先级会随进程的推进或等待时间的增加而改变。 一般来说, 进程优先级的设置可以参照以下原则: 系统进程 > 用户进程。 交互型进程 > 非交互型进程(或前台进程 > 后台进程)。 I/O型进程 > 计算型进程。 时间片轮转(RR)调度算法 时间片轮转(RR)调度算法主要适用于分时系统。这种算法最大的特点是公平, 系统将所有的就绪进程按FCFS策略排成一个就绪队列, 每隔一定的时间便产生一次时钟中断, 激活调度程序进行调度, 将CPU分配给就绪队列的队首进程, 并令其执行一个时间片。在执行完一个时间片后, 即使进程并未运行完成, 它也必须释放出(被剥夺)CPU给就绪队列的新队首进程, 而被剥夺的进程返回到就绪队列的末尾重新排队, 等候再次运行。 在RR 调度算法中, 时间片的大小对系统性能的影响很大。若时间片足够大, 则时间片轮转调度算法就退化为先来先服务调度算法。若时间片很小, 则CPU将在进程间过于频繁地切换, 使CPU的开销增大。 多级队列调度算法 该算法在系统中设置多个就绪队列, 将不同类型或性质的进程固定分配到不同的就绪队列。每个队列可实施不同的调度算法。同一队列中的进程可以设置不同的优先级, 不同的队列本身也可以设置不同的优先级。 多级反馈队列调度算法(融合了前几种算法的优点) 多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合与发展。通过动态调整进程优先级和时间片大小, 多级反馈队列调度算法可以兼顾多方面的系统目标。 多级反馈队列调度算法的实现思想如下: 设置多个就绪队列, 并为每个队列赋予不同的优先级。第1级队列的优先级最高, 第2级队列的优先级次之, 其余队列的优先级逐个降低。 赋予各个队列的进程运行时间片的大小各不相同。在优先级越高的队列中, 每个进程的时间片就越小。 每个队列都采用FCFS算法。新进程进入内存后, 首先将它放入第1级队列的末尾。若它在一个时间片结束时尚未完成, 调度程序将其转入第2级队列的末尾等待调度;若它在第2级队列中运行一个时间片后仍未完成, 再将它放入第3级队列, 以此类推。 按队列优先级调度。仅当第1级队列为空时, 才调度第2级队列中的进程运行;仅当第1~i-1级队列均为空时, 才会调度第i级队列中的进程运行。若CPU正在执行第i级队列中的某个进程时, 又有新进程进入任何一个优先级较高的队列, 此时须立即将正在运行的进程放回到第i级队列的末尾, 而将CPU分配给新到的高优先级进程。 基于公平原则的调度算法 (1) 保证调度算法 保证调度算法向用户做出明确的性能保证。一种很实际且很容易实现的保证是:若系统中有n个用户登录, 则每个用户都保证获得1/n的CPU时间。 (2) 公平分享调度算法 保证对进程公平, 但并不意味着对用户也公平。公平分享调度算法保证所有用户能获得相同的CPU时间, 或所要求的时间比例。",
  "多处理机调度 多处理机系统的调度较单处理机系统复杂, 它与系统结构有关。 非对称多处理机(Asymmetric MultiProcessing, AMP)大多采用主从式操作系统, 内核驻留在主机上, 而从机上只运行用户程序, 进程调度由主机负责。 对称多处理机(Symmetric MultiProcessing,SMP)的所有处理机都是相同的, 因此由调度程序将任何一个进程分配给任何一个CPU。 亲和性和负载平衡 当一个进程从一个CPU移到其他CPU上时, 应将第一个CPU的缓存设置为无效, 然后重新填充第二个CPU的缓存, 这种操作的代价较高, 因此系统应尽量避免将进程从一个CPU 移到另一个CPU, 而应试图让一个进程运行在同一个CPU上, 这称为处理器亲和性。 对于SMP系统, 应尽量保证所有CPU的负载平衡(也称负载均衡)。 然而, 负载平衡通常会抵消处理器亲和性带来的好处。 多处理机调度方案 方案一:公共就绪队列 系统中仅设置一个公共就绪队列, 所有CPU共享同一个就绪队列。这种方案很好地实现了负载平衡, 但处理器亲和性不好。 方案二:私有就绪队列 系统为每个CPU设置一个私有就绪队列。这种方案很好地实现了处理器亲和性, 缺点是必须进行负载平衡。",
  "同步与互斥的基本概念 在多道程序环境下, 进程是并发执行的, 不同进程之间存在着不同的相互制约关系。为了协调进程之间的相互制约关系, 引入了进程同步的概念。 临界资源 虽然多个进程可以共享系统中的各种资源, 但其中许多资源一次只能为一个进程所用, 我们将一次仅允许一个进程使用的资源称为临界资源。 对临界资源的访问, 必须互斥地进行, 在每个进程中, 访问临界资源的那段代码称为临界区。 为了保证临界资源的正确使用, 可将临界资源的访问过程分成4个部分: 进入区。为了进入临界区使用临界资源, 在进入区要检查可否进入临界区, 若能进入临界区, 则应设置正在访问临界区的标志, 以阻止其他进程同时进入临界区。 临界区。进程中访问临界资源的那段代码, 也称临界段。 退出区。将正在访问临界区的标志清除。 剩余区。代码中的其余部分。 同步 同步亦称直接制约关系, 是指为完成某种任务而建立的两个或多个进程, 这些进程因为需要协调它们的运行次序而等待、传递信息所产生的制约关系。同步关系源于进程之间的相互合作。 互斥 互斥也称间接制约关系。当一个进程进入临界区使用临界资源时, 另一个进程必须等待, 当占用临界资源的进程退出临界区后, 另一进程才允许去访问此临界资源。 为禁止两个进程同时进入临界区, 同步机制应遵循以下准则: 空闲让进。临界区空闲时, 可以允许一个请求进入临界区的进程立即进入临界区。 忙则等待。当已有进程进入临界区时, 其他试图进入临界区的进程必须等待。 有限等待。对请求访问的进程, 应保证能在有限时间内进入临界区, 防止进程无限等待。 让权等待(原则上应该遵循, 但非必须)。当进程不能进入临界区时, 应立即释放处理器, 防止进程忙等待。",
  "实现临界区互斥的基本方法 软件实现方法 在进入区设置并检查一些标志来标明是否有进程在临界区中, 若已有进程在临界区, 则在进入区通过循环检查进行等待, 进程离开临界区后则在退出区修改标志。 (1) 算法一:单标志法 该算法设置一个公用整型变量 turn, 指示允许进入临界区的进程编号。该算法可以实现每次只允许一个进程进入临界区。但两个进程必须交替进入临界区, 若某个进程不再进入临界区, 则另一个进程也将无法进入临界区(违背“空闲让进”准则)。 (2) 算法二:双标志先检查法 该算法设置一个布尔型数组flag[2], 用来标记各个进程想进入临界区的意愿。优点:不用交替进入, 可连续使用。缺点:P₀和 P₁ 可能同时进入临界区。 (3) 算法三:双标志后检查法 算法三先设置自己的标志, 再检查对方的标志, 若对方的标志为true, 则等待;否则, 进入临界区。两个进程都想进入时, 双方都争着进入临界区, 结果谁也进不了(违背“空闲让进”准则), 于是因各个进程都长期无法访问临界区而导致“饥饿”现象(违背“有限等待”准则)。 (4) 算法四:Peterson 算法 Peterson 算法结合了算法一和算法三的思想, 利用flag[]解决互斥访问问题, 而利用 turn 解决“饥饿”问题。若双方都争着进入临界区, 则可让进程将进入临界区的机会谦让给对方。 硬件实现方法 (1) 中断屏蔽方法 当一个进程正在执行它的临界区代码时, 防止其他进程进入其临界区的最简单方法是关中断。 这种方法的缺点:①限制了CPU 交替执行程序的能力, 因此系统效率会明显降低。②将关中断的权限交给用户则很不明智。③不适用于多处理器系统。 (2) 硬件指令方法——TestAndSet 指令 借助一条硬件指令 TestAndSet 指令(简称TS指令)实现互斥, 这条指令是原子操作。其功能是读出指定标志后将该标志设置为真。 相比于软件实现方法, TS指令将“加锁”和“检查”操作用硬件的方式变成了一气呵成的原子操作。缺点是, 暂时无法进入临界区的进程会占用CPU循环执行TS指令, 因此不能实现“让权等待”。 (3) 硬件指令方法——Swap 指令 Swap 指令的功能是交换两个字(字节)的内容。 用硬件指令方法实现互斥的优点:①简单、容易验证其正确性;②适用于任意数量的进程, 支持多处理器系统;③支持系统中有多个临界区。缺点:①等待进入临界区的进程会占用CPU执行while循环, 不能实现“让权等待”;②从等待进程中随机选择一个进程进入临界区, 有的进程可能一直选不上, 从而导致“饥饿”现象。",
  "互斥锁 解决临界区最简单的工具就是互斥锁(mutexlock)。一个进程在进入临界区时调用 acquire()函数, 以获得锁;在退出临界区时调用 release()函数, 以释放锁。每个互斥锁有一个布尔变量 available, 表示锁是否可用。 acquire()或 release()的执行必须是原子操作, 因此互斥锁通常采用硬件机制来实现。 上面描述的互斥锁也称自旋锁, 其主要缺点是忙等待。互斥锁通常用于多处理器系统。",
  "信号量 信号量机制是一种功能较强的机制, 可用来解决互斥与同步问题, 它只能被两个标准的原语wait()和 signal()访问, 也可简写为P()和V()。 原语是指完成某种功能且不被分割、不被中断执行的操作序列, 通常可由硬件来实现。 整型信号量 整型信号量被定义为一个用于表示资源数量的整型量S。在整型信号量机制中的wait 操作, 只要信号量S≤0, 就会不断循环测试。因此, 该机制并未遵循“让权等待”的准则, 而是使进程处于“忙等”的状态。 记录型信号量 记录型信号量机制是一种不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数量的整型变量value外, 再增加一个进程链表L, 用于链接所有等待该资源的进程。 对信号量S的一次P操作, 表示进程请求一个该类资源。当S.value<0时, 表示该类资源已分配完毕, 因此应调用 block 原语进行自我阻塞, 主动放弃CPU, 可见该机制遵循了“让权等待”准则。 对信号量S的一次V操作, 表示进程释放一个该类资源。若加1后仍是S.value≤0, 则表示仍有进程在等待该类资源, 因此应调用 wakeup 原语将S.L中的第一个进程唤醒。 利用信号量实现进程互斥 为了使多个进程能互斥地访问某个临界资源, 需要为该资源设置一个互斥信号量S, 其初值为1, 然后将各个进程访问该资源的临界区置于P(S)和V(S)之间。 利用信号量实现同步 要让本来异步的并发进程相互配合, 有序推进。为了实现这种同步关系, 需要设置一个同步信号量S, 其初值为0。 利用信号量实现前驱关系 信号量也可用来描述程序或语句之间的前驱关系。要为每对前驱关系设置一个同步信号量, 其初值均为0。在“前驱操作”之后, 对相应的同步信号量执行V操作, 在“后继操作”之前, 对相应的同步信号量执行P操作。",
  "经典同步问题 生产者-消费者问题 问题描述:系统中有一组生产者进程和一组消费者进程, 生产者每次生产一个产品并放入缓冲区, 消费者每次从缓冲区中取出一个产品并消费。生产者和消费者共享一个初始为空、大小为n的缓冲区。只有当缓冲区不满时, 生产者才能将产品放入缓冲区;只有当缓冲区不空时, 消费者才能从中取出产品。缓冲区是临界资源, 各进程必须互斥访问。 问题分析:生产者和消费者对缓冲区的访问是互斥关系, 同时生产者和消费者又是一个相互协作的关系, 只有生产者生产之后, 消费者才能消费, 它们也是同步关系。 读者-写者问题 问题描述:有读者和写者两组并发进程, 共享一个文件, 当两个或以上的读进程同时访问共享数据时不会产生副作用, 但若某个写进程和其他进程(读进程或写进程)同时访问共享数据时则可能导致数据不一致的错误。因此要求:①允许多个读者可以同时对文件执行读操作;②只允许一个写者往文件中写信息;③任意一个写者在完成写操作之前不允许其他读者或写者工作;④写者执行写操作前, 应让已有的读者和写者全部退出。 问题分析:由题目分析读者和写者是互斥的, 写者和写者也是互斥的, 而读者和读者不存在互斥问题。 哲学家进餐问题 问题描述:一张圆桌边上坐着5名哲学家, 每两名哲学家之间的桌上摆一根筷子。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐。 问题分析:5名哲学家与左右邻居对其中间筷子的访问是互斥关系。本题的关键是如何让一名哲学家拿到左右两根筷子而不造成死锁或饥饿现象。 为防止死锁发生, 可对哲学家进程施加一些限制条件, 比如:①至多允许4名哲学家同时进餐;②仅当一名哲学家左右两边的筷子都可用时, 才允许他拿起筷子;③对哲学家顺序编号, 要求奇数号哲学家先拿左边的筷子, 然后拿右边的筷子, 而偶数号哲学家刚好相反。",
  "管程 在信号量机制中, 每个要访问临界资源的进程都必须自备同步的PV操作, 大量分散的同步操作给系统管理带来了麻烦, 且容易因同步操作不当而导致系统死锁。于是, 便产生了一种新的进程同步工具——————管程。 管程的定义 利用共享数据结构抽象地表示系统中的共享资源, 而将对该数据结构实施的操作定义为一组过程。这个代表共享资源的数据结构, 以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序, 称为管程(monitor)。 管程由4部分组成:①管程的名称;②局部于管程内部的共享数据结构说明;③对该数据结构进行操作的一组过程(或函数);④对局部于管程内部的共享数据设置初始值的语句。 管程将对共享资源的操作封装起来, 管程内的共享数据结构只能被管程内的过程所访问。每次仅允许一个进程进入管程, 从而实现进程互斥。 条件变量 当一个进程进入管程后被阻塞, 若该进程不释放管程, 则其他进程无法进入管程。为此, 将阻塞原因定义为条件变量 condition。每个条件变量保存了一个等待队列, 用于记录因该条件变量而阻塞的所有进程, 对条件变量只能进行两种操作, 即wait 和 signal。 x.wait:当x对应的条件不满足时, 正在调用管程的进程调用x.wait将自己插入x条件的等待队列, 并释放管程。 x.signal:x对应的条件发生了变化, 则调用x.signal, 唤醒一个因x条件而阻塞的进程。",
  "死锁的概念 死锁的定义 在多道程序系统中, 由于进程的并发执行, 极大地提升了系统效率。然而, 多个进程的并发执行也带来了新的问题——死锁。死锁, 是指多个进程因竞争资源而造成的一种僵局(互相等待), 若无外力干涉, 这些进程都将无法向前推进。 死锁和饥饿的共同点是进程无法顺利执行下去。 死锁和饥饿的主要差别:①死锁进程的集合中的每一个进程都在等待被该集合中的其他进程所占有的资源, 而饥饿的进程仅在等待被其他进程所占有的资源。②若有死锁现象, 则发生死锁的进程必然处于等待态, 也可能处于就绪态(长期得不到CPU)。 死锁产生的原因 (1) 系统资源的竞争 通常系统中拥有的不可剥夺资源, 其数量不足以满足多个进程运行的需要, 使得进程在运行过程中, 会因争夺资源而陷入僵局。 (2) 进程推进顺序非法 进程在运行过程中, 请求和释放资源的顺序不当, 也会导致产生进程死锁。 死锁产生的必要条件 产生死锁必须同时满足以下4个条件, 只要其中任一条件不成立, 死锁就不会发生。 互斥条件。进程要求对所分配的资源(如打印机)进行排他性控制, 即在一段时间内某资源仅为一个进程所占有。 请求和保持条件。进程所获得的资源在未使用完之前, 不能被其他进程强行夺走, 即使自己已占有的资源只能由自己来释放。 不剥夺条件。进程已获得的资源在未使用完之前, 不能被剥夺, 只能在使用完时由自己释放。 循环等待条件。存在一种进程资源的循环等待链, 链中每个进程已获得的资源同时被链中下一个进程所请求。",
  "死锁预防 死锁预防的方法是使4个必要条件中的至少一个不能成立, 来预防死锁的发生。 破坏互斥条件 若允许系统资源都能共享使用, 则系统不会进入死锁状态。但有些资源根本不能同时共享, 故破坏互斥条件而预防死锁的方法不太可行。 破坏请求和保持条件 为了不致发生死锁, 必须保证当一个进程已保持了某些不可剥夺资源时, 便不能再请求其他任何资源。要做到这一点, 可采用两种协议: 第一种协议。所有进程在开始运行之前, 必须一次性地申请其在整个运行过程中所需的全部资源。 第二种协议。允许一个进程只获得运行初期所需的资源后, 便开始运行。进程运行过程中再逐步释放已分配到的、且已用毕的全部资源, 然后再请求新的所需资源。 破坏不剥夺条件 当一个已保持了某些资源的进程, 再提出新的资源请求而不能立即得到满足时, 必须释放它已保持的所有资源, 待以后需要时再重新申请。 破坏循环等待条件 为了破坏循环等待条件, 可采用顺序资源分配法。首先给系统中的资源编号, 规定每个进程必须按编号递增的顺序请求资源, 同类资源一次申请完。",
  "死锁避免 避免死锁同样是事先预防策略, 但它并不像死锁预防策略那样严格地限制进程对资源的访问, 而是在每次资源分配前, 先分析此次分配是否会使系统进入不安全状态, 若不会, 才将资源分配给它。 系统安全状态 所谓系统安全状态, 是指系统能按某种进程推进顺序, 为每个进程分配其所需资源, 直至满足每个进程对资源的最大需求, 使每个进程都可顺利地完成。 若系统无法找到这样一个安全序列, 则称系统处于不安全状态。 银行家算法 银行家算法是著名的死锁避免算法, 其思想是:操作系统视为银行家, 操作系统管理的资源视为银行家的资金, 进程向操作系统请求资源视为用户向银行家贷款。",
  "死锁检测和解除 死锁检测 死锁检测和解除是指系统在运行过程中, 能发现死锁的存在, 并能解除死锁。 为了能对系统是否已发生了死锁进行检测, 必须: 保存有关资源的请求和分配信息。 提供一种能利用这些信息去检测系统是否已进入死锁状态的算法。 死锁解除 死锁解除的主要方法有: 剥夺资源。从其他进程剥夺足够数量的资源给死锁进程, 以解除死锁状态。 撤销进程。最简单的方法是撤销全部死锁进程, 但代价太大。另一种方法是逐个撤销死锁进程, 直至死锁状态消除。 进程回退。让一个或多个进程回退到足以避免死锁的地步, 进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息, 设置还原点。",
  "I/O 设备 I/O 设备管理是操作系统设计中最凌乱也最具挑战性的部分。它包含了很多领域的不同设备及与设备相关的应用程序,因此很难有一个通用且一致的设计方案。 设备的分类 I/O 设备是指可以将数据输入计算机的外部设备,或者可以接收计算机输出数据的外部设备。I/O 设备的类型繁多,从不同的角度可将它们分为不同的类型。 按信息交换的单位分类,I/O设备可分为: 1)块设备。信息交换以数据块为单位,如磁盘、磁带等。磁盘设备的基本特征是传输速率较高、可寻址,即对它可随机地读/写任意一块。 2)字符设备。信息交换以字符为单位,如交互式终端机、打印机等。它们的基本特征是传输速率低、不可寻址,并且通常采用中断I/O方式。 按设备的传输速率分类,I/O设备可分为: 1)低速设备。传输速率仅为每秒几字节到数百字节,如键盘、鼠标等。 2)中速设备。传输速率为每秒数千字节至数万字节,如激光打印机等。 3)高速设备。传输速率在数百千字节至千兆字节,如磁盘、光盘等。 按设备的使用特性分类,I/O设备可分为: 1)人机交互设备。用于用户和计算机之间交互信息的设备,如键盘、显示器、打印机等。 2)存储设备。用于存储信息的设备,如磁盘、磁带、光盘等。 3)网络通信设备。用于计算机和计算机之间的通信,如网卡、调制解调器等。 按设备的共享属性分类,I/O设备可分为: 1)独占设备。同一时刻只能由一个进程占用的设备。一旦将这类设备分配给某进程,便由该进程独占,直至用完释放。低速设备一般是独占设备,如打印机。 2)共享设备。同一时间段内允许多个进程同时访问的设备。对于共享设备,可同时分配给多个进程,通过分时的方式共享使用。典型的共享设备是磁盘。 3)虚拟设备。通过SPOOLing 技术将独占设备改造为共享设备,将一个物理设备变为多个逻辑设备,从而可将设备同时分配给多个进程。 I/O接口 I/O接口(也称设备控制器)是CPU与设备之间的“桥梁”,以实现设备和计算机之间的数据交换。它接收发自CPU的命令,控制设备工作,使CPU能从繁杂的设备控制事务中解脱出来。设备控制器主要由三部分组成。 1)设备控制器与CPU的接口。用于实现CPU与设备控制器之间的通信。该接口有三类信号线:数据线、地址线和控制线。 2)设备控制器与设备的接口。一个设备控制器可以连接一个或多个设备,因此控制器中有一个或多个设备接口。 3)I/O逻辑。用于实现对设备的控制。它通过一组控制线与CPU交互,对从CPU收到的I/O命令进行译码。 设备控制器的主要功能有:①接收和识别命令;②数据交换;③标识和报告设备的状态;④地址识别;⑤数据缓冲;⑥差错控制。 I/O接口的类型 从不同的角度看,I/O接口可以分为不同的类型。 1)按数据传送方式,可分为并行接口和串行接口。 2)按主机访问 I/O设备的控制方式,可分为程序查询接口、中断接口和DMA接口等。 3)按功能选择的灵活性,可分为可编程接口和不可编程接口。 I/O端口 I/O端口是指设备控制器中可被CPU直接访问的寄存器,主要有以下三类寄存器。 数据寄存器:用于缓存从设备送来的输入数据,或从CPU送来的输出数据。 状态寄存器:保存设备的执行结果或状态信息,以供CPU读取。 控制寄存器:由CPU写入,以便启动命令或更改设备模式。 对I/O 端口的编址方式有与存储器独立编址和统一编址两种。 (1)独立编址 独立编址是指为每个端口分配一个I/O端口号。I/O端口的地址空间与主存地址空间是两个独立的地址空间。 优点:I/O端口译码简单,寻址速度更快。使用专用I/O指令,可使程序更加清晰。 缺点:I/O 指令少,程序设计的灵活性较差。CPU需要提供两组独立的控制信号,增加了控制的复杂性。 (2)统一编址 统一编址也称内存映射I/O,是指将主存地址空间分出一部分给I/O端口进行编址,I/O端口和主存单元在同一地址空间的不同分段中。 优点:不需要专门的I/O指令,使得CPU访问I/O的操作更加灵活和方便。 缺点:端口地址占用了部分主存地址空间。译码电路更加复杂,降低了寻址速度。",
  "I/O 控制方式 I/O 控制是指控制设备和主机之间的数据传送。I/O控制方式共有4种。 1.程序直接控制方式 CPU对I/O 设备的控制采取轮询的I/O方式,也称程序轮询方式。CPU向设备控制器发出一条I/O指令,启动从I/O设备读取一个字(节),然后不断地循环测试设备状态(称为轮询),直到确定该字(节)已在设备控制器的数据寄存器中。于是CPU将数据寄存器中的数据取出,送入内存的指定单元。 这种方式简单且易于实现,但缺点也很明显。CPU的绝大部分时间都处于等待I/O设备状态的循环测试中,CPU和I/O设备只能串行工作,导致CPU的利用率相当低。 2.中断驱动方式 中断驱动方式的思想是允许I/O设备主动打断CPU的运行并请求服务,从而“解放”CPU,使得CPU向设备控制器发出一条I/O指令后可以继续做其他有用的工作。 从设备控制器的角度来看:设备控制器从 CPU 接收一个读命令,然后从设备读数据。一旦数据读入设备控制器的数据寄存器,便通过控制线给CPU发出中断信号,表示数据已准备好。 从CPU的角度来看:当前运行进程发出读命令,该进程将被阻塞,然后转去执行其他程序。在每个指令周期的末尾,CPU检查中断信号。当有来自设备控制器的中断时,CPU保存当前运行进程的上下文,转去执行中断处理程序以处理该中断请求。 相比于程序轮询I/O方式,在设备准备数据期间,CPU和设备并行工作,CPU的利用率得到明显提升。但是,中断驱动方式仍有两个明显的问题:①设备与内存之间的数据交换都必须经过 CPU中的寄存器;②CPU是以字(节)为单位进行干预的。",
  "DMA方式 DMA(直接存储器存取)方式的基本思想是,在I/O设备和内存之间开辟直接的数据交换通路,彻底“解放”CPU。DMA方式的特点如下: 1)基本传送单位是数据块。 2)所传送的数据,是从设备直接送入内存的,或者相反,而不再经过CPU。 3)仅在传送一个或多个数据块的开始和结束时,才需要CPU干预。 为了实现主机和控制器之间直接交换成块的数据,须在DMA控制器中设置如下4类寄存器: 1)命令/状态寄存器(CR)。 2)内存地址寄存器(MAR)。 3)数据寄存器(DR)。 4)数据计数器(DC)。 DMA方式的工作过程是:CPU接收到设备的DMA请求时,它向DMA控制器发出一条命令,同时设置MAR和DC初值,启动DMA控制器,然后继续其他工作。之后CPU就将I/O 控制权交给DMA控制器,由DMA 控制器负责数据传送。整个数据传送结束后,DMA控制器向CPU发送一个中断信号。 DMA方式的优点:数据传输以“块”为单位,CPU介入的频率进一步降低;数据传送不再经过CPU的寄存器,CPU和设备的并行操作程度得到了进一步提升。 4.通道控制方式 I/O通道是一种特殊的处理机,它可执行一系列通道指令。设置通道后,CPU只需向通道发送一条 I/O 指令,通道收到该指令后,执行通道程序,完成规定的I/O任务后,向CPU发出中断请求。通道方式可以实现CPU、通道和I/O设备三者的并行工作。 通道与一般处理机的区别是:通道指令的类型单一,没有自己的内存,通道所执行的通道程序是放在主机的内存中的,也就是说通道与CPU共享内存。 通道与DMA方式的区别是:DMA方式需要CPU来控制传输的数据块大小、传输的内存位置,而通道方式中这些信息是由通道控制的。另外,每个DMA 控制器对应一台设备与内存传递数据,而一个通道可以控制多台设备与内存的数据交换。",
  "I/O 软件层次结构 为使复杂的I/O软件能具有清晰的结构、良好的可移植性和易适应性,目前普遍采用层次结构的I/O软件。整个I/O软件可以视为具有4个层次的系统结构,各层次及其功能如下: (1)用户层软件 实现与用户交互的接口,用户可直接调用在用户层提供的、与I/O操作有关的库函数,对设备进行操作。用户层I/O软件必须通过一组系统调用来获取操作系统服务。 (2)设备独立性软件 用于实现用户程序与设备驱动器的统一接口、设备命名、设备保护,以及设备的分配与释放等,同时为设备管理和数据传送提供必要的存储空间。 设备独立性也称设备无关性,其含义是指应用程序所用的设备不局限于某个具体的物理设备。为实现设备独立性而引入了逻辑设备和物理设备这两个概念。 使用逻辑设备名的好处是:①增加设备分配的灵活性;②易于实现I/O 重定向。 设备独立性软件的主要功能可分为以下两个方面。①执行所有设备的公有操作,包括:对设备的分配与回收:将逻辑设备名映射为物理设备名;对设备进行保护;缓冲管理:差错控制;提供独立于设备的大小统一的逻辑块。②向用户层(或文件层)提供统一接口。 (3)设备驱动程序 与硬件直接相关,每类设备需要配置一个设备驱动程序。设备驱动程序负责具体实现系统对设备发出的操作指令,驱动I/O设备工作的驱动程序,它是I/O进程与设备控制器之间的通信程序。 (4)中断处理程序 当I/O操作完成时,设备控制器发送一个中断信号,CPU响应中断后,根据中断类型号找到相应的中断处理程序进行处理,处理完后,再返回到被中断的进程。 中断处理层的主要任务有:进行进程上下文的切换,对处理中断信号源进行测试,读取设备状态和修改进程状态等。",
  "应用程序I/O接口 I/O接口的分类 在I/O 系统与高层之间的接口中,根据设备类型的不同,又进一步分为若干类。 (1)字符设备接口 字符设备是指数据的存取和传输是以字符为单位的设备,如键盘、打印机等。基本特征是传输速率较低、不可寻址,并且在输入/输出时通常采用中断驱动方式。 get 和 put 操作,由于字符设备不可寻址,只能采取顺序存取方式,通常为字符设备建立一个字符缓冲区。 in-control 指令,字符设备类型繁多,差异甚大,因此在接口中提供一种通用的 in-control 指令来处理它们。 字符设备都属于独占设备,为此接口中还需要提供打开和关闭操作,以实现互斥共享。 (2)块设备接口 块设备是指数据的存取和传输是以数据块为单位的设备,典型的块设备是磁盘。基本特征是传输速率较高、可寻址。磁盘设备的I/O常采用DMA方式。 块设备接口支持将上层发来的打开、读、写和关闭等抽象命令,映射为设备能识别的较低层的具体操作。 内存映射接口通过内存的字节数组来访问磁盘,而不提供读/写磁盘操作。 (3)网络设备接口 现代操作系统都提供面向网络的功能,因此还需要提供相应的网络软件和网络通信接口。 许多操作系统提供的网络I/O接口为网络套接字接口。 阻塞I/O和非阻塞I/O 操作系统的I/O接口还涉及两种模式:阻塞和非阻塞。 阻塞 I/O 是指当用户进程调用IO操作时,进程就被阻塞,并移到阻塞队列,I/O操作完成后,进程才被唤醒,移到就绪队列。 优点:操作简单,实现难度低,适合并发量小的应用开发。 缺点:I/O 执行阶段进程会一直阻塞下去。 非阻塞 I/O 是指当用户进程调用I/O操作时,不阻塞该进程,但进程需要不断询问I/O操作是否完成,在I/O执行阶段,进程还可以做其他事情。 优点:进程在等待I/O期间不会阻塞,可以做其他事情,适合并发量大的应用开发。 缺点:轮询方式询问I/O结果,会占用CPU的时间。",
  "设备独立性软件 也称与设备无关的软件,是I/O 系统的最高层软件,它的下层是设备驱动程序,其界限因操作系统和设备的不同而有所差异。比如,一些本应由设备独立性软件实现的功能,也可能放在设备驱动程序中实现。这样的差异主要是出于对操作系统、设备独立性软件和设备驱动程序运行效率等多方面因素的权衡。总体而言,设备独立性软件包括执行所有设备公有操作的软件。",
  "高速缓存与缓冲区 磁盘高速缓存(Disk Cache) 操作系统中使用磁盘高速缓存技术来提高磁盘的I/O速度,对访问高速缓存要比访问原始磁盘数据更为高效。例如,正在运行进程的数据既存储在磁盘上,又存储在物理内存上,也被复制到CPU的二级和一级高速缓存中。不过,磁盘高速缓存技术不同于通常意义下的介于CPU与内存之间的小容量高速存储器,而是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。因此,磁盘高速缓存逻辑上属于磁盘,物理上是驻留在内存中的盘块。 磁盘高速缓存在内存中分为两种形式:一种是在内存中开辟一个单独的空间作为缓存区,大小固定;另一种是将未利用的内存空间作为一个缓冲池,供请求分页系统和磁盘I/O时共享。 缓冲区(Buffer) 在设备管理子系统中,引入缓冲区的目的主要如下: 1)缓和CPU与I/O设备间速度不匹配的矛盾。 2)减少对CPU的中断频率,放宽对CPU中断响应时间的限制。 3)解决基本数据单元大小(数据粒度)不匹配的问题。 4)提高CPU和1/0设备之间的并行性。 缓冲区的实现方法如下: 1)采用硬件缓冲器,但由于成本太高,除一些关键部位外,一般不采用硬件缓冲器。 2)利用内存作为缓冲区,本节要介绍的正是由内存组成的缓冲区。 根据系统设置缓冲区的个数,缓冲技术可以分为如下几种: (1)单缓冲 每当用户进程发出一个I/O请求,操作系统便在内存中为之分配一个缓冲区。通常,一个缓冲区的大小就是一个块。在块设备输入时,假定从设备将一块数据输入缓冲区的时间为T,操作系统将该缓冲区中的数据传送到工作区的时间为M,而CPU对这一块数据进行处理的时间为C。 在单缓冲区中, T是可以和C并行的。 当T>C时,CPU处理完一块数据后,暂时不能将下一块数据传送到工作区,必须等待缓冲区装满数据,再将下一块数据从缓冲区传送到工作区,平均处理一块数据的时间为T+M。 当T<C时,缓冲区中装满数据后,暂时不能继续送入下一块数据,必须等待CPU处理完上一块数据,再将下一块数据从缓冲区传送到工作区,平均处理一块数据的时间为C+M。 总结:单缓冲区处理每块数据的平均时间为 Max(C,T)+M (2)双缓冲 为了加快输入和输出速度,提高设备利用率,引入了双缓冲机制,也称缓冲对换。当设备输入数据时,先将数据送入缓冲区1,装满后便转向缓冲区2。此时,操作系统可以从缓冲区1中取出数据,送入用户进程,并由CPU对数据进行处理。当缓冲区1中取出的数据处理完后,若缓冲区2已装满,则操作系统又从缓冲区2中取出数据送入用户进程处理,而设备又可以开始将数据送入缓冲区1。 在双缓冲区中,C和M是可以与T并行的。 当T>C+M时,说明设备输入的时间比数据传送和处理的时间多,可使设备连续输入。平均处理一块数据的时间为T。 当T<C+M时,说明设备输入的时间比数据传送和处理的时间少,可使CPU不必等待设备输入。平均处理一块数据的时间为 C+M。 总结:双缓冲区处理每块数据的平均时间为 Max(C+M,T)。 若两台机器之间仅配置了单缓冲,则它们在任意时刻都只能实现单方向的数据传输。为了实现双向数据传输,必须在两台机器中都设置两个缓冲区,一个用作发送缓冲区,另一个用作接收缓冲区。 (3)循环缓冲 在双缓冲机制中,当输入与输出的速度基本匹配时,能取得较好的效果。但若两者的速度相差甚远,则双缓冲区的效果不会太理想。为此,又引入了多缓冲机制,将多个缓冲区组成循环缓冲区的形式。 循环缓冲包含多个大小相等的缓冲区,每个缓冲区中有一个链接指针指向下一个缓冲区,最后一个缓冲区指针指向第一个缓冲区,多个缓冲区链接成一个循环队列。 循环缓冲中还需设置 in 和 out 两个指针,in指向第一个可以输入数据的空缓冲区,out指向第一个可以提取数据的满缓冲区。 (4)缓冲池 相比于缓冲区(仅是一块内存空间),缓冲池是包含一个用于管理自身的数据结构和一组操作函数的管理机制,用于管理多个缓冲区。缓冲池可供多个进程共享使用。 缓冲池由多个系统公用的缓冲区组成,缓冲区按其使用状况可以分为:①空缓冲队列;②输入队列;③输出队列。此外还应具有4种工作缓冲区:①用于收容输入数据的工作缓冲区(hin),②用于提取输入数据的工作缓冲区(sin),③用于收容输出数据的工作缓冲区(hout),④用于提取输出数据的工作缓冲区(sout)。 缓冲池中的缓冲区有以下4种工作方式。 1)收容输入。输入进程需要输入数据时,从空缓冲队列的队首摘下一个空缓冲区,作为收容输入工作缓冲区,然后将数据输入其中,装满后再将它挂到输入队列的队尾。 2)提取输入。计算进程需要输入数据时,从输入队列的队首取得一个缓冲区,作为提取输入工作缓冲区,从中提取数据,用完该数据后将它挂到空缓冲队列的列尾。 3)收容输出。计算进程需要输出数据时,从空缓冲队列的队首取得一个空缓冲区,作为收容输出工作缓冲区,当其中装满数据后,再将它挂到输出队列的队尾。 4)提取输出。输出进程需要输出数据时,从输出队列的队首取得一个装满输出数据的缓冲区,作为提取输出工作缓冲区,当数据提取完后,再将它挂到空缓冲队列的队尾。 3.高速缓存与缓冲区的对比 高速缓存是可以保存数据拷贝的高速存储器,访问高速缓存比访问原始数据更高效,速度更快。 相同点：都介于高速设备和低速设备之间。 区别： 存放数据：高速缓存存放的是低速设备上的某些数据的复制数据；缓冲区存放的是低速设备传递给高速设备的数据(或相反)。 目的：高速缓存存放的是高速设备经常要访问的数据；高速设备和低速设备的通信都要经过缓冲区。",
  "设备分配与回收 1.设备分配概述 设备分配是指根据用户的1/0请求分配所需的设备。分配的总原则是充分发挥设备的使用效率,尽可能地既让设备忙碌,又避免由于不合理的分配方法造成进程死锁。 2.设备分配的数据结构 在系统中,可能存在多个通道,每个通道可以连接多个控制器,每个控制器可以连接多个物理设备。设备分配的数据结构要能体现出这种从属关系。 1)设备控制表(DCT):系统为每个设备配置一张DCT,表中的表项就是设备的各个属性。在DCT中,应该有下列字段:设备类型、设备标识符、设备状态、指向控制器表的指针、重复执行次数或时间、设备队列的队首指针。 2)控制器控制表(COCT):每个设备控制器都对应一张COCT。操作系统根据COCT的信息对控制器进行操作和管理。 3)通道控制表(CHCT):每个通道都对应一张CHCT。操作系统根据CHCT 的信息对通道进行操作和管理。 4)系统设备表(SDT):整个系统只有一张SDT。它记录已连接到系统中的所有物理设备的情况,每个物理设备对应一个表目。 3.设备分配时应考虑的因素 (1)设备的固有属性 设备的固有属性可分成三种,对它们应采取不同的分配策略。 1)独占设备:将它分配给某个进程后,便由该进程独占,直至进程完成或释放该设备。 2)共享设备:可将它同时分配给多个进程,需要合理调度各个进程访问该设备的先后次序。 3)虚拟设备:虚拟设备属于可共享设备,可将它同时分配给多个进程使用。 (2)设备分配算法 针对设备分配,通常只采用以下两种分配算法: 1)FCFS算法。该算法根据各个进程对某个设备提出请求的先后次序,将这些进程排成一个设备请求队列,设备分配程序总是将设备首先分配给队首进程。 2)最高优先级优先算法。在利用该算法形成设备队列时,优先级高的进程排在设备队列前面,而对于优先级相同的I/O请求,则按FCFS 原则排队。 (3)设备分配中的安全性 设备分配中的安全性是指在设备分配中应防止发生进程死锁。 1)安全分配方式。每当进程发出I/O请求后,便进入阻塞态,直到其I/O操作完成时才被唤醒。优点是设备分配安全,缺点是CPU和I/0设备是串行工作的。 2)不安全分配方式。进程在发出 I/O 请求后仍继续运行,需要时又会发出第二个、第三个I/O请求等。仅当进程所请求的设备已被另一进程占用时,才进入阻塞态。优点是一个进程可同时操作多个设备,使进程推进迅速;缺点是有可能造成死锁。 4.设备分配的步骤 下面以独占设备为例,介绍设备分配的过程。 1)分配设备。首先根据1/0请求中的物理设备名,查找SDT,从中找出该设备的DCT,再根据DCT 中的设备状态字段,可知该设备的状态。若忙,则将进程PCB挂到设备等待队列中:若不忙,则根据一定的策略将设备分配给该进程。 2)分配控制器。设备分配后,根据DCT找到COCT,查询控制器的状态。若忙,则将进程PCB 挂到控制器等待队列中;若不忙,则将控制器分配给该进程。 3)分配通道。控制器分配后,根据COCT找到CHCT,查询通道的状态。若忙,则将进程PCB 挂到通道等待队列中;若不忙,则将通道分配给该进程。只有设备、控制器和通道都分配成功时,这次的设备分配才算成功。 5.逻辑设备名到物理设备名的映射 为了实现设备的独立性,进程中应使用逻辑设备名来请求某类设备。但是,系统只能识别物理设备名,因此在系统中需要配置一张逻辑设备表,用于将逻辑设备名映射为物理设备名。 逻辑设备表(Logical Unit Table,LUT)的每个表项中包含3项内容:逻辑设备名、物理设备名和设备驱动程序的入口地址。 在系统中,可采取两种方式设置逻辑设备表: 1)整个系统中只设置一张LUT。所有进程的设备分配情况都记录在同一张LUT中,这就要求所有用户不能使用相同的逻辑设备名,主要适用于单用户系统。 2)为每个用户设置一张LUT。系统为每个用户设置一张LUT,同时在多用户系统中都配置系统设备表。因此,不同用户可以使用相同的逻辑设备名。",
  "SPOOLing 技术(假脱机技术) 为了缓和CPU的高速性与I/O设备的低速性之间的矛盾,引入了假脱机技术,它是操作系统中采用的一项将独占设备改造成共享设备的技术。该技术利用专门的外围控制机,先将低速I/O设备上的数据传送到高速磁盘上,或者相反。SPOOLing系统的组成如下。 (1)输入井和输出井 在磁盘上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘,用于收容I/O设备输入的数据。输出井模拟脱机输出时的磁盘,用于收容用户程序的输出数据。 (2)输入缓冲区和输出缓冲区 在内存中开辟的两个缓冲区。输入缓冲区用于暂存由输入设备送来的数据,以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据,以后再传送到输出设备。 (3)输入进程和输出进程 输入进程用于模拟脱机输入时的外围控制机,将用户要求的数据从输入设备传送到输入缓冲区,再存放到输入井中。输出进程用于模拟脱机输出时的外围控制机,将用户要求输出的数据从内存传送到输出井,待输出设备空闲时,再将输出井中的数据经输出缓冲区输出至输出设备。 (4)井管理程序 用于控制作业与磁盘井之间信息的交换。 当多个用户进程发出打印输出请求时,SPOOLing 系统同意它们的请求,但并不真正立即将打印机分配给它们,而由假脱机管理进程为每个进程做如下两项工作: 1)在磁盘缓冲区中为进程申请一个空闲盘块,并将要打印的数据送入其中暂存。 2)为用户进程申请一张空白的用户请求打印表,并将用户的打印要求填入其中,再将该表挂到假脱机文件队列上。 SPOOLing 系统的特点:①提高了I/O速度;②将独占设备改造为共享设备;③实现了虚拟设备功能。 SPOOLing 技术是一种以空间换时间的技术。",
  "设备驱动程序接口 设备驱动程序是I/O系统的上层与设备控制器之间的通信程序,其主要任务是接收上层应用发来的抽象 I/O请求,如read 或write命令,将它们转换为具体要求后发送给设备控制器,进而使其启动设备去执行任务;反之,它也将设备控制器发来的信号传送给上层应用。 设备驱动程序应具有以下功能:①接收由上层软件发来的命令和参数,并将抽象要求转换为与设备相关的具体要求。②检查用户I/O请求的合法性,了解设备的工作状态,传递与设备操作有关的参数,设置设备的工作方式。③发出I/O命令,若设备空闲,则立即启动它;若设备忙,则将请求者的PCB挂到设备队列上等待。④及时响应由设备控制器发来的中断请求,并根据其中断类型,调用相应的中断处理程序进行处理。 相比于普通的应用程序和系统程序,设备驱动程序具有以下差异:①设备驱动程序将抽象的I/O 请求转换成具体的I/O操作后,传送给设备控制器,并将设备控制器中记录的设备状态和I/O 操作的完成情况及时地反馈给请求进程。②设备驱动程序与设备采用的I/O控制方式紧密相关。③设备驱动程序与硬件密切相关,对于不同类型的设备,应配置不同的设备驱动程序。④由于设备驱动程序与硬件紧密相关,目前很多设备驱动程序的基本部分已固化在ROM中。⑤设备驱动程序应允许同时多次调用执行。 为了使所有的设备驱动程序都有统一的接口,一方面,要求每个设备驱动程序与操作系统之间都有相同或相近的接口;另一方面,要将抽象的设备名转换为具体的物理设备名,并且进一步找到相应的设备驱动程序入口。",
  "I/O 操作举例 内核缓冲区是处于内核空间的缓冲区,用户缓冲区是处于用户空间的缓冲区。 程序调用“scanf(\"%c\",&d)”时,scanf()会关联一个用户缓冲区buf。 scanf()的第一阶段的工作是在C语言函数库中完成的: 1)检查与 scanf函数关联的用户缓冲区buf,若缓冲区中已有数据,则直接读取。若缓冲区为空,则触发系统调用read。 2)执行系统调用read,传入三个参数:fd(文件描述符)、buf(用户空间缓冲区)、count(读取的最大字节数)。 第二阶段的工作是系统调用,read 调用会展开成一段包含陷阱指令的代码,从用户态陷入内核态以执行相关的操作。 进入内核态后,系统调用服务例程申请一个内核缓冲区,并且最终转到真正执行I/O操作的设备驱动层。在中断方式下,系统调用服务例程执行过程的大致描述如下: 1)设置相应的I/O参数后,发起I/O的进程P进入阻塞态,CPU调度其他进程运行。 2)用户通过键盘输入字符,字符被送到键盘I/O接口的数据端口。 3)键盘I/O接口向CPU发出中断请求。 4)CPU响应中断并执行键盘中断处理程序,将字符从I/O接口的数据端口送入内核缓冲区。 5)进程P被唤醒,插入就绪队列,等待被调度。 6)进程P再次获得CPU后,系统调用服务例程将字符从内核缓冲区复制到用户缓冲区。 7)进程P从系统调用返回,之后scanf函数进行字符解析,最终将该字符存储到变量d中。",
  "磁盘 磁盘(Disk)是表面涂有磁性物质的物理盘片,通过一个称为磁头的导体线圈从磁盘存取数据。在读/写操作期间,磁头固定,磁盘在下面高速旋转。磁盘盘面上的数据存储在一组同心圆中,称为磁道。每个磁道与磁头一样宽,一个盘面有上千个磁道。磁道又划分为几百个扇区,每个扇区固定存储大小(如1KB),一个扇区称为一个盘块。相邻磁道及相邻扇区间通过一定的间隙分隔开,以避免精度错误。注意,因为扇区按固定圆心角度划分,所以密度从最外道向里道增加,磁盘的存储能力受限于最内道的最大记录密度。 磁盘安装在一个磁盘驱动器中,它由磁头臂、用于旋转磁盘的转轴和用于数据输入/输出的电子设备组成。多个盘片垂直堆叠,组成磁盘组,每个盘面对应一个磁头,所有磁头固定在一起,与磁盘中心的距离相同且只能“共进退”。所有盘片上相对位置相同的磁道组成柱面。扇区是磁盘可寻址的最小单位,磁盘上能存储的物理块数由扇区数、磁道数及磁盘面数决定,磁盘地址用“柱面号·盘面号·扇区号”表示。 读/写磁盘数据块的过程如下:①根据柱面号移动磁头臂,让磁头移动到对应的柱面;②激活对应盘面的磁头;③当磁盘旋转时,磁头从对应扇区上划过,从而完成对指定扇区的读/写。 磁盘按不同的方式可分为若干类型:磁头相对于盘片的径向方向固定的称为固定头磁盘,这种磁盘中的每个磁道有一个磁头。磁头可移动的称为活动头磁盘,磁头臂可来回伸缩定位磁道。盘片永久固定在磁盘驱动器内的称为固定盘磁盘。盘片可移动和替换的称为可换盘磁盘。最早的磁盘由IBM公司研发,称为温彻斯特磁盘,它是一种磁头活动而盘片固定的磁盘存储器。",
  "磁盘的管理 1.磁盘初始化 一个新的磁盘只是一个磁性记录材料的空白盘。在磁盘可以存储数据之前,必须将它分成扇区,以便磁盘控制器能够进行读/写操作,这个过程称为低级格式化(也称物理格式化)。每个扇区通常由头部、数据区域和尾部组成。头部和尾部包含了一些磁盘控制器的使用信息。 2.分区 在可以使用磁盘存储文件之前,还要完成两个步骤。第一步是,将磁盘分区,每个分区由一个或多个柱面组成,每个分区的起始扇区和大小都记录在磁盘主引导记录的分区表中。第二步是,对物理分区进行逻辑格式化(也称高级格式化),将初始的文件系统数据结构存储到磁盘上,这些数据结构包括空闲的空间和已分配的空间,以及一个初始为空的目录,建立根目录、对保存空闲磁盘块信息的数据结构进行初始化。 因为扇区的单位太小,为了提高效率,操作系统将多个相邻的扇区组合在一起,形成一簇(在Linux中称为块)。 3.引导块 计算机启动时需要运行一个初始化程序(自举程序),它初始化CPU、寄存器、设备控制器和内存等,接着启动操作系统。为此,自举程序找到磁盘上的操作系统内核,将它加载到内存,并转到起始地址,从而开始操作系统的运行。 自举程序通常存放在ROM中,为了避免改变自举代码而需要改变ROM硬件的问题,通常只在ROM 中保留很小的自举装入程序,而将完整功能的引导程序保存在磁盘的启动块上,启动块位于磁盘的固定位置。具有启动分区的磁盘称为启动磁盘或系统磁盘。 Windows 系统将引导代码存储在磁盘的第0号扇区,它称为主引导记录(MBR)。引导首先运行ROM中的代码,这个代码指示系统从MBR中读取引导代码。除了包含引导代码,MBR还包含一个磁盘分区表和一个标志(以指示从哪个分区引导系统)。当系统找到引导分区时,读取分区的第一个扇区,称为引导扇区,并继续余下的引导过程。 4.坏块 磁盘有移动部件且容错能力弱,因此容易导致一个或多个扇区损坏。 对于简单磁盘,坏块可手动处理,如MS-DOS的Format命令执行逻辑格式化时会扫描磁盘以检查坏块。坏块在FAT表上会标明,因此程序不会使用它们。 对于复杂的磁盘,控制器维护磁盘内的坏块列表。控制器可以采用备用块来逻辑地替代坏块,这种方案称为扇区备用。",
  "磁盘调度算法 磁盘的存取时间 一次磁盘读/写操作的时间由寻找(寻道)时间、旋转延迟时间和传输时间决定。 1)寻道时间。活动头磁盘在读/写信息前,将磁头移动到目的磁道所需的时间。 2)旋转延迟时间。磁头定位到要读/写扇区所需的时间。 3)传输时间。从磁盘读出或向磁盘写入数据所需的时间。 在磁盘的存取时间中,寻道时间占大头,它与磁盘调度算法密切相关;而延迟时间和传输时间都与磁盘旋转速度线性相关。因此,磁盘调度的主要目标是减少磁盘的平均寻道时间。 2.磁盘调度算法 (1)先来先服务(First Come First Served, FCFS)算法 FCFS 算法根据进程请求访问磁盘的先后顺序进行调度,这是一种最简单的调度算法。该算法的优点是具有公平性。若有大量进程竞争使用磁盘,则这种算法在性能上往往接近于随机调度。 (2)最短寻道时间优先(Shortest Seek Time First, SSTF)算法 SSTF 算法每次选择调度的是离当前磁头最近的磁道,使每次的寻道时间最短。但不能保证平均寻道时间最小,但能提供比FCFS算法更好的性能。这种算法会产生“饥饿”现象。 (3)扫描(SCAN)算法 SSTF 算法产生饥饿的原因是“磁头可能在一个小范围内来回地移动”。为了防止这个问题,可以规定:只有磁头移动到最外侧磁道时才能向内移动,移动到最内侧磁道时才能向外移动,这就是 SCAN 算法的思想。它是在SSTF算法的基础上规定了磁头移动的方向。磁头移动规律与电梯运行相似,因此也称电梯调度算法。SCAN算法对最近扫描过的区域不公平。 (4)循环扫描(Circular SCAN, C-SCAN)算法 在SCAN 算法的基础上规定磁头单向移动来提供服务,返回时直接快速移动至起始端而不服务任何请求。 采用 SCAN 算法和C-SCAN算法时,磁头总是严格地遵循从盘面的一端到另一端,在实际使用时还可以改进,即磁头只需移动到最远端的一个请求即可返回,不需要到达磁盘端点。这种改进后的SCAN 算法和C-SCAN算法称为LOOK调度和C-LOOK调度。 3.减少延迟时间的方法 除减少寻道时间外,减少延迟时间也是提高磁盘传输效率的重要因素。 可对一个盘面的扇区进行交替编号,即让逻辑上相邻的块在物理上保持一定的间隔,则读入多个连续块时能够减少延迟时间。 此外,可对不同的盘面进行错位命名,读完一个盘面的最后一个扇区后,还有一段时间处理,当磁头首次划过下一个盘面的第一个扇区时能直接读取,从而减少了延迟时间。 提高磁盘I/O速度的方法 1)采用磁盘高速缓存。 2)调整磁盘请求顺序。即上面介绍的各种磁盘调度算法。 3)提前读。在读磁盘当前块时,将下一磁盘块也读入内存缓冲区。 4)延迟写。仅在缓冲区首部设置延迟写标志,然后释放此缓冲区并将其链入空闲缓冲区链表的尾部,当其他进程申请到此缓冲区时,才真正将缓冲区信息写入磁盘块。 5)优化物理块的分布。除了上面介绍的扇区编号优化,当文件采用链接方式和索引方式组织时,应尽量将同一个文件的盘块安排在一个磁道或相邻的磁道上,以减少寻道时间。 6)虚拟盘。是指用内存空间去仿真磁盘,又叫RAM盘。 7)采用磁盘阵列RAID。",
  "固态硬盘 固态硬盘的特性 固态硬盘(Solid State Disk, SSD)是一种基于闪存技术的存储器。一个SSD由一个或多个闪存芯片和闪存翻译层组成。闪存芯片替代传统磁盘中的机械驱动器,而闪存翻译层将来自CPU的逻辑块读/写请求翻译成对底层物理设备的读/写控制信号,因此闪存翻译层相当于扮演了磁盘控制器的角色。 一个闪存由B块组成,每块由P页组成。数据是以页为单位读/写的。以块为单位擦除,只有在一页所属的块整个被擦除后,才能写这一页。一旦一个块被擦除,块中的每个页就都可以直接再写一次。某个块进行了若干重复写后,就会磨损坏,不能再使用。 随机写很慢,有两个原因。首先,擦除块比较慢。其次,若写操作试图修改一个包含已有数据的页P,则该块中所有含有用数据的页都必须被复制到一个新(擦除过的)块中,然后才能进行对页P的写操作。 比起传统磁盘,SSD有很多优点,它由半导体存储器构成,没有移动的部件,因此随机访问速度比机械磁盘要快很多,也没有任何机械噪声和震动,能耗更低、抗震性好、安全性高等。 2.磨损均衡(Wear Leveling) 固态硬盘也有缺点,闪存的擦写寿命是有限的。若直接用普通闪存组装 SSD,读/写数据时会集中在SSD的一部分闪存,这部分闪存的寿命会损耗得特别快。 为了弥补 SSD的寿命缺陷,引入了磨损均衡。SSD磨损均衡技术大致分为两种: 1)动态磨损均衡。写入数据时,优先选择擦除次数少的新闪存块。 2)静态磨损均衡。就算没有数据写入,SSD也会监测并自动进行数据分配,让老的闪存块承担以读为主的存储任务。同时让较新的闪存块腾出空间,以承担更多以写为主的存储任务。",
  "文件的基本概念 文件(File)是以硬盘为载体的存储在计算机上的信息集合,文件可以是文本文档、图片、程序等。在系统运行时,计算机以进程为基本单位进行资源的调度和分配;而在用户进行的输入,输出中,则以文件为基本单位。大多数应用程序的输入都是通过文件来实现的,其输出也都保存在文件中,以便信息的长期存储及将来的访问。当用户将文件用于程序的输入、输出时,还希望可以访问、修改和保存文件等,实现对文件的维护管理,这就需要系统提供一个文件管理系统,操作系统中的文件系统(File System)就是用于实现用户的这些管理要求的。 要清晰地理解文件的概念,就要了解文件究竟由哪些东西组成。 1.文件的定义 首先,文件肯定包括一块存储空间,更准确地说,是存储空间中的数据;其次,操作系统要管理大量的数据,因此必须要对这些数据进行分类,所以文件必定包含分类和索引的信息;最后,不同用户对数据的访问权限不同,因此文件中一定包含关于访问权限的信息。 从用户的角度看,文件系统是操作系统的重要部分之一。用户关心的是如何命名、分类和查找文件,如何保证文件数据的安全性及对文件可以进行哪些操作等。而对于其中的细节,如文件如何存储在辅存上、如何管理文件辅存区域等方面,则关心甚少。 文件系统提供了与二级存储相关的资源的抽象,让用户能在不了解文件的各种属性、文件存储介质的特征及文件在存储介-质上的具体位置等情况下,方便快捷地使用文件。用户通过文件系统建立文件,用于应用程序的输入、输出,对资源进行管理。 首先了解文件的结构,我们通过自底向上的方式来定义。 1)数据项。是文件系统中最低级的数据组织形式,可分为以下两种类型: 基本数据项。用于描述一个对象的某种属性的一个值,是数据中的最小逻辑单位。 组合数据项。由多个基本数据项组成。 2)记录。是一组相关的数据项的集合,用于描述一个对象在某方面的属性。 3)文件。是指由创建者所定义的、具有文件名的一组相关元素的集合,可分为有结构文件和无结构文件两种。在有结构文件中,文件由若干个相似的记录组成,如一个班的学生记录;而无结构文件则被视为一个字符流,比如一个二进制文件或字符文件。 在操作系统中,通常将程序和数据组织成文件。文件可以是数字、字符或二进制代码,基本访问单元可以是字节或记录。文件可以长期存储在硬盘中,允许可控制的进程间共享访问,能够被组织成复杂的结构。 2.文件的属性 除了文件数据,操作系统还会保存与文件相关的信息,如所有者、创建时间等,这些附加信息称为文件属性或文件元数据。文件属性在不同系统中差别很大,但通常都包括如下属性。 1)名称。文件名称唯一,以容易读取的形式保存。 2)类型。被支持不同类型的文件系统所使用。 3)创建者。文件创建者的ID。 4)所有者。文件当前所有者的ID。 5)位置。指向设备和设备上文件的指针。 6)大小。文件当前大小(用字节、字或块表示),也可包含文件允许的最大值。 7)保护。对文件进行保护的访问控制信息。 8)创建时间,最后一次修改时间和最后一次存取时间。文件创建、上次修改和上次访问的相关信息,用于保护和跟踪文件的使用。 操作系统通过文件控制块(见下一小节)来维护文件元数据。 3.文件的分类 为了便于管理文件,将文件分成了若干类型。不同系统对文件的管理方式不同,因此它们的文件分类方法也有很大差异。下面是几种常见的文件分类方法。 1)按性质和用途分类,分为系统文件、用户文件、库文件。 2)按文件中数据的形式分类,分为源文件、目标文件、可执行文件。 3)按存取控制属性分类,分为可执行文件、只读文件、读/写文件。 4)按组织形式和处理方式分类,分为普通文件、目录文件、特殊文件。",
  "文件控制块和索引节点 与进程管理一样,为便于文件管理,引入了文件控制块的数据结构。 1.文件控制块 文件控制块(File Control Block,FCB)是用来存放控制文件需要的各种信息的数据结构,以实现按名存取。文件与FCB一一对应,FCB的有序集合称为文件目录,一个FCB就是一个文件目录项。通常,一个文件目录也被视为一个文件,称为目录文件。每当创建一个新文件,系统就要为其建立一个FCB,用来记录文件的各种属性。 FCB 主要包含以下信息: 基本信息,如文件名、文件的物理位置、文件的逻辑结构、文件的物理结构等。 存取控制信息,包括文件主的存取权限、核准用户的存取权限以及一般用户的存取权限。 使用信息,如文件建立时间、上次修改时间等。 索引节点 文件目录通常存放在磁盘上,当文件很多时,文件目录会占用大量的盘块。在查找目录的过程中,要先将存放目录文件的第一个盘块中的目录调入内存,然后用给定的文件名逐一比较,若未找到指定文件,就还需要不断地将下一盘块中的目录项调入内存,逐一比较。我们发现,在检索目录的过程中,只用到了文件名,仅当找到一个目录项(其中的文件名与要查找的文件名匹配)时,才需从该目录项中读出该文件的物理地址。也就是说,在检索目录时,文件的其他描述信息不会用到,也不需要调入内存。因此,有的系统(如UNIX)便采用了文件名和文件描述信息分离的方法,使文件描述信息单独形成一个称为索引节点的数据结构,简称i节点(inode)。在文件目录中的每个目录项仅由文件名和相应的索引节点号(或索引节点指针)构成。 (1)磁盘索引节点 是指存放在磁盘上的索引节点。每个文件有一个唯一的磁盘索引节点,主要包括以下内容: 文件主标识符,拥有该文件的个人或小组的标识符。 文件类型,包括普通文件、目录文件或特别文件。 文件存取权限,各类用户对该文件的存取权限。 文件物理地址,每个索引节点中含有13个地址项,即iaddr(0)~iaddr(12),它们以直接或间接方式给出数据文件所在盘块的编号。 文件长度,指以字节为单位的文件长度。 文件链接计数,在本文件系统中所有指向该文件的文件名的指针计数。 文件存取时间,本文件最近被进程存取、修改的时间及索引节点最近被修改的时间。 (2)内存索引节点 是指存放在内存中的索引节点。当文件被打开时,要将磁盘索引节点复制到内存的索引节点中,便于以后使用。在内存索引节点中增加了以下内容: 索引节点号,用于标识内存索引节点。 状态,指示i节点是否上锁或被修改。 访问计数,每当有一进程要访问此i节点时,计数加1;访问结束减1。 逻辑设备号,文件所属文件系统的逻辑设备号。 链接指针,设置分别指向空闲链表和散列队列的指针。",
  "文件的操作 1.文件的基本操作 文件属于抽象数据类型。为了正确地定义文件,需要考虑可以对文件执行的操作。操作系统提供一系列的系统调用,实现对文件的创建、删除、读、写、打开和关闭等操作。 1)创建文件。创建文件有两个必要步骤:一是为新文件分配外存空间;二是在目录中为之创建一个目录项,目录项记录了新文件名、文件在外存中的地址等信息。 2)删除文件。为了删除文件,根据文件名查找目录,删除指定文件对应的目录项和文件控制块,然后回收该文件所占用的存储空间(包括磁盘空间和内存缓冲区)。 3)读文件。为了读文件,根据文件名查找目录,找到指定文件的目录项后,从中得到被读文件在外存中的地址;在目录项中,还有一个指针用于对文件进行读操作。 4)写文件。为了写文件,根据文件名查找目录,找到指定文件的目录项后,再利用目录项中的写指针对文件进行写操作。每当发生写操作时,便更新写指针。 2.文件的打开与关闭 当用户对一个文件实施多次读/写等操作时,每次都要从检索目录开始。为了避免多次重复地检索目录,大多数操作系统要求,当用户首次对某文件发出操作请求时,须先利用系统调用 open将该文件打开。系统维护一个包含所有打开文件信息的表,称为打开文件表。所谓“打开”,是指系统检索到指定文件的目录项后,将该目录项从外存复制到内存中的打开文件表的一个表目中,并将该表目的索引号(也称文件描述符)返回给用户。当用户再次对该文件发出操作请求时,可通过索引号在打开文件表中查找到文件信息,从而节省了大量的检索开销。当文件不再使用时,可利用系统调用close关闭它,则系统将从打开文件表中删除这一表目。 在多个进程可以同时打开文件的操作系统中,通常采用两级表:整个系统表和每个进程表。整个系统的打开文件表包含与进程无关的信息,如文件在磁盘上的位置、访问日期和文件大小。每个进程的打开文件表保存的是进程对文件的使用信息,如文件的当前读/写指针、文件访问权限,并包含指向系统表中适当条目的指针。一旦有进程打开了一个文件,系统表就包含该文件的条目。当另一个进程执行调用open时,只不过是在其打开文件表中增加一个条目,并指向系统表的相应条目。通常,系统打开文件表为每个文件关联一个打开计数器(Open Count),以记录多少进程打开了该文件。当文件不再使用时,利用系统调用close 关闭它,会删除单个进程的打开文件表中的相应条目,系统表中的相应打开计数器也会递减。当打开计数器为0时,表示该文件不再被使用,并且可从系统表中删除相应条目。 文件名不必是打开文件表的一部分,因为一旦完成对FCB 在磁盘上的定位,系统就不再使用文件名。对于访问打开文件表的索引号,UNIX称之为文件描述符,而Windows称之为文件句柄。因此,只要文件未被关闭,所有文件操作都是通过文件描述符(而非文件名)来进行。 每个打开文件都具有如下关联信息: 文件指针。系统跟踪上次的读/写位置作为当前文件位置的指针,这种指针对打开文件的某个进程来说是唯一的,因此必须与磁盘文件属性分开保存。 文件打开计数。计数器跟踪当前文件打开和关闭的数量。因为多个进程可能打开同一个文件,所以系统在删除打开文件条目之前,必须等待最后一个进程关闭文件。 文件磁盘位置。大多数文件操作要求系统修改文件数据。查找磁盘上的文件所需的信息保存在内存中,以便系统不必为每个操作都从磁盘上读取该信息。 访问权限。每个进程打开文件都需要有一个访问模式(创建、只读、读/写、添加等)。该信息保存在进程的打开文件表中,以便操作系统能够允许或拒绝后续的I/O请求。",
  "文件的逻辑结构 文件的逻辑结构是指从用户角度出发所看到的文件的组织形式。而文件的物理结构(也称存储结构)是指将文件存储在外存上的存储组织形式,是用户所看不见的。文件的逻辑结构与存储介质特性无关,它实际上是指在文件的内部,数据在逻辑上是如何组织起来的。 按逻辑结构,文件可划分为无结构文件和有结构文件两大类。 1.无结构文件 无结构文件是最简单的文件组织形式,它是由字符流构成的文件,所以也称流式文件,其长度以字节为单位。对流式文件的访问,是通过读/写指针来指出下一个要访问的字节。在系统中运行的大量源程序、可执行文件、库函数等,所采用的就是无结构文件。无结构文件没有结构,因此对记录的访问只能通过穷举搜索的方式,因此这种文件形式对很多应用不适用。 2.有结构文件 有结构文件是指由一个以上的记录构成的文件,所以也称记录式文件。各记录由相同或不同数量的数据项组成,根据各记录的长度是否相等,可分为定长记录和变长记录两种。 1)定长记录。文件中所有记录的长度都是相同的,各数据项都在记录中的相同位置,具有相同的长度。检索记录的速度快,方便用户对文件进行处理,广泛用于数据处理中。 2)变长记录。文件中各记录的长度不一定相同,原因可能是记录中所包含的数据项数量不同,也可能是数据项本身的长度不定。检索记录只能顺序查找,速度慢。 有结构文件按记录的组织形式可以分为顺序文件、索引文件、索引顺序文件。 (1)顺序文件 文件中的记录一个接一个地顺序排列,记录可以是定长记录或变长记录。顺序文件中记录的排列有两种结构:①串结构,各记录之间的顺序与关键字无关,通常是按存入的先后时间进行排列,检索时必须从头开始顺序依次查找,比较费时;②顺序结构,所有记录按关键字顺序排列,对于定长记录的顺序文件,检索时可采用折半查找,效率较高。 在对记录进行批量操作,即每次要读或写一大批记录时,顺序文件的效率是所有逻辑文件中的最高的。此外,对于顺序存储设备(如磁带),也只有顺序文件才能被存储并能有效地工作。在经常需要查找、修改、增加或删除单个记录的场合,顺序文件的性能较差。 (2)索引文件 对于变长记录的顺序文件,要查找第i条记录,必须顺序地查找前i-1条记录。 变长记录的顺序文件只能顺序查找,效率较低。为此,可以建立一张索引表,为主文件的每个记录在索引表中分别设置一个索引表项,其中包含指向记录的指针和记录长度,索引表按关键字排序,因此其本身也是一个定长记录的顺序文件。这样就将对变长记录顺序文件的顺序检索,转变成了对定长记录索引文件的随机检索,从而加快了记录的检索速度。 索引文件需要配置索引表,且每个记录都要有一个索引项,因此增加了存储开销。 (3)索引顺序文件 索引顺序文件是顺序文件和索引文件的结合。最简单的索引顺序文件只使用了一级索引,先将变长记录顺序文件中的所有记录分为若干组,然后为文件建立一张索引表,并为每组中的第一个记录建立一个索引项,其中包含该记录的关键字和指向该记录的指针。 检索时,首先查找索引表,找该记录所在的组,然后在该组中使用顺序查找,就能很快地找到记录。 索引文件和索引顺序文件都提高了查找速度,但都因配置索引表而增加了存储空间。 (4)直接文件或散列文件(Hash File) 给定记录的键值或通过散列函数转换的键值直接决定记录的物理地址。散列文件具有很高的存取速度,但是会引起冲突,即不同关键字的散列函数值可能相同。",
  "文件的物理结构 文件的物理结构就是研究文件的实现,即文件数据在物理存储设备上是如何分布和组织的。文件的物理结构有两个方面的回答:一是文件的分配方式,讲的是对磁盘非空闲块的管理;二是文件存储空间管理,讲的是对磁盘空闲块的管理。 文件分配对应于文件的物理结构,是指如何为文件分配磁盘块。常用的文件分配方法有三种:连续分配、链接分配和索引分配。 内存与磁盘之间的数据交换(磁盘I/O)都是以块为单位进行的。 1.连续分配 连续分配方法要求每个文件在磁盘上占有一组连续的块。磁盘地址定义了磁盘上的一个线性排序,这种排序使进程访问磁盘时需要的寻道数和寻道时间最小。 采用连续分配时,逻辑文件中的记录也顺序存储在相邻的物理块中。一个文件的目录项中应记录该文件的第一个磁盘块的块号和所占用的块数。 连续分配的优点:①支持顺序访问和直接访问。②顺序访问容易且速度快。缺点:①为文件分配连续的存储空间会产生很多外部碎片。②必须事先知道文件的长度,也无法满足文件动态增长的要求。③为保持文件的有序性,删除和插入记录时,需要对相邻的记录做物理上的移动。 2.链接分配 链接分配是一种采用离散分配的方式。链式分配的优点:①消除了磁盘的外部碎片,提高了磁盘的利用率。②便于动态地为文件分配盘块,因此无须事先知道文件的大小。③文件的插入、删除和修改也非常方便。链接分配又可分为隐式链接和显式链接两种形式。 (1)隐式链接 隐式链接方式。目录项中含有文件第一块的指针(盘块号)和最后一块的指针。每个文件对应一个磁盘块的链表,磁盘块分布在磁盘的任何地方。除文件的最后一个盘块外,每个盘块都存有指向文件下一个盘块的指针,这些指针对用户是透明的。 隐式链接的缺点:①只支持顺序访问,随机访问效率很低。②稳定性问题,文件盘块中的任何一个指针出问题,都会导致文件数据的丢失。③指向下一个盘块的指针也要耗费一定的存储空间。 (2)显式链接 显式链接是指将用于链接文件各物理块的指针,显式地存放在内存的一张链接表中,该表在整个文件系统中仅设置一张,称为文件分配表(File Allocation Table, FAT)。每个表项中存放指向下一个盘块的指针。文件目录中只需记录该文件的起始块号,后续块号可通过查FAT找到。 FAT的表项与全部磁盘块一一对应,并且可以用一个特殊的数字-1表示文件的最后一块,可以用-2表示这个磁盘块是空闲的。因此,FAT还标记了空闲的磁盘块,操作系统可以通过FAT对磁盘空闲空间进行管理。 显式链接的优点:①支持顺序访问,也支持直接访问。②FAT在系统启动时就被读入内存,检索记录是在内存中进行的,因此不仅显著提高了检索速度,还明显减少了访问磁盘的次数。缺点:FAT需要占用一定的内存空间。 3.索引分配 (1)单级索引分配方式 将每个文件所有的盘块号集中地放在一起。它为每个文件分配一个索引块(表),将分配给该文件的所有盘块号都记录在该索引块中。 索引分配的优点是支持直接访问。索引分配也不会产生外部碎片。缺点是索引块增加了额外的存储空间开销。 索引块的主要问题是,每个文件必须有一个索引块,当文件很小时,该方式仍为之分配一个索引块,此时索引块的利用率很低;当文件很大时,若其盘块号都需占用若干个索引块,此时可通过链指针将各索引块按序链接起来,但这种方法是低效的。 (2)多级索引分配方式 当文件太大而索引块太多时,应该为这些索引块再建立一级索引,称为主索引,将第一个索引块的盘块号、第二个索引块的盘块号…填入该主索引表,这样,便形成了二级索引分配方式,其原理类似于内存管理中的多级页表。查找时,通过主索引查找第二级索引,再通过第二级索引查找所需数据块。若文件非常大,则还可使用三级、四级索引分配方式。 多级索引的优点:极大加快了对大型文件的查找速度。缺点:当访问一个盘块时,其所需启动磁盘的次数随着索引级数的增加而增多。 (3)混合索引分配方式 为了能够较全面地照顾到小型、中型、大型和特大型文件,可采用混合索引分配方式。对于小文件,为了提高对众多小文件的访问速度,最好能将它们的每个盘块地址直接放入FCB,即为直接寻址。对于中型文件,可以采用单级索引分配,即为一次间址。对于大型或特大型文件,可以采用两级和三级索引分配。UNIX系统采用的就是这种分配方式,在其索引节点中,共设有13个地址项,即i.addr(0)~i.addr(12)。 1)直接地址。在索引节点中可设置10个直接地址项,即用i.addr(0)~i.addr(9)来存放直接地址,即文件数据块的盘块号。 2)一次间接地址。可再利用索引节点中的地址项i.addr(10)来提供一次间接地址,即采用一级索引分配。 3)多次间接地址。当文件长度很大时,还需利用地址项i.addr(11)来提供二次间接地址,即采用两级索引分配;利用地址项i.addr(12)来提供三次间接地址。",
  "文件保护 为了防止文件共享可能导致文件被破坏或未经核准的用户修改文件,文件系统必须控制用户对文件的存取,即解决对文件的读、写、执行的许可问题。为此,必须在文件系统中建立相应的文件保护机制,可以通过口令保护,加密保护和访问控制等方式实现。 1.访问类型 对文件的保护可从限制对文件的访问类型中出发。可加以控制的访问类型主要有以下几种。 读。从文件中读数据。 写。向文件中写数据。 执行。将文件装入内存并执行。 添加。将新信息添加到文件结尾部分。 删除。删除文件,释放空间。 列表清单。列出文件名和文件属性。 2.访问控制 解决访问控制最常用的方法是根据用户身份进行控制。而实现基于身份访问的最为普通的方法是,为每个文件和目录增加一个访问控制列表(Access-Control List, ACL),以规定每个用户名及其所允许的访问类型。 精简的访问控制列表可采用拥有者、组和其他三种用户类型。 1)拥有者。创建文件的用户。 2)组。一组需要共享文件且具有类似访问的用户。 3)其他。系统内的所有其他用户。 口令和密码是另外两种访问控制方法。 口令指用户在建立一个文件时提供一个口令,系统为其建立FCB时附上相应口令,同时告诉允许共享该文件的其他用户。用户请求访问时必须提供相应的口令。 密码指用户对文件进行加密,文件被访问时需要使用密钥。这种方法保密性强,节省了存储空间,不过编码和译码要花费一定的时间。",
  "目录的基本概念 上节说过,FCB的有序集合称为文件目录,一个FCB 就是一个文件目录项。与文件管理系统和文件集合相关联的是文件目录,它包含有关文件的属性、位置和所有权等。 首先来看目录管理的基本要求:从用户的角度看,目录在用户(应用程序)所需要的文件名和文件之间提供一种映射,所以目录管理要实现“按名存取”;目录存取的效率直接影响到系统的性能,所以要提高对目录的检索速度;在多用户系统中,应允许多个用户共享一个文件,因此目录还需要提供用于控制访问文件的信息。此外,应允许不同用户对不同文件采用相同的名字,以便于用户按自己的习惯给文件命名,目录管理通过树形结构来解决和实现。",
  "目录的操作 在理解一个文件系统的需求前,我们首先考虑在目录这个层次上所需要执行的操作,这有助于后面文件系统的整体理解。 搜索。当用户使用一个文件时,需要搜索目录,以找到该文件的对应目录项。 创建文件。当创建一个新文件时,需要在目录中增加一个目录项。 删除文件。当删除一个文件时,需要在目录中删除相应的目录项。 创建目录。在树形目录结构中,用户可创建自己的用户文件目录,并可再创建子目录。 删除目录。有两种方式:①不删除非空目录,删除时要先删除目录中的所有文件,并递归地删除子目录。②可删除非空目录,目录中的文件和子目录同时被删除。 移动目录。将文件或子目录在不同的父目录之间移动,文件的路径名也会随之改变。 显示目录。用户可以请求显示目录的内容,如显示该用户目录中的所有文件及属性。 修改目录。某些文件属性保存在目录中,因此这些属性的变化需要改变相应的目录项。",
  "目录结构 单级目录结构 在整个文件系统中只建立一张目录表,每个文件占一个目录项。 当建立一个新文件时,必须先检索所有目录项,以确保没有“重名”的情况,然后在该目录中增设一项,将新文件的属性信息填入该项。当访问一个文件时,先按文件名在该目录中查找到相应的FCB,经合法性检查后执行相应的操作。当删除一个文件时,先从该目录中找到该文件的目录项,回收该文件所占用的存储空间,然后清除该目录项。 单级目录结构实现了“按名存取”,但是存在查找速度慢、文件不允许重名、不便于文件共享等缺点,而且对于多用户的操作系统显然是不适用的。 2.两级目录结构 为了克服单级目录所存在的缺点,可以采用两级方案,将文件目录分成主文件目录(Master File Directory, MFD)和用户文件目录(User File Directory, UFD)两级。 主文件目录项记录用户名及相应用户文件目录所在的存储位置。用户文件目录项记录该用户所有文件的FCB。当某用户欲对其文件进行访问时,只需搜索该用户对应的UFD,这既解决了不同用户文件的“重名”问题,又在一定程度上保证了文件的安全。 两级目录结构提高了检索的速度,解决了多用户之间的文件重名问题,文件系统可以在目录上实现访问限制。但是两级目录结构缺乏灵活性,不能对文件分类。 3.树形目录结构 将两级目录结构加以推广,就形成了树形目录结构。它可以明显地提高对目录的检索速度和文件系统的性能。当用户要访问某个文件时,用文件的路径名标识文件,文件路径名是个字符串,由从根目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。从根目录出发的路径称为绝对路径,系统中的每个文件都有唯一的路径名。一个进程在运行时,其所访问的文件大多局限于某个范围,当层次较多时,每次从根目录查询会浪费时间,因此可为每个进程设置一个当前目录(也称工作目录),此时进程对各文件的访问都只需相对于当前目录而进行。当用户要访问某个文件时,使用相对路径名标识文件,相对路径由从当前目录出发到所找文件通路上所有目录名与数据文件名用分隔符“/”链接而成。 通常,每个用户都有各自的“当前目录”,登录后自动进入该用户的“当前目录”。操作系统提供一个专门的系统调用,供用户随时改变“当前目录”。 树形目录结构可以很方便地对文件进行分类,层次结构清晰,也能够更有效地进行文件的管理和保护。在树形目录中,不同性质、不同用户的文件,可以分别呈现在系统目录树的不同层次或不同子树中,很容易地赋予不同的存取权限。但是,在树形目录中查找一个文件,需要按路径名逐级访问中间节点,增加了磁盘访问次数,这无疑会影响查询速度。目前,大多数操作系统如 UNIX、Linux和Windows 系统都采用了树形文件目录。 4.无环图目录结构 树形目录结构能便于实现文件分类,但不便于实现文件共享,为此在树形目录结构的基础上增加一些指向同一节点的有向边,使整个目录成为一个有向无环图。这种结构允许目录共享子目录或文件,同一个文件或子目录可以出现在两个或多个目录中。 当某用户要求删除一个共享节点时,若系统只是简单地将它删除,则当另一共享用户需要访问时,会因无法找到这个文件而发生错误。为此,可为每个共享节点设置一个共享计数器,每当图中增加对该节点的共享链时,计数器加1;每当某用户提出删除该节点时,计数器减1。仅当共享计数器为0时,才真正删除该节点,否则仅删除请求用户的共享链。 无环图目录结构方便地实现了文件的共享,但使得系统的管理变得更加复杂。",
  "目录实现 在访问一个文件时,操作系统利用路径名找到相应目录项,目录项中提供了查找文件磁盘块所需要的信息。目录实现的基本方法有线性列表和哈希表两种,要注意目录的实现就是为了查找,因此线性列表实现对应线性查找,哈希表的实现对应散列查找。 线性列表 最简单的目录实现方法是,采用文件名和数据块指针的线性列表。当创建新文件时,必须首先搜索目录以确定没有同名的文件存在,然后在目录中增加一个新的目录项。当删除文件时,则根据给定的文件名搜索目录,然后释放分配给它的空间。当要重用目录项时有许多种方法:可以将目录项标记为不再使用,或将它加到空闲目录项的列表上,还可以将目录的最后一个目录项复制到空闲位置,并减少目录的长度。采用链表结构可以减少删除文件的时间。 线性列表的优点在于实现简单,不过由于线性表的特殊性,查找比较费时。 哈希表 除了采用线性列表存储文件目录项,还可以采用哈希数据结构。哈希表根据文件名得到一个值,并返回一个指向线性列表中元素的指针。这种方法的优点是查找非常迅速,插入和删除也较简单,不过需要一些措施来避免冲突(两个文件名称哈希到同一位置)。 目录查询是通过在磁盘上反复搜索完成的,需要不断地进行I/O操作,开销较大。所以如前所述,为了减少I/O操作,将当前使用的文件目录复制到内存,以后要使用该文件时只需在内存中操作,因此降低了磁盘操作次数,提高了系统速度。",
  "文件共享 文件共享使多个用户共享同一个文件,系统中只需保留该文件的一个副本。若系统不能提供共享功能,则每个需要该文件的用户都要有各自的副本,会造成对存储空间的极大浪费。 前面介绍了无环图目录,基于该结构可实现文件共享,当建立链接关系时,必须将被共享文件的物理地址(盘块号)复制到相应的目录。若某个用户向该文件添加新数据,且需要增加新盘块,则这些新增的盘块只会出现在执行操作的目录中,对其他共享用户是不可见的。 1.基于索引节点的共享方式(硬链接) 硬链接是基于索引节点的共享方式,它将文件的物理地址和属性等信息不再放在目录项中,而是放在索引节点中,在目录中只设置文件名及指向相应索引节点的指针。在索引节点中还有一个链接计数count,也称引用计数,表示链接到本索引节点(文件)上的用户目录项的数量。当count=2时,表示有两个用户目录项链接到本文件上,即有两个用户共享此文件。 当用户创建一个新文件时,他是该文件的所有者,此时将count置为1。当用户B要共享此文件时,在B的目录中增加一个目录项,并设置一个指针指向该文件的索引节点。此时,文件主仍是用户A,count=2。当用户不再需要此文件时,能否直接将其删除?答案是否定的。因为若删除该文件,必然也删除该文件的索引节点,这样便使用户B的指针悬空。因此用户不能删除此文件,只是将该文件的count减1,然后删除自己目录中的相应目录项。用户B仍可以使用该文件。当count=0时,表示没有用户使用该文件,才删除该文件。 2.利用符号链实现文件共享(软链接) 为使用户B能共享用户A的一个文件F,可由系统创建一个LINK类型的新文件L,并将文件L写入用户B的目录,以实现B的目录与文件F的链接。文件L中只含有被链接文件F的路径名。这种链接方法称为符号链接或软链接,它类似于Windows 系统中的快捷方式。当用户B访问文件L时,操作系统看到要读的文件属于LINK类型,则根据其中记录的路径名去查询文件F,然后对F进行读/写操作,从而实现用户B对文件F的共享。 利用符号链方式实现文件共享时,只有文件主才拥有指向其索引节点的指针。而共享该文件的其他用户只有该文件的路径名,并不拥有指向其索引节点的指针。这样,也就不会发生在文件主删除一个共享文件后留下一个悬空指针的情况。当文件主将一个共享文件删除后,若其他用户又试图通过符号链去访问它时,则会访问失败,于是再将符号链删除,此时不会产生任何影响。 在符号链的共享方式中,当其他用户读共享文件时,系统根据文件路径名依次查找目录,直至找到该文件的索引节点。因此,每次访问共享文件时,都可能要多次地读盘,增大了访问文件的开销。此外,符号链接也是一个文件,其索引节点也要耗费一定的磁盘空间。 利用符号链实现网络文件共享时,只需提供该文件所在机器的网络地址及文件路径名。",
  "文件系统结构 文件系统(File system)提供高效和便捷的磁盘访问,以便允许存储、定位、提取数据。文件系统有两个不同的设计问题:第一个问题是,定义文件系统的用户接口,它涉及定义文件及其属性、所允许的文件操作、如何组织文件的目录结构。第二个问题是,创建算法和数据结构,以便映射逻辑文件系统到物理外存设备。现代操作系统有多种文件系统类型,因此文件系统的层次结构也不尽相同。一个合理的文件系统层次结构。 (1)1/0控制层 包括设备驱动程序和中断处理程序,在内存和磁盘系统之间传输信息。设备驱动程序将输入的命令翻译成底层硬件的特定指令,硬件控制器利用这些指令使I/O设备与系统交互。设备驱动程序告诉1/0控制器对设备的什么位置采取什么动作。 (2)基本文件系统 向对应的设备驱动程序发送通用命令,以读取和写入磁盘的物理块。每个物理块由磁盘地址标识。该层也管理内存缓冲区,并保存各种文件系统、目录和数据块的缓存。在进行磁盘块传输前,分配合适的缓冲区,并对缓冲区进行管理。管理它们对于系统性能的优化至关重要。 (3)文件组织模块 组织文件及其逻辑块和物理块。文件组织模块可以将文件的逻辑块地址转换为物理块地址,每个文件的逻辑块从0到N编号,它与数据的物理块不匹配,因此需要通过转换来定位。文件组织模块还包括空闲空间管理器,以跟踪未分配的块,根据需求提供给文件组织模块。 (4)逻辑文件系统 用于管理文件系统中的元数据信息。元数据包括文件系统的所有结构,而不包括实际数据(或文件内容)。逻辑文件系统管理目录结构,以便根据给定文件名为文件组织模块提供所需要的信息。它通过文件控制块来维护文件结构。逻辑文件系统还负责文件保护。",
  "文件系统布局 1.文件系统在磁盘中的结构 文件系统存放在磁盘上,多数磁盘划分为一个或多个分区,每个分区中有一个独立的文件系统。文件系统可能包括如下信息:启动存储在那里的操作系统的方式、总的块数、空闲块的数量和位置、目录结构以及各个具体文件等。一个可能的文件系统布局。 简单描述如下: 1)主引导记录(Master Boot Record,MBR),位于磁盘的0号扇区,用来引导计算机,MBR的后面是分区表,该表给出每个分区的起始和结束地址。表中的一个分区被标记为活动分区。当计算机启动时,BIOS读入并执行MBR。MBR做的第一件事是确定活动分区,读入它的第一块,即引导块。 2)引导块(boot block), MBR执行引导块中的程序后,该程序负责启动该分区中的操作系统。每个分区都是统一从一个引导块开始,即使它不含有一个可启动的操作系统,也不排除以后会在该分区安装一个操作系统。Windows 系统称之为分区引导扇区。 除了从引导块开始,磁盘分区的布局是随着文件系统的不同而变化的。文件系统经常包含有如图4.20所列的一些项目。 3)超级块(super block),包含文件系统的所有关键信息,在计算机启动时,或者在该文件系统首次使用时,超级块会被读入内存。超级块中的典型信息包括分区的块的数量、块的大小、空闲块的数量和指针、空闲的FCB数量和FCB指针等。 4)文件系统中空闲块的信息,可以用位示图或指针链接的形式给出。后面也许跟的是一组i节点,每个文件对应一个i节点,i节点说明了文件的方方面面。接着可能是根目录,它存放文件系统目录树的根部。最后,磁盘的其他部分存放了其他所有的目录和文件。 2.文件系统在内存中的结构 内存中的信息用于管理文件系统并通过缓存来提高性能。这些数据在安装文件系统时被加载,在文件系统操作期间被更新,在卸载时被丢弃。这些结构的类型可能包括: 1)内存中的安装表(mount table),包含每个已安装文件系统分区的有关信息。 2)内存中的目录结构的缓存,包含最近访问目录的信息。 3)整个系统的打开文件表,包含每个打开文件的FCB副本、打开计数及其他信息。 4)每个进程的打开文件表,包含进程打开文件的文件描述符(Windows称之为文件句柄)和指向整个系统的打开文件表中对应表项的指针。",
  "文件存储空间管理 一个存储设备可以按整体用于文件系统,也可以细分。例如,一个磁盘可以划分为2个分区,每个分区都可以有单独的文件系统。包含文件系统的分区通常称为卷(volume)。卷可以是磁盘的一部分,也可以是整个磁盘,还可以是多个磁盘组成RAID集。 在一个卷中,存放文件数据的空间(文件区)和FCB的空间(目录区)是分离的。因为存在很多种类的文件表示和存放格式,所以现代操作系统中一般都有很多不同的文件管理模块,通过它们可以访问不同格式的卷中的文件。卷在提供文件服务前,必须由对应的文件程序进行初始化,划分好目录区和文件区,建立空闲空间管理表格及存放卷信息的超级块。 文件存储设备分成许多大小相同的物理块,并以块为单位交换信息,因此,文件存储设备的管理实质上是对空闲块的组织和管理,它包括空闲块的组织、分配与回收等问题。 1.空闲表法 空闲表法属于连续分配方式,它与内存的动态分区分配类似,为每个文件分配一块连续的存储空间。系统为外存上的所有空闲区建立一张空闲表,每个空闲区对应一个空闲表项,其中包括表项序号、该空闲区的第一个空闲盘块号、该空闲区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列。 盘块的分配: 空闲盘区的分配与内存的动态分配类似,也是采用首次适应算法、最佳适应算法等。 盘块的回收: 在对用户所释放的存储空间进行回收时,也采用类似于内存回收的方法,即要考虑回收区是否与空闲盘块表中插入点的前区和后区相邻接,对相邻接者应予以合并。 2.空闲链表法 空闲链表法是指将所有空闲盘区拉成一条空闲链,可分为以下两种。 (1)空闲盘块链 空闲盘块链是指将磁盘上的所有空闲空间以盘块为单位拉成一条链。每个盘块都有指向下一个空闲盘块的指针。当用户请求分配存储空间时,从链首开始,依次摘下适当数量的空闲盘块分配给用户。当用户释放存储空间时,将回收的盘块依次插入空闲盘块链的末尾。 空闲盘块链的优点是分配和回收一个盘块的过程非常简单。缺点是在为一个文件分配盘块时可能要重复操作多次,效率较低;又因它是以盘块为单位的,空闲盘块链会很长。 (2)空闲盘区链 空闲盘区链是指将磁盘上的所有空闲盘区拉成一条链,每个盘区包含若干相邻的盘块。每个盘区含有指向下一个空闲盘区的指针和本盘区的盘块数。分配盘区的方法与内存的动态分区分配类似,通常采用首次适应算法。回收盘区时,同样也要将回收区与相邻接的空闲盘区合并。 空闲盘区链的优缺点正好与空闲盘块链的相反,优点是分配与回收的效率较高,且空闲盘区链较短。缺点是分配与回收的过程比较复杂。 3.位示图法 位示图是利用二进制的一位来表示磁盘中一个盘块的使用情况,磁盘上的所有盘块都有一个二进制位与之对应。当其值为“0”时,表示对应的盘块空闲;为“1”时,表示已分配。 盘块的分配: 1)顺序扫描位示图,从中找出一个或一组其值为“0”的二进制位。 2)将找到的一个或一组二进制位转换成与之对应的盘块号。假设找到值为“0”的二进制位处在位示图的第i行、第j列,则其对应的盘块号b应按下式计算(n为每行位数):b=n(i-1)+j 3)修改位示图,令 map[i,j]=1. 盘块的回收: 1)将回收盘块的盘块号转换成位示图中的行号和列号。转换公式为:i=(b-1)DIV n+1, j=(b-1)MOD n+1 2)修改位示图,令 map[i,j]=0。 位示图法的优点是很容易在位示图中找到一个或一组相邻接的空闲盘块。位示图很小,占用空间少,因此可将它保存在内存中,从而节省许多磁盘启动的开销。 位示图法的问题是位示图大小会随着磁盘容量的增加而增大,因此常用于小型计算机。 4.成组链接法 空闲表法和空闲链表法都不适用于大型文件系统,因为这会使空闲表或空闲链表太大。UNIX系统中采用的是成组链接法,它结合了上述两种方法的思想而克服“表太长”的缺点。 成组链接法的思想:将空闲盘块分成若干组,如每100个盘块作为一组,每组的第一个盘块记录下一组的空闲盘块总数和空闲盘块号。这样,由各组的第一个盘块可以链接成一条链。第一组的空闲盘块总数和空闲盘块号保存在内存的专用栈中,称为空闲盘块号栈。 盘块的分配: 根据空闲盘块号栈的指针,将与之对应的盘块分配给用户,同时移动指针,并将栈中的空闲盘块数减1。若该指针指向的是栈底的盘块号,则在该盘块号对应的盘块中保存的是下一组空闲盘块号,因此要将该盘块的内容读入栈,作为新的空闲盘块号栈的内容,并将原栈底盘块号对应的盘块分配出去。 盘块的回收: 将回收的盘块号存入空闲盘块号栈的顶部,同时移动指针,并将栈中的空闲盘块数加1。当栈中的空闲盘块数已达100时,表示栈已满,将现有栈中的100个空闲盘块号存入新回收的盘块,并将该新回收的盘块号作为新栈底,再将栈中的空闲盘块数置为1。",
  "虚拟文件系统 虚拟文件系统(VFS)屏蔽了不同文件系统的差异和操作细节,向上为用户提供了文件操作的统一调用接口。当用户程序访问文件时,通过VFS 提供的统一调用函数(如open()等)来操作不同文件系统的文件,而无须考虑具体的文件系统和实际的存储介质。 虚拟文件系统采用了面向对象的思想,它抽象出一个通用的文件系统模型,定义了通用文件系统都支持的接口。新的文件系统只要支持并实现这些接口,即可安装和使用。为了实现虚拟文件系统,系统抽象了四种对象类型。每个对象都包含数据和函数指针,这些函数指针指向操作这些数据的文件系统的实现函数。这四种对象类型如下。 (1)超级块对象 表示一个已安装(或称挂载)的特定文件系统。超级块对象对应于磁盘上特定扇区的文件系统超级块,用于存储已安装文件系统的元信息。其操作方法包含一系列可在超级块对象上调用的操作函数,主要有分配 inode、销毁inode、读inode、写inode等。 (2)索引节点对象 表示一个特定的文件。索引节点和文件是一对一的关系。只有当文件被访问时,才在内存中创建索引节点对象,每个索引节点对象都会复制磁盘索引节点包含的一些数据。索引节点对象还提供许多操作函数,如创建新索引节点、创建硬链接、创建新目录等。 (3)目录项对象 表示一个特定的目录项。目录项对象是一个路径的组成部分,它包含指向关联索引节点的指针,还包含指向父目录和指向子目录的指针。不同于前面两个对象,目录项对象在磁盘上没有对应的数据结构,而是VFS在遍历路径的过程中,将它们逐个解析成目录项对象的。 (4)文件对象 表示一个与进程相关的已打开文件。可以通过调用open()打开一个文件,通过调用close()关闭一个文件。文件对象和物理文件的关系类似于进程和程序的关系。文件对象仅是进程视角上代表已打开的文件,它反过来指向其索引节点。文件对象包含与该文件相关联的目录项对象,包含该文件的文件系统、文件指针等,还包含在该文件对象上的一系列操作函数。 当进程发起一个面向文件的系统调用时,内核调用VFS中的一个函数,该函数调用目标文件系统中的相应函数,将文件系统请求转换到面向设备的指令。 对用户来说,不需要关心不同文件系统的具体实现细节,只需要对一个虚拟的文件操作界面进行操作。VFS对每个文件系统的所有细节进行抽象,使得不同的文件系统在系统中运行的进程看来都是相同的。严格来说,VFS并不是一种实际的文件系统,它只存在于内存中,不存在于任何外存空间中。VFS在系统启动时建立,在系统关闭时消亡。",
  "文件系统挂载 如文件在使用前要打开那样,文件系统在进程使用之前必须先安装,也称挂载(Mounting)。将设备中的文件系统挂载到某个目录后,就可通过这个目录来访问该设备上的文件。注意,这里的设备指的是逻辑上的设备,如一个磁盘上的不同分区都可视为不同的设备。 Windows 系统维护一个扩展的两级目录结构,用驱动器字母表示设备和卷。卷具有常规树结构的目录,与驱动器号相关联,还含有指向已安装文件系统的指针。特定文件的路径形式为driver- letter:\\path\\to\\file,访问时,操作系统找到相应文件系统的指针,并遍历该设备的目录结构,以查找指定的文件。 UNIX 使用系统的根文件系统,它是在系统启动时直接安装的,也是内核映像所在的文件系统。除了根文件系统,所有其他文件系统都要先挂载到根文件系统中的某个目录后才能访问。其他文件系统要么在系统初始化时自动安装,要么由用户挂载在已安装文件系统的目录下。安装文件系统的这个目录称为安装点,同一个设备可以有多个安装点,同一个安装点同时只能挂载一个设备。将设备挂载到安装点之后,通过该目录就可以读取该设备中的数据。"
]